> 当前位置：【Java】05_JavaWeb_Database  -> 5.1_MySQL数据库

----



# MySQL 下载安装和配置



## 0、MySQL的下载

### 下载地址

- https://downloads.mysql.com/archives/community/



### 图形化界面工具

- 软件1：MySQLWorkBench

  https://dev.mysql.com/downloads/workbench/

- 软件2：Navicat（Win/Mac）

- 软件3：SQLyog（Win）



## 1、Docker - MySQL安装和配置

### 1.1 Docker-MySQL 官网地址

https://hub.docker.com/_/mysql



### 1.2 创建单容器

#### 步骤1：拉取镜像

```shell
docker pull mysql:5.7.34
```



#### 步骤2：备份镜像

```shell
cd /docker_data/
docker save mysql:5.7.34 -o mysql.5.7.34.tar
```



#### 步骤3：导入镜像

```shell
docker load -i mysql.5.7.34.tar
```



#### 步骤4：创建并运行容器

##### （1）使用命令

```shell
# --restart always：容器退出时总是重启
# --privileged=true：特权模式，不受限制地访问任何自己的系统调用，给容器提供了几乎所有主机（作为root）可以做的事情的权限
# -e , --env=[]：设置环境变量，容器中可以使用该环境变量

# Linux - 使用默认卷
docker run -itd --name mysql --restart always --privileged=true -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root mysql:5.7.34 --character-set-server=utf8 --collation-server=utf8_general_ci

# Linux - 使用自定义卷挂载
docker run -itd --name mysql --restart always --privileged=true -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -v /docker_data/mysql:/var/lib/mysql mysql:5.7.34 --character-set-server=utf8 --collation-server=utf8_general_ci

# Mac - 使用自定义卷挂载
docker run -itd --name mysql --restart always --privileged=true -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -v /Users/td/Documents/03_DevTools/docker_data/mysql:/var/lib/mysql mysql:5.7.34 --character-set-server=utf8 --collation-server=utf8_general_ci
```

##### （2）使用 docker  compose

- TODO



#### 步骤5：进入容器

```shell
docker exec -it mysql bash
```



#### 步骤6：退出容器

```shell
exit
```



### 1.3 创建集群容器

#### （1）使用命令

#### （2）使用 docker  compose



## 2、Linux系统 -  MySQL安装和配置

### 2.1 MySQL 基本信息

```bash
- 安装目录： /usr/local/mysql
- 账户：root
- 密码：root
```



### 2.2  MySQL 安装和配置

- 步骤0：安装前的装备

```bash
- 添加 MySQL 组和 MySQL 用户，用于设置 MySQL 安装目录文件所有者和所属组
groupadd mysql
useradd -r -g mysql mysql

- 查看是否安装Mysql
chkconfig --list mysqld

- 切换到想要保存到的目录
mkdir /usr/local/download 
cd /usr/local/download/
```



- 步骤1：下载 MySQL（一般存放在执行本命令的目录下）

  wget [http://dev.MySQL.com/get/Downloads/MySQL-5.7/mysql-5.7.11-Linux-glibc2.5-x86_64.tar.gz](http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.11-Linux-glibc2.5-x86_64.tar.gz)

  

- 步骤2：解压二进制文件，更改 MySQL 目录名称，移动 MySQL 到/usr/local目录下

```bash
tar -zxvf mysql-5.7.11-Linux-glibc2.5-x86_64.tar.gz
mv mysql-5.7.11-linux-glibc2.5-x86_64 mysql
mv mysql /usr/local
```



- 步骤3：更改 MySQL 目录所属的组和用户，更改权限

```bash
cd /usr/local/mysql
chown -R mysql .
chgrp -R mysql .
```



- 步骤4：初始化 MySQL 配置表

```bash
mkdir data
yum -y install libaio.so.*
bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data

- 运行完上面3行命令后，此处会生成 MySQL 的密码，记下来
```



- 步骤5：将 MySQL 目录下除了data目录的所有文件，改回root用户所有，MySQL 用户只需作为 mysql/data/ 目录下所有文件的所有者

```bash
chown -R root .
chown -R mysql data
```



- 步骤6：复制配置文件，修改my.cnf关键配置

```bash
cp support-files/my-default.cnf /etc/my.cnf
vi /etc/my.cnf
```



- 步骤7：修改my.cnf内容（按下esc后，输入：wq 退出vim编辑器）

```bash
character-set-server=utf8
basedir = /usr/local/mysql
datadir = /usr/local/mysql/data
port = 3306
socket = /tmp/mysql.sock
```



- 步骤8：创建tmp目录，然后赋予 MySQL 权限

```bash
mkdir tmp
chown -R mysql:mysql tmp
```



- 步骤9：将mysqld服务加入开机自启动项

```bash
cp support-files/mysql.server /etc/init.d/mysql
chmod +x /etc/init.d/mysql
```



- 步骤10：把 MySQL 注册为开机启动的服务

```bash
chkconfig --add mysql
```



- 步骤11：查看是否添加成功

```bash
chkconfig --list mysql

显示结果为以下内容表示添加成功：
mysql 0:off 1:off 2:on 3:on 4:on 5:on 6:off
```



- 步骤12：开机自启，配置环境变量

```bash
（1）进入profile
vi /etc/profile

（2）按i编辑放在最后一行
# mysql
PATH=$PATH:/usr/local/mysql:/usr/local/mysql/bin
export PATH 

（3）退出vim之后，使其修改生效
source /etc/profile

（4）执行完可通过命令查看是否添加成功
echo $PATH
```



- 步骤13：第一次登录并修改密码

```bash
- 启动MySQL
service mysql start

- 登录 MySQL 服务
mysql -uroot -p

- 查看数据库
show databases;

- 使用数据库
use mysql

- 更改密码
alter user 'root'@'localhost' identified by 'tdcj@06300830';
update user set host='%' where user='root';
flush privileges;
```



- 步骤14：添加一个新用户

```bash
- 添加用户
grant all privileges on *.* to 'td'@'%' identified by 'td';
grant all privileges on *.* to 'cj'@'%' identified by 'cj';
grant all privileges on *.* to 'liweifa515'@'%' identified by 'root';
grant all privileges on *.* to 'jianan412'@'%' identified by 'root';

- 选择数据库
use mysql

- 查看用户
select host,user from user;
  +-----------+-----------+
  | host | user |
  +-----------+-----------+
  | % | td |
  | localhost | mysql.sys |
  | localhost | root |
  +-----------+-----------+ 

- 刷新配置
flush privileges;

- 退出mysql
quit
```



- 步骤15：停止firewalld服务（Centos从7开始默认用的是firewalld，这个是基于iptables的，虽然有iptables的核心，但是iptables的服务是没安装的）

```bash
sudo systemctl stop firewalld.service && sudo systemctl disable firewalld.service
```



- 步骤16：使用Navicat登录

```bash
- 用户名：td
- 密码：td
```



### 2.3 MySQL 启动和关闭

```bash
service mysql start
service mysql stop
service mysql restart
```



### 2.4 更改密码

（1）登录MySQL

```
mysql -u 用户名 -p
```

（2）选择数据库

```
use mysql;
```

（3）修改密码

```
set password for 用户名@localhost = password('密码'); 
```

（4）使配置生效

```
flush privileges;
```

（5）退出MySQL

```
quit;
```



### 2.5 root账户被删时，修改密码

（1）修改配置文件my.cnf

```
vim /etc/my.cnf
```

（2）在配置文件[mysqld]下添加语句，启动 MySQL 服务的时候跳过权限表认证

```
skip-grant-tables
```

（3）重启MySQL

```
service mysql restart
```

（4）用空密码的root 用户连接到MySQL

```
mysql -u root -p
```

（6）使用下列命令添加root账户

```mysql
use mysql;

insert into user set user='root',ssl_cipher='',x509_issuer='',x509_subject='';

flush privileges;

GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' IDENTIFIED BY 'tdcj@06300830' WITH GRANT OPTION; 

flush privileges;
```

（7）查看root账户的权限（xxx_priv：Y表示成功）

```
select * from mysql.user where user='root'\G;
```

（8）修改配置文件my.cnf

```
vim /etc/my.cnf
```

（8）在配置文件[mysqld]下注释语句

```
#skip-grant-tables
```

（10）重启MySQL

```
service mysql restart
```



## 3、Win系统 -  MySQL安装和配置

### 3.1 MySQL 基本信息

```bash
- 安装目录：E:\06_study\MySQL_5.7.19
- 账户：root
- 密码：root
```



### 3.2 MySQL 配置 （cmd命令窗口下执行）

- 步骤1：配置环境变量

```java
MYSQL_HOME=E:\06_study\MySQL_5.7.19\
Path=%MYSQL_HOME%\bin;
```



- 步骤2：在安装目录的<span style='color:red'>根目录</span>下创建目录 data
  E:\06_study\MySQL_5.7.19\data



- 步骤3：修改安装目录下的 my.ini 中的路径（有的版本没有就直接创建该文件）

```bash
####################配置文件开始###################
[client]
default-character-set = utf8

[mysql]
default-character-set = utf8

[mysql.server]
default-character-set = utf8

[mysqld_safe]
default-character-set = utf8

[mysqld]
port=3306
basedir  ="E:/06_study/MySQL_5.7.19"
datadir  ="E:/06_study/MySQL_5.7.19/data"
tmpdir   ="E:/06_study/MySQL_5.7.19/data"
socket   ="E:/06_study/MySQL_5.7.19/mysql.sock"
log-error="E:/06_study/MySQL_5.7.19/data/mysql_error.log"
character-set-server=utf8 
collation-server=utf8_general_ci 

#server_id = 2

#skip-locking
max_connections=100
table_open_cache=256
query_cache_size=1M

tmp_table_size=32M
thread_cache_size=8

default-storage-engine=InnoDB
innodb_data_home_dir="E:/06_study/MySQL_5.7.19/data/"
innodb_flush_log_at_trx_commit =1
innodb_log_buffer_size=128M
innodb_buffer_pool_size=128M
innodb_log_file_size=10M
innodb_thread_concurrency=16
innodb-autoextend-increment=1000
join_buffer_size = 128M
sort_buffer_size = 32M
read_rnd_buffer_size = 32M
max_allowed_packet = 32M
explicit_defaults_for_timestamp=true
sql-mode="STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION"
sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
####################配置文件结束###################
```



- 步骤4：在命令行中安装MySQL

```bash
# 切换目录
cd E:/06_study/MySQL_5.7.19/bin

# 初始化mysql
mysqld --initialize-insecure --user=mysql

# 执行安装mysql（安装成功显示Service successfully installed.）
mysqld install
```



- 步骤5：首次启动登录设置

```bash
- 启动mysql服务
net start mysql

- 登录mysql（第一次登录没有密码，直接回车）
mysql -u root -p

- 设置密码
set password for root@localhost = password('root');
set password for td@localhost = password('td');

- 刷新配置
flush privileges;
```



- 步骤6：设置开机自启

```bash
- 切换到bin目录
cd E:\06_study\MySQL_5.7.19\bin

- 执行命令
mysqld -nt --install
```



### 3.3 MySQL 启动和关闭

```bash
- 数据库的启动
net start mysql

- 数据库的关闭
net stop mysql
```



## 4、Mac系统 -  MySQL安装和配置

### 4.1 MySQL 基本信息

```bash
- 安装目录：/usr/local/
- 账户：root
- 密码：root
```



### 4.2 修改MySQL默认密码

- 步骤1：Mac系统 -> 系统偏好设置 -> mysql -> 在弹出页面中点击stop mysql server，关闭mysql服务

```bash
sudo /usr/local/mysql/support-files/mysql.server start
sudo /usr/local/mysql/support-files/mysql.server stop
sudo /usr/local/mysql/support-files/mysql.server restart
```

- 步骤2：进入终端，获取管理员权限

```bash
cd /usr/local/mysql/bin/
sudo s:u
```

- 步骤3：禁止mysql验证功能（回车后，mysql会自动重启，偏好设置中mysql的状态会变成running）

```bash
./mysqld_safe --skip-grant-tables &
```

- 步骤4：刷新配置

```bash
./mysql
FLUSH PRIVILEGES;
```

- 步骤5：修改密码

```bash
SET PASSWORD FOR 'root'@'localhost' = PASSWORD('你的新密码’);
```



### 4.3 解决MySQL和navicat下，表的中文乱码问题

- 步骤1：将安装目录下的my.cnf复制到 /etc文件夹下，开始编辑

```bash
vim /etc/my.cnf
```

- 步骤2：复制以下内容到my.cnf文件（esc保存文件，:wq退出vim）

```bash
# Example MySQL config file for medium systems. 
# 
# This is for a system with little memory (32M - 64M) where MySQL plays 
# an important part, or systems up to 128M where MySQL is used together with 
# other programs (such as a web server) 
# 
# MySQL programs look for option files in a set of 
# locations which depend on the deployment platform. 
# You can copy this option file to one of those 
# locations. For information about these locations, see: 
# http://dev.mysql.com/doc/mysql/en/option-files.html
# 
# In this file, you can use all long options that a program supports. 
# If you want to know which options a program supports, run the program 
# with the "--help" option. 
# The following options will be passed to all MySQL clients 
[client]
default-character-set=utf8
#password = your_password 
port = 3306 
socket = /tmp/mysql.sock 
# Here follows entries for some specific programs 
# The MySQL server 
[mysqld]
character-set-server=utf8
init_connect='SET NAMES utf8
port = 3306 
socket = /tmp/mysql.sock 
skip-external-locking 
key_buffer_size = 16M 
max_allowed_packet = 16M 
table_open_cache = 64 
sort_buffer_size = 512K 
net_buffer_length = 8K 
read_buffer_size = 256K 
read_rnd_buffer_size = 512K 
myisam_sort_buffer_size = 8M 
character-set-server=utf8 
init_connect='SET NAMES utf8' 
# Don't listen on a TCP/IP port at all. This can be a security enhancement, 
# if all processes that need to connect to mysqld run on the same host. 
# All interaction with mysqld must be made via Unix sockets or named pipes. 
# Note that using this option without enabling named pipes on Windows 
# (via the "enable-named-pipe" option) will render mysqld useless! 
# 
#skip-networking

# Replication Master Server (default) 
# binary logging is required for replication 
log-bin=mysql-bin

# binary logging format - mixed recommended 
binlog_format=mixed

# required unique id between 1 and 2^32 - 1 
# defaults to 1 if master-host is not set 
# but will not function as a master if omitted 
server-id = 1

# Replication Slave (comment out master section to use this) 
# 
# To configure this host as a replication slave, you can choose between 
# two methods : 
# 
# 1) Use the CHANGE MASTER TO command (fully described in our manual) - 
# the syntax is: 
# 
# CHANGE MASTER TO MASTER_HOST=<host>, MASTER_PORT=<port>, 
# MASTER_USER=<user>, MASTER_PASSWORD=<password> ; 
# 
# where you replace <host>, <user>, <password> by quoted strings and 
# <port> by the master's port number (3306 by default). 
# 
# Example: 
# 
# CHANGE MASTER TO MASTER_HOST='125.564.12.1', MASTER_PORT=3306, 
# MASTER_USER='joe', MASTER_PASSWORD='secret'; 
# 
# OR 
# 
# 2) Set the variables below. However, in case you choose this method, then 
# start replication for the first time (even unsuccessfully, for example 
# if you mistyped the password in master-password and the slave fails to 
# connect), the slave will create a master.info file, and any later 
# change in this file to the variables' values below will be ignored and 
# overridden by the content of the master.info file, unless you shutdown 
# the slave server, delete master.info and restart the slaver server. 
# For that reason, you may want to leave the lines below untouched 
# (commented) and instead use CHANGE MASTER TO (see above) 
# 
# required unique id between 2 and 2^32 - 1 
# (and different from the master) 
# defaults to 2 if master-host is set 
# but will not function as a slave if omitted 
#server-id = 2 
# 
# The replication master for this slave - required 
#master-host = <hostname> 
# 
# The username the slave will use for authentication when connecting 
# to the master - required 
#master-user = <username> 
# 
# The password the slave will authenticate with when connecting to 
# the master - required 
#master-password = <password> 
# 
# The port the master is listening on. 
# optional - defaults to 3306 
#master-port = <port> 
# 
# binary logging - not required for slaves, but recommended 
#log-bin=mysql-bin

# Uncomment the following if you are using InnoDB tables 
#innodb_data_home_dir = /usr/local/mysql/data 
#innodb_data_file_path = ibdata1:10M:autoextend 
#innodb_log_group_home_dir = /usr/local/mysql/data 
# You can set .._buffer_pool_size up to 50 - 80 % 
# of RAM but beware of setting memory usage too high 
#innodb_buffer_pool_size = 16M 
#innodb_additional_mem_pool_size = 2M 
# Set .._log_file_size to 25 % of buffer pool size 
#innodb_log_file_size = 5M 
#innodb_log_buffer_size = 8M 
#innodb_flush_log_at_trx_commit = 1 
#innodb_lock_wait_timeout = 50

[mysqldump] 
quick 
max_allowed_packet = 16M

[mysql] 
no-auto-rehash 
# Remove the next comment character if you are not familiar with SQL 
#safe-updates 
default-character-set=utf8

[myisamchk] 
key_buffer_size = 20M 
sort_buffer_size = 20M 
read_buffer = 2M 
write_buffer = 2M

[mysqlhotcopy] 
interactive-timeout
```

- 步骤3：进入MySQL数据库，输入电脑密码

```bash
mysql -u root -p
```

- 步骤4：在MySQL的数据库界面，使用数据库

```bash
USE 数据库名;
```

- 步骤5：选择表
- 步骤6：查看该表字符集

```bash
show variables like ‘%char%’;
```



## 5、报错集锦

### 5.1 导入数据报错，2006 - MySQL server has gone away

- 问题描述：导入数据报错，2006 - MySQL server has gone away

- 解决方法：更改max_allowed_packet的值（如：max_allowed_packet=16M），然后重启Mysql

```java
- Win系统，在my.ini配置文件中更改（Mysql目录下）
- Mac系统，在my.cnf配置文件中更改（/private/etc/my.cnf）
```



### 5.2  MySQL：ERROR 1040: Too many connections

- 问题描述：连接数满
- 解决方法：修改MySQL配置文件

```shell
Win：安装根目录下 my.ini
Linux：/etc/my.cnf

# MySQL 最大连接数
max_connections=3600
```



### 5.3 java.sql.SQLException: The server time zone value 'xxxx' is unrecognized or represents more than one time zone

- 解决方法：jdbc.properties 文件中 url 后设置时区

```properties
jdbc.url = jdbc:mysql:///JavaWeb_7.1_Mybatis?serverTimezone=UTC
```



# 第一章 MySQL 语法

## 0、约束

### （1）主键约束

```sql
# 约束的作用: 对表中的数据进行进一步的限制，从而保证数据的正确性、有效性、完整性.
# 违反约束的不正确数据，将无法插入到表中

# 主键约束
# 特点：不可重复、唯一、非空
# 作用：用来表示数据库中的每一条记录

# ------------------------------------------------------

# 添加主键约束
#（1）建表时，添加主键约束
# 字段名 字段类型 primary key auto_increment,

# auto_increment：主键自增，字段类型必须是整数类型，默认的开始值是1

# delete 和 truncate 对自增长的影响
# delete：只是删除表中所有数据，对自增没有影响
# truncate：将整个表删除掉，然后创建一个新的表，自增的主键，重新从1开始

# 自定义主键自增的起始值
create table emp2
(
    id   int primary key auto_increment,
    name varchar(20),
    sex  char(1)
) auto_increment = 100;

#（2）建表后，插入主键约束
# alter table 表名 add primary key(主键列名);

# ------------------------------------------------------

# 删除主键约束
# alter table 表名 drop primary key;
```



### （2）非空约束

```sql
# 非空约束
# 特点：某一列不予许为空

# 语法格式
# 字段名 字段类型 not null
```



### （3）唯一约束

```sql
# 唯一约束
# 特点：表中的某一列的值不能重复(对 null 不做唯一的判断)

# 语法格式
# 字段名 字段类型 unique

# 添加唯一约束
create table emp3
(
    id   int primary key auto_increment,
    name varchar(20) unique,
    sex  char(1)
);

#【区别】主键约束与唯一约束
# 主键约束，唯一且不能够为空
# 唯一约束，唯一但是可以为空
# 一个表中只能有一个主键，但是可以有多个唯一约束
```



### （4）外键约束

```sql
# 外键：在从表中与主表的主键对应的那个字段
# 优点：外键约束可以让两张表之间产生一个对应关系，从而保证主从表的引用的完整性

# 创建外键约束
# （1）新建表时添加外键
# constraint 外键约束名称 foreign key(外键字段名) references 主表名(主键字段名)

# （2）已有表添加外键
# alter table 从表 add constraint 外键约束名称 foreign key(外键字段名) references 主表(主键字段名);

# 删除外键约束
# alter table 从表 drop foreign key 外键约束名称;


# 注意事项
# 从表外键类型必须与主表主键类型一致，否则创建失败
# 添加数据时，应该先添加主表中的数据
# 删除数据时，应该先删除从表中的数据
```



### （5）默认值约束

```sql
# 默认值约束
# 用来指定某列的默认值

# 语法格式
# 字段名 字段类型 default 默认值
```



## 1、DDL（数据定义语言）

### 1.1 操作库

#### （1）创建数据库

```mysql
# 创建数据库
# create database 数据库名;
create database if not exists `td_mysql_db` default character set utf8mb4 collate utf8mb4_unicode_ci;
```



#### （2）选择数据库

```mysql
# 选择数据库
# use 数据库名;
use td_mysql_db;
```



#### （3）删除数据库

```mysql
# 删除数据库
# drop database 数据库名;
drop database td_mysql_db;
```



### 1.2 操作表

#### （1）创建表

```mysql
# 创建表
# create table 表名 (列名 列类型);
CREATE TABLE IF NOT EXISTS `tb_admin_info`
(
    `id`          INT PRIMARY KEY AUTO_INCREMENT COMMENT '序号',
    `username`    VARCHAR(20) NOT NULL COMMENT '登录账户',
    `pwd`         VARCHAR(20) NOT NULL COMMENT '密码',
    `sex`         VARCHAR(20) COMMENT '性别',
    `create_user` VARCHAR(20) COMMENT '创建人',
    `create_time` DATE COMMENT '创建时间',
    `update_user` VARCHAR(20) COMMENT '修改人',
    `update_time` TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
    `effective`   VARCHAR(1) COMMENT '是否有效（1有效 0无效）'
) COMMENT ='管理员信息管理表' ENGINE = InnoDB
                      DEFAULT CHARSET = utf8;
```

- 解析

```sql
- ``用于标注 表名和字段名
- ''用于标注 表和字段的 注释
- COMMENT 用于给表和字段标注注释
- PRIMARY KEY 关键字用于定义列为主键（可以使用多列来定义主键，列间以逗号分隔）
- AUTO_INCREMENT 定义列为自增的属性，一般用于主键，数值会自动加1
- NULL 表示该字段可以为空（默认不写就是为 NULL ）
- NOT NULL 表示该字段不能为空（添加记录时，如果该字段不输入任何数据，为NULL ，会报错）
- ENGINE 设置存储引擎
- CHARSET 设置编码
```



#### （2）修改表

```mysql
zhuyaoshi z# 修改表注释
ALTER TABLE tb_admin_info COMMENT '管理员表';

# 修改列注释
ALTER TABLE tb_admin_info MODIFY COLUMN username VARCHAR(100) COMMENT '用户名';

# 修改列类型（不带注释就会修改为无注释）
ALTER TABLE tb_admin_info MODIFY COLUMN pwd BIGINT;
```



#### （3）删除表

```mysql
# 删除表
# DROP TABLE 数据库名;
DROP TABLE tb_admin_info ;
```



#### （4）复制表

```mysql
#（1）只复制表结构到新表（带字段注释）
# create table 新表 select * from 旧表 where 1=2;
create table tb_admin_info1 select * from tb_admin_info where 1=2;

#（2）只复制表结构到新表（带表注释、字段注释）
# create table 新表 like 旧表;
create table tb_admin_info2 like tb_admin_info;

#（3）复制表结构及数据到新表（带字段注释）
# create table 新表 select * from 旧表;
create table tb_admin_info3 select * from tb_admin_info;

#（4）复制旧表的部分字段到新表（带数据、带字段注释）
# create table 新表 as ( select 旧表字段1, 旧表字段2 from 旧表);
create table tb_admin_info4 as ( select username, pwd from tb_admin_info);

#（5）旧表字段改名到新表（带数据、带字段注释）
# create table 新表 as (select id, 旧表字段1 as 新表字段1, 旧表字段2 as 新表字段2 from 旧表);
create table tb_admin_info5 as (select id, username as username5, pwd as pwd5 from tb_admin_info);

#（6）复制旧表的部分数据到新表（带数据、带字段注释）
# create table 新表 as ( select * from 旧表 where left(字段名,最左边的字符数) = '字段名的值匹配条件');
create table tb_admin_info6 as ( select * from tb_admin_info where left(username,2) = 'td');

# 创建新表的同时定义表中的字段信息（带数据、带字段注释）
create table tb_admin_info7 ( id integer not null auto_increment primary key) as ( select * from tb_admin_info);

```



#### （5）临时表

```
- 临时表只在当前连接可见，当关闭连接时，Mysql 会自动删除表并释放所有空间
- 如果使用了 MySQL 客户端程序连接来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然也可以手动销毁

- 临时表在 MySQL 3.23 版本中添加，如果 MySQL 版本低于 3.23 版本就无法使用 MySQL 的临时表
```



```mysql
# 创建临时表 - 通过查询其他表
# create temporary table 临时表名 as (select *  from 旧的表名 limit 0,10000);
create temporary table temp_tb_admin_info as (select *  from tb_admin_info limit 0,10000);

# 查询临时表
select * from temp_tb_admin_info;

# 删除临时表
drop table temp_tb_admin_info;
```



## 2、DML（数据操作语言）

### 2.0 数据类型

#### （1）数值类型

- 严格数值数据类型：INTEGER、SMALLINT、DECIMAL、NUMERIC
- 近似数值数据类型：FLOAT、REAL、DOUBLE、PRECISION

| 类型         | 大小                                     | 范围（有符号）                                               | 范围（无符号）                                               | 用途                |
| ------------ | ---------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------- |
| TINYINT      | 1 byte                                   | (-128，127)                                                  | (0，255)                                                     | 小整数值            |
| SMALLINT     | 2 bytes                                  | (-32 768，32 767)                                            | (0，65 535)                                                  | 大整数值            |
| MEDIUMINT    | 3 bytes                                  | (-8 388 608，8 388 607)                                      | (0，16 777 215)                                              | 大整数值            |
| INT或INTEGER | 4 bytes                                  | (-2 147 483 648，2 147 483 647)                              | (0，4 294 967 295)                                           | 大整数值            |
| BIGINT       | 8 bytes                                  | (-9,223,372,036,854,775,808，9 223 372 036 854 775 807)      | (0，18 446 744 073 709 551 615)                              | 极大整数值          |
| FLOAT        | 4 bytes                                  | (-3.402 823 466 E+38，-1.175 494 351 E-38)，<br/>0，<br/>(1.175 494 351 E-38，3.402 823 466 351 E+38) | 0，(1.175 494 351 E-38，3.402 823 466 E+38)                  | 单精度<br/>浮点数值 |
| DOUBLE       | 8 bytes                                  | (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，<br/>0，<br/>(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) | 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) | 双精度<br/>浮点数值 |
| DEC或DECIMAL | 对DECIMAL(M,D) ，如果M>D，为M+2否则为D+2 | 依赖于M和D的值                                               | 依赖于M和D的值                                               | 小数值              |



#### （2）日期/时间类型

- 每个时间类型有一个有效值范围和一个"零"值，当指定不合法的MySQL不能表示的值时使用"零"值
- 特别的：TIMESTAMP类型有专有的自动更新特性

| 类型      | 大小（bytes） | 范围                                                         | 格式                | 用途                     |
| --------- | ------------- | ------------------------------------------------------------ | ------------------- | ------------------------ |
| DATE      | 3             | 1000-01-01/9999-12-31                                        | YYYY-MM-DD          | 日期值                   |
| TIME      | 3             | '-838:59:59'/'838:59:59'                                     | HH:MM:SS            | 时间值或持续时间         |
| YEAR      | 1             | 1901/2155                                                    | YYYY                | 年份值                   |
| DATETIME  | 8             | 1000-01-01 00:00:00/9999-12-31 23:59:59                      | YYYY-MM-DD HH:MM:SS | 混合日期和时间值         |
| TIMESTAMP | 4             | 1970-01-01 00:00:00/2038结束时间是第 **2147483647** 秒，北京时间 **2038-1-19 11:14:07**，格林尼治时间 2038年1月19日 凌晨 03:14:07 | YYYYMMDD HHMMSS     | 混合日期和时间值，时间戳 |


#### （3）字符类型

- char(n) 和 varchar(n) 中括号中 n 代表字符的个数，比如 CHAR(30) 就可以存储 30 个字符

- BLOB 类型：TINYBLOB、BLOB、MEDIUMBLOB、LONGBLOB（区别在于可容纳存储范围不同）
- TEXT 类型：TINYTEXT、TEXT、MEDIUMTEXT、LONGTEXT

| 类型       | 大小                  | 格式       | 用途                            |
| ---------- | --------------------- | ---------- | ------------------------------- |
| CHAR       | 0-255 bytes           | char(n)    | 定长字符串                      |
| VARCHAR    | 0-65535 bytes         | varchar(n) | 变长字符串                      |
| TINYBLOB   | 0-255 bytes           |            | 不超过 255 个字符的二进制字符串 |
| TINYTEXT   | 0-255 bytes           |            | 短文本字符串                    |
| BLOB       | 0-65 535 bytes        |            | 二进制形式的长文本数据          |
| TEXT       | 0-65 535 bytes        |            | 长文本数据                      |
| MEDIUMBLOB | 0-16 777 215 bytes    |            | 二进制形式的中等长度文本数据    |
| MEDIUMTEXT | 0-16 777 215 bytes    |            | 中等长度文本数据                |
| LONGBLOB   | 0-4 294 967 295 bytes |            | 二进制形式的极大文本数据        |
| LONGTEXT   | 0-4 294 967 295 bytes |            | 极大文本数据                    |



### 3.1 插入数据 - 增

```mysql
# 插入数据 - 一条
# insert into 表名 (字段1, 字段2) values (字段1的值, 字段2的值);
insert into tb_admin_info (username, pwd, sex) values ('TD', '123','男');

# 插入数据 - 多条
# insert into 表名 (字段1, 字段2) values (字段1的值, 字段2的值), (字段1的值, 字段2的值) ;
insert into tb_admin_info (username, pwd, sex) values ('TD', '123','男'), ('CJ', '123','男'), ('Jan', '123', '男'), ('Shirley', '123', '女');
```



### 3.2 修改数据 - 改

```sql
# 修改数据
# 不带条件的修改
# update 表名 set 列名 = 值;

# 带条件的修改
# update 表名 set 列名 = 值 where 条件表达式：字段名 = 值;
```



### 3.3 删除数据 - 删

#### （1）单表删除

```sql
# 1、delete 删除整张表的数据，不会释放表所占用的空间，并且操作是可以撤销
# 删除所有数据
# delete from 表名;

# 指定条件 删除数据
# delete from 表名 where 字段名 = 值;

# 2、drop 删除表的结构，以及被依赖的约束(constrain)、触发器(trigger)、索引(index)
# drop table 数据库名;
drop table tb_admin_info ;

# 判断表是否存在， 存在的话就删除,不存在就不执行删除
drop table if exists tb_admin_info;

# 3、truncate 删除内容、释放空间但不删除表的结构(定义)
# truncate table 表名;


# 注意
# truncate 只能对table
# delete 可以是 table 和 view
# 执行速度：drop > truncate > delete
```

#### （2）级联删除

```sql
# 级联删除：删除主表数据的同时，也删除掉从表数据

# 在建表的时候，添加级联删除（ON DELETE CASCADE）
CREATE TABLE employee
(
    eid     INT PRIMARY KEY AUTO_INCREMENT,
    ename   VARCHAR(20),
    age     INT,
    dept_id INT,
    CONSTRAINT emp_dept_fk FOREIGN KEY (dept_id) REFERENCES department (id)
        ON DELETE CASCADE -- 添加级联删除
);
```



## 3、DQL（数据查询语言）

### 3.1 操作数据（单表查询）

#### （1）简单查询

```sql
# 查询表的所有数据
# select * from 表名;
select * from tb_admin_info;

# 查询表字段数据
# select 字段1,字段2,字段3 from 表名;
select id,username,pwd,create_user,create_time,update_user,update_time,effective from tb_admin_info;

# 别名查询
select id, username as '用户名', pwd as '密码' from tb_admin_info;

# 去重查询 distinct
select distinct username from tb_admin_info;

# 运算查询 (查询结果参与运算)
select id + 1, username from tb_admin_info;

# 获取最近的 id 值
#（1）查询和插入所使用的Connection对象必须是同一个才可以，否则返回值是不可预料的
#（2）LAST_INSERT_ID 是与table无关的，如果向表a插入数据后，再向表b插入数据，LAST_INSERT_ID返回表b中的Id值
#（3）假如你使用一条INSERT语句插入多个行，  LAST_INSERT_ID() 只返回插入的第一行数据时产生的值
#（4）假如你使用 INSERT IGNORE而记录被忽略，则AUTO_INCREMENT 计数器不会增量，而 LAST_INSERT_ID() 返回0, 这反映出没有插入任何记录。
select last_insert_id();
```



#### （2）条件查询（Where）

| 操作符 | 描述                                           |
| ------ | ---------------------------------------------- |
| =      | 等号，检测两个值是否相等                       |
| <>, != | 不等于，检测两个值是否相等                     |
| >      | 大于号，检测左边的值是否大于右边的值           |
| <      | 小于号，检测左边的值是否小于右边的值           |
| >=     | 大于等于号，检测左边的值是否大于或等于右边的值 |
| <=     | 小于等于号，检测左边的值是否小于或等于右边的值 |

```mysql
# 1、比较运算符
#（1） >    <     >=      <=     =    <>    !=
#    大于、小于、大于等于、小于等于、等于、不等于、不等于

#（2）between ... and ... 在某一区间的值
# select * from 表名 where 字段 between xx and xx;

#（3）in 集合表示多个值，使用逗号分隔，in中的每个数据都会作为一次条件，只要满足条件就会显示
# select * from 表名 where 字段 in ('xx','xx');

#（4）Like子句 - 模糊查询
# select * from 表名 where 条件1 like '%值%';
select * from tb_admin_info where username like '%T%'; -- 查看包含T的
select * from tb_admin_info where username like 'T%';  -- 查询 T 开头的
select * from tb_admin_info where username like '%T';  -- 查询 T 结尾的
select * from tb_admin_info where username like 'T';   -- 查询值为 T 的

# select * from 表名 where 条件1 like '_值_';
select * from tb_admin_info where username like '_t_';    -- 该值有三位且中间字母是 t 的
select * from tb_admin_info where username like '_t';     -- 该值有两位且结尾字母是 t 的
select * from tb_admin_info where username like 't_';     -- 该值有两位且开头字母是 t 的

#（5）查询某一列为 NULL 的值
# select * from 表名 where 字段 is null;
select * from tb_admin_info where effective is null;


# 2、逻辑运算符
#（1）多个条件同时成立（and 或者 &&）
# select * from 表名 where 条件1 = '值' and 条件2 = '值';
select * from tb_admin_info where username = 'TD' and pwd = '123';
# select * from 表名 where 条件1 = '值' && 条件2 = '值';
select * from tb_admin_info where username = 'TD' && pwd = '123';

#（2）多个条件任一成立（or 或者 ||）
# select * from 表名 where 条件1 = '值' or 条件2 = '值';
select * from tb_admin_info where username = 'TD' or username = 'CJ';
# select * from 表名 where 条件1 = '值' || 条件2 = '值';
select * from tb_admin_info where username = 'TD' || username = 'CJ';

#（3）不成立，取反（not）
select * from tb_admin_info where username not in ('TD');
select * from tb_admin_info where id not between 2 and 3;
```



#### （3）排序查询（Order by）

```sql
# asc：升序（默认，可以省略不写）
# desc：降序

# 1、单列排序：只按照某一个字段进行排序
# select 字段1, 字段2 from 表名1, 表名2 order by 字段1, 字段2;
select * from tb_admin_info order by username ;

# select 字段1, 字段2 from 表名1, 表名2 order by 字段1, 字段2 asc;
select * from tb_admin_info order by username asc ;

# select 字段1, 字段2 from 表名1, 表名2 order by 字段1, 字段2 desc;
select * from tb_admin_info order by username desc ;

# 2、组合排序：同时对多个字段进行排序, 如果第一个字段相同 就按照第二个字段进行排序,以此类推
select * from tb_admin_info order by username desc, id desc ;

# ---------------------------------------------------------------------------------

#【待验证】拼音排序：如果字符集采用的是 gbk(汉字编码字符集)，直接在查询语句后边添加 ORDER BY
select * from tb_admin_info order by username desc ;

#【待验证】拼音排序：如果字符集采用的是 utf8(万国码)，需要先对字段进行转码然后排序
select * from tb_admin_info order by CONVERT(username using gbk) desc ;
```



#### （4）聚合函数

```sql
# select 聚合函数(字段名) from 表名;

# count(字段) 统计指定列不为NULL的记录行数
# sum(字段)   计算指定列的数值和
# max(字段)   计算指定列的最大值
# min(字段)   计算指定列的最小值
# avg(字段)   计算指定列的平均值

# -----------------------------------------------------

# 1、count(字段) 统计指定列不为NULL的记录行数
#（1）1与 * 效果一样
select COUNT(1) from tb_admin_info;
select COUNT(*) from tb_admin_info;

#（2）统计表中某个字段的记录条数
select COUNT(username) from tb_admin_info;

#（3）count函数忽略了空值，所以使用时注意不要使用带有null的列进行统计
```



#### （5）分组查询

```sql
# 分组查询：使用 group by 语句,对查询的信息进行分组,相同数据作为一组（一般和聚合函数一起使用）
# select 分组字段/聚合函数 from 表名 group by 分组字段 [having 条件];

select sex from tb_admin_info group by sex;
select count(sex),sex from tb_admin_info group by sex;

# 在分组后，对数据进行过滤，使用关键字 having，作用类似于where条件
# 查询平均薪资大于6000的部门
# select dept_name, avg(salary)
# from emp
# where dept_name is not null
# group by dept_name
# having avg(salary) > 6000;

# ---------------------------------------------------------
#【区别】where 与 having
# where 进行分组前的过滤
# where 后面不能写聚合函数

# having 是分组后的过滤
# having 后面可以写聚合函数
```



（6）限制查询（Limit）

```sql
# 通过 limit 指定查询多少行数据，限制返回的查询结果的行数

# 参数说明
# select * : 返回所有记录
# limit N : 返回 N 条记录
# offset M : 起始行数, 从0开始记数, 如果省略，则默认为0
# limit N,M : 相当于 limit M offset N , 从第 N 条记录开始, 返回 M 条记录

# select 字段1,字段2 from 表名 where 条件1,条件2 order by 字段3,字段4 desc limit n offset m ;
# select 字段1,字段2 from 表名 where 条件1,条件2 order by 字段3,字段4 desc limit n, m ;

# 查询前5条
select * from tb_admin_info limit 0,5;

# 从第4条开始,查询6条
select * from tb_admin_info limit 3,6;

# 分页公式：起始索引 = (当前页 - 1) * 每页条数
# 每页显示3条数据
select * from tb_admin_info limit 0,3;  -- 第 1 页
select * from tb_admin_info limit 3,3;  -- 第 2 页
select * from tb_admin_info limit 6,3;  -- 第 3 页
```



### 3.2 操作数据（多表查询）

- 内连接：inner join，只获取两张表中，交集部分的数据.
- 左外连接：left join，以左表为基准，查询左表的所有数据，以及与右表有交集的部分
- 右外连接：right join，以右表为基准，查询右表的所有的数据，以及与左表有交集的部分

#### （1）交叉连接查询（笛卡尔积）

```sql
# 交叉连接查询，会产生笛卡尔积，得到2个表的数据的乘积
# select 字段名 from 表1, 表2;
```

#### （2）内连接查询

```sql
# 内连接的特点：通过指定的条件去匹配两张表中的数据，匹配上就显示，匹配不上就不显示
# 比如通过: 从表的外键 = 主表的主键 方式去匹配

# -------------------------------------------------------------------

# 隐式内连接
# from子句后面直接写 多个表名 使用where指定连接条件
# select 字段名 from 左表, 右表 where 连接条件;

# 查询所有商品信息和对应的分类信息
# select * from products,category where category_id = cid;

# -------------------------------------------------------------------

# 显式内连接
# 使用 inner join ...on（inner 可省略）
# select 字段名 from 左表 inner join 右表 on 条件;

# 查询所有商品信息和对应的分类信息
# select * from products p inner join category c on p.category_id = c.cid;
```

#### （3）外连接查询

```sql
# 左外连接的特点
# 以左表为基准，匹配右边表中的数据，如果匹配的上，就展示匹配到的数据
# 如果匹配不到，左表中的数据正常展示，右边的展示为null

# 使用 left outer join（outer 可以省略）
# select 字段名 from 左表 left outer join 右表 on 条件;
# select * from category c left join products p on c.`cid`= p.`category_id`;

# -------------------------------------------------------------------

# 右外连接的特点
# 以右表为基准，匹配左边表中的数据，如果能匹配到，展示匹配到的数据
# 如果匹配不到，右表中的数据正常展示，左边展示为null

# 使用 right outer join（outer 可以省略）
# select 字段名 from 左表 right outer join 右表 on 条件;
# select * from products p right join category c on p.`category_id` = c.`cid`;
```



#### （4）联合查询（Union）

```sql
# union 左右两边的列的数量要一样，一般是两个表有相同的列
# all: 可选，返回所有结果集，包含重复数据
# distinct: 可选，删除结果集中重复的数据（默认情况下 union 操作符已经删除了重复数据，所以 distinct 修饰符对结果没影响）
# select 字段1, 字段2 from 表1 where 条件1 = '' union/all/distinct select 字段1, 字段2 from 表2 where 条件2 = '';

# union 语句：用于将不同表中相同列中查询的数据展示出来（不包括重复数据）
# select 列名称 from 表名称 union select 列名称 from 表名称 order by 列名称;
select id, username, pwd from tb_admin_info union select id, username, pwd from tb_admin_info order by username;
select id, username, pwd from tb_admin_info union select id, username, pwd from tb_admin_info order by username;

# union all 语句：用于将不同表中相同列中查询的数据展示出来（包括重复数据）
# select 列名称 from 表名称 union all select 列名称 from 表名称 order by 列名称;
select id, username, pwd from tb_admin_info union all select id, username, pwd from tb_admin_info order by username;
```



#### （5）子查询

```sql
# 子查询概念
# 一条select 查询语句的结果，作为另一条 select 语句的一部分

# 子查询的特点
# 子查询必须放在小括号中
# 子查询一般作为父查询的查询条件使用

# 子查询常见分类
# where型子查询：将子查询的结果，作为父查询的比较条件
# from型子查询：将子查询的结果，作为一张表，提供给父层查询使用
# exists型子查询：子查询的结果是单列多行，类似一个数组，父层查询使用 IN 函数，包含子查询的结果

# -------------------------------------------------------------------

# 子查询的结果作为查询条件
# select 查询字段 from 表 where 字段=（子查询）;

# 将最高价格作为条件,获取商品信息
# select * from products where price = (select max(price) from products);

# -------------------------------------------------------------------

# 子查询的结果作为一张表
# 当子查询作为一张表的时候，需要起别名，否则无法访问表中的字段
# select 查询字段 from （子查询）表别名 where 条件;

# select p.`pname`, p.`price`, c.cname
# from products p
#          inner join (select * from category) c on p.`category_id` = c.cid
# where p.`price` > 500;

# -------------------------------------------------------------------


# 子查询总结
# 1. 子查询如果查出的是一个字段(单列)， 那就在where后面作为条件使用
# 2. 子查询如果查询出的是多个字段(多列)，就当做一张表使用(要起别名)
```



## 4、DCL（数据控制语言）

### 4.1 创建用户

#### 方式 1：使用 create user 语句创建用户

```sql
# create user '用户名'@'主机名' identified by '密码';
create user 'td'@'localhost' identified by 'td';

# % 表示用户可以在任意电脑登录 mysql 服务器
create user 'cj'@'%' identified by 'cj';
```

#### 方式 2：使用 insert 语句新建用户

```sql
# 可以使用 insert 语句将用户的信息添加到 mysql.user 表中，但必须拥有对 mysql.user 表的 insert 权限
# 通常 insert 语句只添加 host、user、authentication_string 这3个字段的值
# mysql 5.7+，user 表中的密码字段为authentication_string
# mysql 5.7-，user 表中的密码字段为 password
insert into mysql.user(host, user, authentication_string, ssl_cipher, x509_issuer, x509_subject)
values ('localhost', 'test1', password('test1'), '', '', '');
```

#### 方式 3：使用 grant 语句新建用户

```sql
# 权限：create、alter、select、insert、update（授予所有的权限则使用 all）
# grant 权限 1, 权限 2... on 数据库名.表名 to '用户名'@'主机名' identified by '密码';

# 创建 查询权限 的用户
grant select on *.* to 'test2'@localhost identified by 'test2';
grant select on *.* to 'test3'@'%' identified by 'test3';

# 创建 所有权限 的用户
grant all on *.* to 'test4'@localhost identified by 'test4';
grant all on *.* to 'test5'@'%' identified by 'test5';
```



#### 授权

```sql
# 格式
# GRANT priv_type [(column_list)] ON database.table
# TO user [IDENTIFIED BY [PASSWORD] 'password']
# [, user[IDENTIFIED BY [PASSWORD] 'password']] ...
# [WITH with_option [with_option]...]

# 其中：
# priv_type 参数表示权限类型；
# columns_list 参数表示权限作用于哪些列上，省略该参数时，表示作用于整个表；
# database.table 用于指定权限的级别；
# user 参数表示用户账户，由用户名和主机名构成，格式是“'username'@'hostname'”；
# IDENTIFIED BY 参数用来为用户设置密码；
# password 参数是用户的新密码。

# WITH 关键字后面带有一个或多个 with_option 参数。这个参数有 5 个选项，详细介绍如下：
# GRANT OPTION：被授权的用户可以将这些权限赋予给别的用户；
# MAX_QUERIES_PER_HOUR count：设置每个小时可以允许执行 count 次查询；
# MAX_UPDATES_PER_HOUR count：设置每个小时可以允许执行 count 次更新；
# MAX_CONNECTIONS_PER_HOUR count：设置每小时可以建立 count 个连接;
# MAX_USER_CONNECTIONS count：设置单个用户可以同时具有的 count 个连接。

# MySQL 中可以授予的权限有如下几组：
# 列权限，和表中的一个具体列相关。例如，可以使用 UPDATE 语句更新表 students 中 name 列的值的权限。
# 表权限，和一个具体表中的所有数据相关。例如，可以使用 SELECT 语句查询表 students 的所有数据的权限。
# 数据库权限，和一个具体的数据库中的所有表相关。例如，可以在已有的数据库 mytest 中创建新表的权限。
# 用户权限，和 MySQL 中所有的数据库相关。例如，可以删除已有的数据库或者创建一个新的数据库的权限。

# 在 GRANT 语句中可用于指定权限级别的值有以下几类格式：
# *：表示当前数据库中的所有表。
# *.*：表示所有数据库中的所有表。
# db_name.*：表示某个数据库中的所有表，db_name 指定数据库名。
# db_name.tbl_name：表示某个数据库中的某个表或视图，db_name 指定数据库名，tbl_name 指定表名或视图名。
# db_name.routine_name：表示某个数据库中的某个存储过程或函数，routine_name 指定存储过程名或函数名。
# TO 子句：如果权限被授予给一个不存在的用户，MySQL 会自动执行一条 CREATE USER 语句来创建这个用户，但同时必须为该用户设置密码。
```

#### 权限类型说明（授予数据库权限时）

| 权限名称                       | 对应user表中的字段    | 说明                                                         |
| ------------------------------ | --------------------- | ------------------------------------------------------------ |
| SELECT                         | Select_priv           | 表示授予用户可以使用 SELECT 语句访问特定数据库中所有表和视图的权限。 |
| INSERT                         | Insert_priv           | 表示授予用户可以使用 INSERT 语句向特定数据库中所有表添加数据行的权限。 |
| DELETE                         | Delete_priv           | 表示授予用户可以使用 DELETE 语句删除特定数据库中所有表的数据行的权限。 |
| UPDATE                         | Update_priv           | 表示授予用户可以使用 UPDATE 语句更新特定数据库中所有数据表的值的权限。 |
| REFERENCES                     | References_priv       | 表示授予用户可以创建指向特定的数据库中的表外键的权限。       |
| CREATE                         | Create_priv           | 表示授权用户可以使用 CREATE TABLE 语句在特定数据库中创建新表的权限。 |
| ALTER                          | Alter_priv            | 表示授予用户可以使用 ALTER TABLE 语句修改特定数据库中所有数据表的权限。 |
| SHOW VIEW                      | Show_view_priv        | 表示授予用户可以查看特定数据库中已有视图的视图定义的权限。   |
| CREATE ROUTINE                 | Create_routine_priv   | 表示授予用户可以为特定的数据库创建存储过程和存储函数的权限。 |
| ALTER ROUTINE                  | Alter_routine_priv    | 表示授予用户可以更新和删除数据库中已有的存储过程和存储函数的权限。 |
| INDEX                          | Index_priv            | 表示授予用户可以在特定数据库中的所有数据表上定义和删除索引的权限。 |
| DROP                           | Drop_priv             | 表示授予用户可以删除特定数据库中所有表和视图的权限。         |
| CREATE TEMPORARY TABLES        | Create_tmp_table_priv | 表示授予用户可以在特定数据库中创建临时表的权限。             |
| CREATE VIEW                    | Create_view_priv      | 表示授予用户可以在特定数据库中创建新的视图的权限。           |
| EXECUTE ROUTINE                | Execute_priv          | 表示授予用户可以调用特定数据库的存储过程和存储函数的权限。   |
| LOCK TABLES                    | Lock_tables_priv      | 表示授予用户可以锁定特定数据库的已有数据表的权限。           |
| ALL 或 ALL PRIVILEGES 或 SUPER | Super_priv            | 表示以上所有权限/超级权限                                    |

#### 权限类型说明（授予表权限时）

| 权限名称                       | 对应user表中的字段 | 说明                                                       |
| ------------------------------ | ------------------ | ---------------------------------------------------------- |
| SELECT                         | Select_priv        | 授予用户可以使用 SELECT 语句进行访问特定表的权限           |
| INSERT                         | Insert_priv        | 授予用户可以使用 INSERT 语句向一个特定表中添加数据行的权限 |
| DELETE                         | Delete_priv        | 授予用户可以使用 DELETE 语句从一个特定表中删除数据行的权限 |
| DROP                           | Drop_priv          | 授予用户可以删除数据表的权限                               |
| UPDATE                         | Update_priv        | 授予用户可以使用 UPDATE 语句更新特定数据表的权限           |
| ALTER                          | Alter_priv         | 授予用户可以使用 ALTER TABLE 语句修改数据表的权限          |
| REFERENCES                     | References_priv    | 授予用户可以创建一个外键来参照特定数据表的权限             |
| CREATE                         | Create_priv        | 授予用户可以使用特定的名字创建一个数据表的权限             |
| INDEX                          | Index_priv         | 授予用户可以在表上定义索引的权限                           |
| ALL 或 ALL PRIVILEGES 或 SUPER | Super_priv         | 所有的权限名                                               |

#### 权限类型说明（授予列权限时）

```
权限类型的值只能指定为 SELECT、INSERT 和 UPDATE，同时权限的后面需要加上列名列表 column-list
```



### 4.2 查看用户

```sql
# 查看所有用户信息和权限
select * from mysql.user;

# 查看某个用户的权限信息
# show grants for '用户名'@'主机名/主机ip';
show grants for 'root'@'localhost';
```



### 4.3 修改用户

```sql
# rename user <旧用户> to <新用户>
# 必须拥有 mysql 数据库的 update 权限或全局 create user 权限
rename user 'test1'@'localhost' to 'test2'@'localhost';
```



### 4.4 删除用户

```sql
# 使用 drop user 语句删除普通用户
# drop user '用户名'@'主机名';

# 使用 delete 语句删除普通用户
# delete from mysql.user where host='主机名' and user='用户名';
```



## 5、索引

### 5.1 创建索引

#### （1）普通索引（index）

- 基于普通字段建立的索引，没有任何限制
- 加快对数据的访问速度
- 最经常出现在查询条件（where column=）或排序条件（orderby column）中的数据列创建索引

```mysql
# 方式1：使用create index 语句创建，在已有的表上创建索引
# create index 索引名 on 表名(列名[长度])
create index username on tb_admin_info(username);

# 方式2：修改表结构添加索引
# alter table 表名 add index 索引名 (列名);
alter table tb_admin_info add index username (username);
alter table tb_admin_info add index (pwd);
```



#### （2）唯一索引（unique）

- 与"普通索引"类似，不同的就是：索引字段的值必须唯一，但允许有空值 
- 在创建或修改表时追加唯一约束，就会自动创建对应的唯一索引，唯一索引可以保证数据记录的唯一性

- 特点：索引列的所有值都只能出现一次，必须唯一

```mysql
# 方式1：创建表的时候直接添加主键索引
# create table 表名(
#     列名 类型(长度),
#     unique [索引名称] (列名)
# );

# 方式2：使用create语句创建，在已有的表上创建索引
# create unique index 索引名 on 表名(列名(长度));

# 方式3：修改表结构添加索引
# alter table 表名 add unique (列名);
```



#### （3）主键索引 (primary key)

- 主键是一种特殊唯一性索引，不允许有空值
- 一个表可以没有主键，但最多只能有一个主键，并且主键值不能包含NULL
- 在创建或修改表时追加主键约束即可，每个表只能有一个主键，用于标识数据表中的某一条记录
- 索引文件存在.ibd文件中

```mysql
# 方式1：创建表的时候直接添加主键索引 (最常用)
# create table 表名(
#     字段名 类型 primary key,
# );

# 方式2：修改表结构，添加主键索引
# alter table 表名 add primary key (列名);
```



#### （4）复合索引

- 单一索引是指索引列为一列的情况，即新建索引的语句只实施在一列上
- 用户可以在多个列上建立索引，这种索引叫做组复合索引（组合索引）
- 复合索引可以代替多个单一索引，相比多个单一索引复合索引所需的开销更小。
- 索引同时有两个概念叫做窄索引和宽索引

```mysql
- 窄索引是指索引列为1-2列的索引
- 宽索引也就是索引列超过2列的索引

设计索引的一个重要原则就是能用窄索引不用宽索引，因为窄索引往往比组合索引更有效

# 创建复合索引
# create index <索引的名字> on tablename (字段名1，字段名2...);
# alter table tablename add index [索引的名字] (字段名1，字段名2...);
# create table tablename ( [...], index [索引的名字] (字段名1，字段名2...) );
```

- 复合索引使用注意事项

```mysql
何时使用复合索引？
- 要根据where条件建索引，注意不要过多使用索引，过多使用会对更新操作效率有很大影响。

如果表已经建立了(col1，col2)，就没有必要再单独建立（col1）
如果现在有(col1)索引，如果查询需要col1和col2条件，可以建立(col1,col2)复合索引，对于查询有一定提高

复合索引字段是有顺序的，在查询使用时要按照索引字段的顺序使用
# 匹配(name,age)组合索引，不匹配(age,name)
select * from user wherename=xx and age=xx
```



#### （5）全文索引

- 查询操作在数据量比较少时，可以使用like模糊查询，但是对于大量的文本数据检索，效率很低
- 如果使用全文索引，查询速度会比like快很多倍
- 在MySQL 5.6 以前的版本，只有MyISAM存储引擎支持全文索引
- 从MySQL 5.6开始MyISAM和InnoDB存储引擎均支持

```mysql
# 创建全文索引
# create fulltext index <索引的名字> on tablename (字段名);
# alter table tablename add fulltext [索引的名字] (字段名);
# create table tablename ( [...], fulltext key [索引的名字] (字段名) ;

# 查询全文索引
# select * from 表名 where match(全文索引名) against('全文索引字段的值');
select * from user where match(name) against('aaa');
```

- 全文索引使用注意事项

```mysql
- 全文索引必须在字符串、文本字段上建立
- 全文索引字段值必须在最小字符和最大字符之间的才会有效。（innodb：3-84；myisam：4-84）
- 全文索引字段值要进行切词处理，按 syntax 字符进行切割，例如 b+aaa，切分成b和aaa

- 全文索引匹配查询，默认使用的是等值匹配，例如a匹配a，不会匹配ab,ac。如果想匹配可以在布尔模式下搜索 a*
select * from user where match(name) against('a*' in boolean mode);
```



### 5.2 查看索引

```mysql
# 查看索引（key_name 的值）
# show index from 表名;
show index from tb_admin_info;
```



### 5.3 删除索引

```mysql
# alter table 表名 drop index 索引名;
alter table tb_admin_info drop index username;

# drop index 索引名 on 表名;
drop index username on tb_admin_info;
```



## 6、序列



## 7、函数

https://www.cnblogs.com/biehongli/p/12389418.html

```sql
length()：mysql里面的length()函数是一个用来获取字符串长度的内置函数。
char_length()：在mysql内置函数里面查看字符串长度的还有一个函数是char_length()。

这两个函数的区别是：
length()： 单位是字节，utf8编码下,一个汉字三个字节，一个数字或字母一个字节。gbk编码下,一个汉字两个字节，一个数字或字母一个字节。
char_length()：单位为字符，不管汉字还是数字或者是字母都算是一个字符。


-- 查看某个汉字占多数字节
select length('哈哈') from dual;
```



## 8、视图

### 8.1 视图概述

```
- 视图是一种虚拟表
- 视图建立在已有表的基础上, 视图赖以建立的这些表称为基表
- 向视图提供数据内容的语句为 SELECT 语句, 可以将视图理解为存储起来的 SELECT 语句. 4. 视图向用户提供基表数据的另一种表现形式
```



### 8.2 视图作用

- 权限控制时可以使用

```
- 比如,某几个列可以运行用户查询,其他列不允许,可以开通视图查询特定的列,起到权限控制的作用
```

- 简化复杂的多表查询

```
- 视图主要就是为了简化多表的查询
- 视图本身就是一条查询SQL,可以将一次复杂的查询构建成一张视图,用户只要查询视图就可以获取想要得到的信息(不需要再编写复杂的SQL)
```



### 8.3 视图的使用

#### （1）创建视图

```mysql
# 参数解析
# view：表示视图
# 视图名称在数据库中必须是唯一的，不能与其他表或视图同名
# column_list：可选参数，表示属性清单，指定视图中各个属性的名称，默认情况下，与SELECT语句中查询 的属性相同
# as：表示视图要执行的操作
# select语句：向视图提供数据内容

# 格式
# create view 视图名 [column_list] as select语句;

create view products_category_view as
select *
from products p
         left join category c on p.`category_id` = c.`cid`;
```

#### （2）查看视图

```mysql
# describe 视图名;
# desc 视图名;
```

#### （3）查询视图

```mysql
# 查询视图，当做一张只读的表操作就可以
# select * from 视图名;
```

#### （4）修改视图

```mysql
# alter view <视图名> as <select语句>;
```

#### （5）删除视图

```mysql
# drop view 视图名;
# drop view 视图名1, 视图名2;
```



### 8.4【区别】视图与表

```
- 视图是建立在表的基础上，表存储数据库中的数据，而视图只是做一个数据的展示
- 通过视图不能改变表中数据（一般情况下视图中的数据都是表中的列经过计算得到的结果,不允许更新）
- 删除视图，表不受影响，而删除表，视图不再起作用
```



## 9、存储过程

### 9.1 存储过程概述

```
- MySQL 5.0 版本开始支持存储过程
- 存储过程（Stored Procedure）是一种在数据库中存储复杂程序，以便外部程序调用的一种数据库对象
- 存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行
- 存储过程其实就是一堆 SQL 语句的合并，中间加入了一些逻辑控制
```



### 9.2 存储过程优缺点

```
优点:
- 存储过程一旦调试完成后，就可以稳定运行（前提是业务需求要相对稳定，没有变化）
- 存储过程减少业务系统与数据库的交互，降低耦合，数据库交互更加快捷（应用服务器与数据库服务器不在同一个地区）

缺点:
- 在互联网行业中，大量使用MySQL，MySQL的存储过程与Oracle的相比较弱，所以较少使用，并且互联网行业需求变化较快也是原因之一
- 尽量在简单的逻辑中使用，存储过程移植十分困难，数据库集群环境，保证各个库之间存储过程变更一致也十分困难。
- 阿里的代码规范里也提出了禁止使用存储过程，存储过程维护起来的确麻烦
```



### 9.3 存储过程的创建方式

- 数据准备

```sql
# 商品表
create table goods
(
    gid  int,
    name varchar(20),
    num  int -- 库存
);

# 订单表
create table orders
(
    oid   int,
    gid   int,
    price int -- 订单价格
);

# 向商品表中添加3条数据
insert into goods values (1, '奶茶', 20);
insert into goods values (2, '绿茶', 100);
insert into goods values (3, '花茶', 25);
```

#### 方式 1：简单存储过程

```sql
-- 声明语句结束符，可以自定义 一般使用$$
delimiter $$
-- 声明存储过程
create procedure 过程名称()
-- 开始编写存储过程
begin
    -- 要执行的操作
-- 存储过程结束
end $$

# 例子
# 查询所有商品数据
delimiter $$
create procedure goods_proc()
begin
    select * from goods;
end $$

# 调用存储过程
# call 存储过程名

# 查询goods表所有数据
call goods_proc;
```

#### 方式 2：创建接收参数的存储过程

```sql
# in 输入参数：表示调用者向存储过程传入值
# create procedure 存储过程名称(in 参数名 参数类型)

# 接收一个商品id, 根据id删除数据
delimiter $$
create procedure goods_proc02(in goods_id int)
begin
    delete from goods where gid = goods_id;
end $$

# 调用存储过程，传递参数
# 删除 id 为2的商品
call goods_proc02(2);
```

#### 方式 3：接收参数插入数据，并返回受影响的行数

```sql
# 变量赋值
# set @变量名=值

# out 输出参数：表示存储过程向调用者传出值
# out 变量名 数据类型

# 向订单表插入一条数据，返回1，表示插入成功
delimiter $$
create procedure orders_proc(in o_oid int, in o_gid int, in o_price int, out out_num int)
begin
    -- 执行插入操作
    insert into orders values (o_oid, o_gid, o_price);
    -- 设置 num 的值为 1
    set @out_num = 1;
    -- 返回 out_num的值
    select @out_num;
end $$

# 调用存储过程插入数据，获取返回值
call orders_proc(1, 2, 30, @out_num);
select * from orders;
```



### 9.4 查看存储过程

```sql
# 查看存储过程的状态
# show procedure status like 存储过程名;
show procedure status like 'goods_proc';
show procedure status like 'goods_proc02';
show procedure status like 'orders_proc';

# 查看存储过程的定义
# show create procedure 存储过程名;
show create procedure goods_proc;
show create procedure goods_proc02;
show create procedure orders_proc;
```



### 9.5 修改存储过程

```sql
# alter procedure 存储过程名 [特征 ...]
```



### 9.6 删除存储过程

```sql
# drop procedure [ if exists ] <过程名>
drop procedure goods_proc;
drop procedure if exists goods_proc02;
```



## 10、触发器

### 10.1 概述

```
- 触发器（trigger）是MySQL提供给程序员和数据分析员来保证数据完整性的一种方法，它是与表事件相关的特殊的存储过程，它的执行不是由程序调用，也不是手工启动，而是由事件来触发，比如当对一个表进行操作（insert，delete， update）时就会激活它执行

- 简单理解: 当执行一条sql语句的时候，这条sql语句的执行会自动去触发执行其他的sql语句

触发器创建的四个要素
1. 监视地点（table） 
2. 监视事件（insert/update/delete） 
3. 触发时间（before/after） 
4. 触发事件（insert/update/delete）
```



### 10.2 创建触发器

#### （1）语法格式

```sql
delimiter $
# 触发器名，在一个数据库中触发器名是唯一的
create trigger trigger_name
    # 触发的时机             监视的事件
    before / after    insert / update / delete
    # 触发器所在的表
    on table_name
    # 行触发器（固定写法，每一行受影响，触发事件都执行）
    for each row
begin
    # 触发事件
end $
```

#### （2）举例

```sql
# 数据准备
# 商品表
create table goods
(
    gid  int,
    name varchar(20),
    num  int -- 库存
);

# 向商品中添加一条数据
insert into goods values(1,'book',40);

# 创建触发器：在下订单的时候，对应的商品的库存量要相应的减少，卖出商品之后减少库存量
delimiter $
# 创建触发器
create trigger t1
    # 指定触发的时机,和要监听的表
    after insert
    # 触发器所在的表
    on orders
    # 行触发器
    for each row
begin
    # 触发后具体要执行的事件：订单+1 库存-1
    update goods set num = num - 1 where gid = 1;
end$
```



### 10.3 查看触发器

```sql
# 查看所有触发器信息
show triggers ;

# 在 triggers 表中查看部分触发器信息
# select * from information_schema.triggers where trigger_name= '触发器名';
select * from information_schema.triggers where trigger_name = 't1';
```



### 10.4 修改触发器

```sql
# 通过删除原触发器，再以相同的名称创建新的触发器
```



### 10.5 删除触发器

```sql
# drop trigger [if exists] [数据库名] <触发器名>
drop trigger td_mysql_db.t1;
drop trigger if exists td_mysql_db.t1;
```



## 11、数据库备份和还原

### 11.1 数据库备份

#### （1）命令行方式

```bash
# 1、进入到 Mysql 安装目录的 bin目录下

# 2、执行备份
# 格式
# mysqldump -u 用户名 -p 密码 数据库 > 文件路径

# 举例：备份 数据库 db2 中的数据到 D 盘的 db2.sql 文件中
mysqldump -uroot -p123456 db2 > D:/db2.sql
```



### 11.2 数据库还原

#### （1）命令行方式

```bash
# 1、登录到 Mysql 数据库

# 2、创建需要还原的 db2 数据库

# 3、选择 db2 数据库
use db2;

# 4、source 备份sql文件的地址
source D:/db2.sql
```



## 12、MySQL 开发开发规约



# 第二章 MySQL 架构原理

## 1、MySQL 简介

- IOE：IBM的服务器，Oracle数据库，EMC存储设备



### 1.1 MySQL 发展历史

- 1985年，ISAM（Index Sequential Access Method）存储引擎被研发

- 1996年，MySQL 1.0 发布
- 1996年10月，MySQL 3.1 发布
- 1999年 - 2000年，MySQL AB 公司成立
- 2000年04月，ISAM 存储引擎升级为 MyISAM 存储引擎，MySQL开源
- 2001年，MySQL 4.0 发布，集成了 InnoDB 存储引擎
- 2005年10月，MySQL 5.0 发布，提供了视图、存储过程等功能
- 2008年01月，MySQL AB 公司被 Sun 公司收购
- 2009年04月，Oracle 收购了 Sun 公司，进入了 Oracle MySQL 时代
- 2010年04月，MySQL 5.5 发布，分为社区版和企业版，InnoDB 成为了默认的存储引擎，增加表分区
- 2013年02月，MySQL 5.6.10 发布（正式版），对 InnoDB 引擎进行改造，提供全文检索能力
- 2015年10月，MySQL 5.7.9 发布（GA正式版）
- 2016年09月，MySQL 8.0 发布（开发班），增加了数据字典、账号权限角色表、InnoDB  增强、JSON 增强等
- 2018年04月，MySQL 8.0.11 发布（GA正式版）



### 1.2 MySQL 分支

![image-20211119200214716](image/image-20211119200214716.png)



## 2、MySQL 应用架构演变

### 阶段1：单机单库

#### （1）方案

```
- 一个简单的小型网站或者应用背后的架构可以非常简单, 数据存储只需要一个 MySQL Instance 就能满足数据读取和写入需求（这里忽略掉了数据备份的实例）
- 处于这个的阶段系统，一般会把所有的信息存到一个 MySQL Instance 里面
```

#### （2）瓶颈

```
- 数据量太大，超出一台服务器承受
- 读写操作量太大，超出一台服务器承受
- 这一台服务器挂了，应用也会挂掉（可用性差）
```



![image-20211119200511419](image/image-20211119200511419.png)



### 阶段2：主从架构

#### （1）方案

```
- 主要解决 架构V1.0 单机单库 下的高可用和读扩展问题
- 通过给 Instance 挂载从库解决读取的压力，主库宕机也可以通过主从切换保障高可用
- 在 MySQL 的场景下就是通过主从结构（双主结构也属于特殊的主从），主库抗写压力，通过从库来分担读压力，对于写少读多的应用，V2.0主从架构完全能够胜任
```

#### （2）瓶颈

```
- 当数据量太大，超出一台服务器承受
- 当写操作太大，超出一台M服务器承受
```

![image-20211119200920446](image/image-20211119200920446.png)

### 阶段3：分库分表

#### （1）方案

```
- 对于 V1.0和V2.0 遇到写入瓶颈和存储瓶颈时，可以通过水平拆分来解决，水平拆分和垂直拆分有较大区别
- 垂直拆分拆完的结果，每一个实例都是拥有全部数据的，而水平拆分之后，任何实例都只有全量的 1/n 的数据
- 以下图所示，将 Userinfo 拆分为 3个Sharding，每个 Sharding 持有总量的 1/3数据，3个Sharding数据的总和等于一份完整数据
```

#### （2）瓶颈

```
- 数据如何路由？（一般可以采用范围拆分，List拆分、Hash拆分等）
- 如何保持数据的一致性也是个难题
```

![image-20211119201303547](image/image-20211119201303547.png)

### 阶段4：云数据库

```
- 对于数据存储的 MySQL来说，如何让其成为一个saas（Software as a Service）是关键点
- MySQL 作为一个 saas 服务，服务提供商负责解决可配置性，可扩展性，多用户存储结构设计等这些疑难问题
```

![image-20211119201634272](image/image-20211119201634272.png)



## 3、MySQL 体系架构

![image-20211119232133860](image/image-20211119232133860.png)

### 3.1 网络连接层

#### （1）客户端连接器（Client Connectors）

- 提供与MySQL服务器建立的支持
- 目前几乎支持所有主流的服务端编程技术，例如常见的 Java、C、Python、.NET等，它们通过各自API技术与MySQL建立连接。



### 3.2 服务层（MySQL Server）

- 服务层是MySQL Server的核心，主要包含系统管理和控制工具、连接池、SQL接口、解析器、查询优化器和缓存六个部分

#### （1）连接池（Connection Pool）

- 负责存储和管理客户端与数据库的连接，一个线程负责管理一个连接。

#### （2）系统管理和控制工具（Management Services & Utilities）

- 例如备份恢复、安全管理、集群管理等

#### （3）SQL接口（SQL Interface）

- 用于接受客户端发送的各种SQL命令，并且返回用户需要查询的结果。
- 比如DML、DDL、存储过程、视图、触发器等。

#### （4）解析器（Parser）

- 负责将请求的SQL解析生成一个"解析树"，然后根据一些MySQL规则进一步检查解析树是否合法。

#### （5）查询优化器（Optimizer）

- 当“解析树”通过解析器语法检查后，将交由优化器将其转化成执行计划，然后与存储引擎交互。

#### （6）缓存（Cache&Buffer）

- 缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，权限缓存，引擎缓存等。
- 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。



### 3.3 存储引擎层（Pluggable Storage Engines）

- 存储引擎负责MySQL中数据的存储与提取，与底层系统文件进行交互。
- MySQL存储引擎是插件式的，服务器中的查询执行引擎通过接口与存储引擎进行通信，接口屏蔽了不同存储引擎之间的差异 
- 现在有很多种存储引擎，各有各的特点，最常见的是 MyISAM 和 InnoDB。



#### 3.3.1 存储引擎分类

- 在5.5版本之前默认采用 MyISAM 存储引擎，从5.5开始采用 InnoDB 存储引擎

```mysql
# 查看当前数据库支持的引擎信息
show engines;

（1）InnoDB：支持事务，具有提交，回滚和崩溃恢复能力，事务安全
（2）MyISAM：不支持事务和外键，访问速度快
（3）Memory：利用内存创建表，访问速度非常快，因为数据在内存，而且默认使用Hash索引，但是一旦关闭，数据就会丢失
（4）Archive：归档类型引擎，仅能支持insert和select语句
（5）Csv：以CSV文件进行数据存储，由于文件限制，所有列必须强制指定not null，另外CSV引擎也不支持索引和分区，适合做数据交换的中间表
（6）BlackHole: 黑洞，只进不出，进来消失，所有插入数据都不会保存
（7）Federated：可以访问远端MySQL数据库中的表。一个本地表，不保存数据，访问远程表内容。
（8）MRG_MyISAM：一组MyISAM表的组合，这些MyISAM表必须结构相同，Merge表本身没有数据，对Merge操作可以对一组MyISAM表进行操作
```



#### 3.3.2 存储引擎特性对比

![image-20211122165621941](image/image-20211122165621941.png)



### 3.4 系统文件层（File System）

- 该层负责将数据库的数据和日志存储在文件系统之上，并完成与存储引擎的交互，是文件的物理存储层。

- 主要包含日志文件，配置文件，数据文件，pid 文件，socket 文件等。

  

#### （1）日志文件

```mysql
# 错误日志（Error log）：默认开启
show variables like '%log_error%';

# 通用查询日志（General query log）：记录一般查询语句
show variables like '%general%';

# 二进制日志（binary log）
# 记录了对 MySQL 数据库执行的更改操作，并且记录了语句的发生时间、执行时长；但是它不记录 select、show 等不修改数据库的SQL
# 主要用于数据库恢复和主从复制
show variables like '%log_bin%';  # 是否开启
show variables like '%binlog%';   # 参数查看
show binary logs;                 # 查看日志文件

# 慢查询日志（Slow query log）：记录所有执行时间超时的查询SQL，默认是10秒
show variables like '%slow_query%';       # 是否开启
show variables like '%long_query_time%';  # 时长
```



#### （2）配置文件

- 用于存放MySQL所有的配置信息文件，比如 my.cnf、my.ini 等。



#### （3）数据文件

```sql
# db.opt 文件
记录这个库的默认使用的字符集和校验规则。

# frm 文件
存储与表相关的元数据（meta）信息，包括表结构的定义信息等，每一张表都会有一个frm 文件

# MYD 文件
MyISAM 存储引擎专用，存放 MyISAM 表的数据（data)，每一张表都会有一个.MYD 文件

# MYI 文件
MyISAM 存储引擎专用，存放 MyISAM 表的索引相关信息，每一张 MyISAM 表对应一个 .MYI 文件

# ibd文件和 IBDATA 文件，用于存放 InnoDB 的数据文件（包括索引）
InnoDB 存储引擎有两种表空间方式：独享表空间和共享表空间
- 独享表空间使用 .ibd 文件来存放数据，且每一张 InnoDB 表对应一个 .ibd 文件（默认为独享表空间）
- 共享表空间使用 .ibdata 文件，所有表共同使用一个（或多个，自行配置）.ibdata 文件

# ibdata1 文件
系统表空间数据文件，存储表元数据、Undo日志等 。

# ib_logfile0、ib_logfile1 文件
Redo log 日志文件
```



#### （4）pid 文件

- pid 文件是 mysqld 应用程序在 Unix/Linux 环境下的一个进程文件
- 和许多其他 Unix/Linux 服务端程序一样，它存放着自己的进程 id。



#### （5）socket 文件

- socket 文件也是在 Unix/Linux 环境下才有的，用户在 Unix/Linux 环境下客户端连接可以不通过TCP/IP 网络而直接使用 Unix Socket 来连接 MySQL



## 4、MySQL 运行机制

![image-20211119234937709](image/image-20211119234937709.png)

### 步骤1：建立连接（Connectors & Connection Pool）

- 通过客户端/服务器通信协议与MySQL建立连接。
- MySQL 客户端与服务端的通信方式/通信机制是 “ 半双工 ”

```
全双工：能同时发送和接收数据（例如平时打电话）
半双工：指的某一时刻，要么发送数据，要么接收数据，不能同时（例如早期对讲机）
单工：只能发送数据或只能接收数据（例如单行道）
```

- 对于每一个 MySQL 的连接，时刻都有一个线程状态来标识这个连接正在做什么

```mysql
# 查看用户正在运行的线程信息 - Info 字段只显示前100个字符（root用户能查看所有线程，其他用户只能看自己的）
show processlist;

# 查看用户正在运行的线程信息 - Info 字段完整信息
show full processlist;

# 字段释义
# id：线程ID（可以使用 kill id号；）
# user：启动这个线程的用户
# Host：发送请求的客户端的IP和端口号
# db：当前命令在哪个库执行

# Command：该线程正在执行的操作命令
  # Create DB：正在创建库操作
  # Drop DB：正在删除库操作
  # Execute：正在执行一个 PreparedStatement
  # Close Stmt：正在关闭一个 PreparedStatement
  # Query：正在执行一个语句
  # Sleep：正在等待客户端发送语句
  # Quit：正在退出
  # Shutdown：正在关闭服务器
  
# Time：表示该线程处于当前状态的时间，单位是秒

# State：线程状态
  # Updating：正在搜索匹配记录，进行修改
  # Sleeping：正在等待客户端发送新请求
  # Starting：正在执行请求处理
  # Checking table：正在检查数据表
  # Closing table : 正在将表中数据刷新到磁盘中
  # Locked：被其他查询锁住了记录
  # Sending Data：正在处理Select查询，同时将结果发送给客户端
  
# Info：一般记录线程执行的语句，默认显示前100个字符。
```



### 步骤2：查询缓存（Cache & Buffer）

- 这是MySQL的一个可优化查询的地方
- 如果开启了查询缓存且在查询缓存过程中查询到完全相同的SQL语句，则将查询结果直接返回给客户端

```mysql
# 查看查询缓存是否启用，空间大小，限制等
show variables like '%query_cache%'; 

# 查看更详细的缓存参数，可用缓存空间，缓存块，缓存多少等
show status like 'Qcache%';

# 即使开启查询缓存，以下SQL也不能缓存
- 查询语句使用 SQL_NO_CACHE
- 查询的结果大于 query_cache_limit 设置
- 查询中有一些不确定的参数，比如now()
```

- 如果没有开启查询缓存或者没有查询到完全相同的 SQL 语句则会由解析器进行语法语义解析，并生成“解析树”
- 缓存Select查询的结果和SQL语句
- 执行Select查询时，先查询缓存，判断是否存在可用的记录集，要求是否完全相同（包括参数值），这样才会匹配缓存数据命中。



### 步骤3：解析器（Parser）将客户端发送的SQL进行语法解析，生成"解析树"

- 预处理器根据一些MySQL规则进一步检查“解析树”是否合法（例如检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义）
- 最后生成新的“解析树”



### 步骤4：查询优化器（Optimizer）根据“解析树”生成最优的执行计划

- MySQL 使用很多优化策略生成最优的执行计划，可以分为两类：静态优化（编译时优化）、动态优化（运行时优化）

#### （1）优化策略 - 等价变换策略

- 基于联合索引，调整条件位置

```
5=5 and a>5 改成 a > 5
a < b and a=5 改成b>5 and a=5
```

#### （2）优化策略 - 优化 count、min、max 等函数

- InnoDB 引擎 min 函数只需要找索引最左边
- InnoDB 引擎 max 函数只需要找索引最右边
- MyISAM 引擎 count(*)，不需要计算，直接返回

#### （3）优化策略 - 提前终止查询

- 使用了limit查询，获取limit所需的数据，就不在继续遍历后面数据

#### （4）优化策略 - in的优化

- MySQL对in查询，会先进行排序，再采用二分法查找数据
- 比如where id in (2,1,3)，变成 in (1,2,3)



### 步骤5：查询执行引擎负责执行 SQL 语句

- 此时查询执行引擎会根据 SQL 语句中表的存储引擎类型，以及对应的API接口与底层存储引擎缓存或者物理文件的交互，得到查询结果并返回给客户端
- 若开启用查询缓存，这时会将SQL 语句和结果完整地保存到查询缓存（Cache&Buffer）中，以后若有相同的 SQL 语句执行则直接返回结果，如果返回结果过多，采用增量模式返回



# 第三章 MySQL 存储引擎 - InnoDB

- MySQL 5.5 版本开始默认使用 InnoDB 作为引擎，它擅长处理事务，具有自动崩溃恢复的特性，主要分为内存结构和磁盘结构



## 1、InnoDB 存储结构

### MySQL 5.7 + 

```
- 将 Undo日志表空间从共享表空间 ibdata 文件中分离出来，可以在安装 MySQL 时由用户自行指定文件大小和数量。
- 增加了 temporary 临时表空间，里面存储着临时表或临时查询结果集的数据。
- Buffer Pool 大小可以动态修改，无需重启数据库实例
```

- 下面是官方的 InnoDB 引擎架构图

![image-20211122215820109](image/image-20211122215820109.png)

### MySQL 8.0

```
- 将InnoDB表的数据字典和Undo都从共享表空间ibdata中彻底分离出来了，以前需要ibdata中数据字典与独立表空间ibd文件中数据字典一致才行，8.0版本就不需要了。
- temporary 临时表空间也可以配置多个物理文件，而且均为 InnoDB 存储引擎并能创建索引，这样加快了处理的速度。
- 用户可以像 Oracle 数据库那样设置一些表空间，每个表空间对应多个物理文件，每个表空间可以给多个表使用，但一个表只能存储在一个表空间中。
- 将Doublewrite Buffer从共享表空间ibdata中也分离出来了。
```

![image-20211123154230588](image/image-20211123154230588.png)



### 1.1 InnoDB 内存结构

#### （1）Buffer Pool（缓冲池，BP）

##### Buffer Pool 概述

- BP以 Page页为单位，默认大小16K，BP的底层采用链表数据结构管理Page
- 在 InnoDB 访问表记录和索引时会在Page页中缓存，以后使用可以减少磁盘IO操作，提升效率

- Page根据状态可以分为三种类型

```
- free page：空闲page，未被使用
- clean page：被使用page，数据没有被修改过
- dirty page：脏页，被使用page，数据被修改过，页中数据和磁盘的数据产生了不一致
```

- 针对上述三种 page 类型，InnoDB 通过三种链表结构来维护和管理

```java
free list
- 表示空闲缓冲区，管理free page

flush list
- 表示需要刷新到磁盘的缓冲区，管理dirty page，内部page按修改时间排序

lru list
- 表示正在使用的缓冲区，管理clean page和dirty page
- 缓冲区以 midpoint为基点，前面链表称为new列表区，存放经常访问的数据，占63%
- 后面的链表称为old列表区，存放使用较少数据，占37%。

脏页既存在于flush链表，也在LRU链表中，但是两种互不影响
- LRU链表负责管理page的可用性和释放
- flush链表负责管理脏页的刷盘操作
```



##### Buffer Pool 操作过程

- 每当有新的page数据读取到buffer pool时，InnoDb引擎会判断是否有空闲页，是否足够
- 如果有就将 free page 从 free list 列表删除，放入到LRU列表中
- 没有空闲页，就会根据改进型 LRU 算法，淘汰LRU链表默认的页，将内存空间释放分配给新的页

```
普通 LRU 算法
- 末尾淘汰法，新数据从链表头部加入，释放空间时从末尾淘汰

改进型 LRU 算法
- 链表分为new和old两个部分，加入元素时并不是从表头插入，而是从中间midpoint位置插入
- 如果数据很快被访问，那么page就会向new列表头部移动
- 如果数据没有被访问，会逐步向old尾部移动，等待淘汰。
```



##### Buffer Pool配置参数

```mysql
# 查看 page 页大小
show variables like '%innodb_page_size%';

# 查看 lru list 中 old 列表参数
show variables like '%innodb_old%';

# 查看 buffer pool 参数
# 可以设置 innodb_buffer_pool_size 为总内存大小的 60%-80%
# 可以设置 innodb_buffer_pool_instances 为多个，这样可以避免缓存争夺
show variables like '%innodb_buffer%';
```



#### （2）Change Buffer（写缓冲区，CB）

##### Change Buffer 概述

- 在进行DML操作时，如果BP没有其相应的Page数据，并不会立刻将磁盘页加载到缓冲池，而是在CB记录缓冲变更，等未来数据被读取时，再将数

  据合并恢复到BP中

- ChangeBuffer占用BufferPool空间，默认占25%，最大允许占50%，可以根据读写业务量来进行调整

```mysql
set global innodb_change_buffer_max_size=20;
```



##### Change Buffer 操作过程

- 当更新一条记录时，该记录在BufffferPool存在，直接在BufffferPool修改，一次内存操作
- 如果该记录在BufferPool不存在（没有命中），会直接在ChangeBuffffer进行一次内存操作，不用再去磁盘查询数据，避免一次磁盘IO
- 当下次查询记录时，会先进性磁盘读取，然后再从ChangeBuffer中读取信息合并，最终载入BufffferPool中。



##### 写缓冲区，仅适用于非唯一普通索引页，为什么？

- 如果在索引设置唯一性，在进行修改时，InnoDB必须要做唯一性校验，因此必须查询磁盘，做一次IO操作。会直接将记录查询到BufferPool中，然后在缓冲池修改，不会在 ChangeBuffer 操作



#### （3）Adaptive Hash Index（自适应哈希索引）

- 用于优化对BP数据的查询
- InnoDB存储引擎会监控对表索引的查找，如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应
- InnoDB存储引擎会自动根据访问的频率和模式来为某些页建立哈希索引



#### （4）Log Buffer（日志缓冲区）

- Log Buffer 用来保存要写入磁盘上log文件（Redo/Undo）的数据
- LogBuffer主要是用于记录InnoDB引擎日志，在DML操作时会产生Redo和Undo日志。
- 日志缓冲区的内容定期刷新到磁盘log文件中
- 日志缓冲区满时会自动将其刷新到磁盘，当遇到BLOB或多行更新的大事务操作时，增加日志缓冲区可以节省磁盘I/O（可以通过将innodb_log_buffffer_size参数调大，减少磁盘IO频率）

```mysql
# 查看 Log Buffer 日志缓冲区 的信息
show variables like '%innodb_log%';

# innodb_flush_log_at_trx_commit 参数控制日志刷新行为，默认为1
# 0：每隔1秒写日志文件和刷盘操作（写日志文件LogBuffer-->OS cache，刷盘OS cache-->磁盘文件），最多丢失1秒数据
# 1：事务提交，立刻写日志文件和刷盘，数据不丢失，但是会频繁IO操作
# 2：事务提交，立刻写日志文件，每隔1秒钟进行刷盘操作
show variables like '%innodb_flush_log%';
```



### 1.2 InnoDB 磁盘结构

#### 1.2.1 Tablespaces（表空间）

- 用于存储表结构和数据

##### （1）系统表空间（The System Tablespace）

- 包含 InnoDB 数据字典、Doublewrite Buffer、Change Buffer、Undo Logs 的存储区域
- 系统表空间也默认包含任何用户在系统表空间创建的表数据和索引数据
- 系统表空间是一个共享的表空间因为它是被多个表共享的
- 该空间的数据文件通过参数 innodb_data_file_path 控制

```mysql
# 默认值 ibdata1:12M:autoextend（文件名为ibdata1、12MB、自动扩展）
show variables like '%innodb_data_file_path%';
```



##### （2）独立表空间（File-Per-Table Tablespaces）

- 默认开启，独立表空间是一个单表表空间，该表创建于自己的数据文件中，而非创建于系统表空间中
- 当 innodb_file_per_table 选项开启时，表将被创建于表空间中。否则，innodb将被创建于系统表空间中
- 每个表文件的表空间由一个.ibd数据文件代表，该文件默认被创建于数据库目录中
- 表空间的表文件支持动态（dynamic）和压缩（commpressed）行格式

```mysql
show variables like '%innodb_file_per_table%';
```



##### （3）通用表空间（General Tablespaces）

- 通用表空间为通过 create tablespace 语法创建的共享表空间
- 通用表空间可以创建于 mysql 数据目录外的其他表空间，其可以容纳多张表，且其支持所有的行格式

```mysql
# 创建表空间 ts1 
CREATE TABLESPACE ts1 ADD DATAFILE ts1.ibd Engine=InnoDB;

# 将表添加到 ts1 表空间
CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1;
```



##### （4）撤销表空间（Undo Tablespaces）

- 撤销表空间由一个或多个包含Undo日志文件组成
- 在MySQL 5.7版本之前 Undo 占用的是System Tablespace共享区，从5.7开始将Undo从System Tablespace分离了出来
- InnoDB使用的undo表空间由innodb_undo_tablespaces配置选项控制，默认为0

```mysql
# 参数值=0表示使用系统表空间ibdata1
# 参数值>0表示使用undo表空间undo_001、undo_002等
show variables like '%innodb_undo_tablespaces%';
```



##### （5）临时表空间（Temporary Tablespaces） 

- 分为 session temporary tablespaces 和 global temporary tablespace 两种
- session temporary tablespaces：存储的是用户创建的临时表和磁盘内部的临时表
- global temporary tablespace：储存用户临时表的回滚段（rollback segments ）
- mysql 服务器正常关闭或异常终止时，临时表空间将被移除，每次启动时会被重新创建



#### 1.2.2 InnoDB Data Dictionary（数据字典）

- InnoDB 数据字典由内部系统表组成，这些表包含用于查找表、索引和表字段等对象的元数据
- 元数据物理上位于InnoDB系统表空间中。由于历史原因，数据字典元数据在一定程度上与InnoDB表元数据文件（.frm文件）中存储的信息重叠。



#### 1.2.3 Doublewrite Buffer（双写缓冲区）

- 双写缓冲区位于系统表空间，是一个存储区域
- 在BufferPage 的page页刷新到磁盘真正的位置前，会先将数据存在Doublewrite 缓冲区
- 如果在page页写入过程中出现操作系统、存储子系统或mysqld进程崩溃，InnoDB可以在崩溃恢复期间从Doublewrite 缓冲区中找到页面的一个好备份

```mysql
# 默认情况下启用双写缓冲区，要禁用 Doublewrite 缓冲区，可以将 innodb_doublewrite 设置为0
show variables like '%innodb_doublewrite%';

# 使用 Doublewrite 缓冲区时建议将 innodb_flflush_method 设置为 O_DIRECT
show variables like '%innodb_flush_method%';
```



#### 1.2.4 Redo Log（重做日志）

- 重做日志是一种基于磁盘的数据结构，用于在崩溃恢复期间更正不完整事务写入的数据。
- MySQL 以循环方式写入重做日志文件，记录 InnoDB 中所有对Buffer Pool修改的日志。
- 当出现实例故障（像断电），导致数据未能更新到数据文件，则数据库重启时须redo，重新把数据更新到数据文件。读写事务在执行的过程中，都会不断的产生redo log
- 默认情况下，重做日志在磁盘上由两个名为 ib_logfile0 和 ib_logfile1 的文件物理表示



#### 1.2.5 Undo Logs（撤销日志）

- 撤消日志是在事务开始之前保存的被修改数据的备份，用于例外情况时回滚事务。
- 撤消日志属于逻辑日志，根据每行记录进行记录。
- 撤消日志存在于系统表空间、撤消表空间和临时表空间中。



## 2、InnoDB 线程模型

![image-20211123154936098](image/image-20211123154936098.png)

### 2.1 IO Thread

- 在 InnoDB 中使用了大量的 AIO（Async IO）来做读写处理，这样可以极大提高数据库的性能
- 在 InnoDB1.0 版本之前共有4个IO Thread，分别是write、read、insert buffer、log thread，后来版本将 read thread 和 write thread 分别增大到了4个，一共有10个了

```
- read thread：负责读取操作，将数据从磁盘加载到缓存page页。4个
- write thread：负责写操作，将缓存脏页刷新到磁盘。4个
- log thread：负责将日志缓冲区内容刷新到磁盘。1个
- insert buffer thread ：负责将写缓冲内容刷新到磁盘。1个
```



### 2.2 Purge Thread

- 事务提交之后，其使用的 undo 日志将不再需要，因此需要 Purge Thread 回收已经分配的 undo 页。

```mysql
show variables like '%innodb_purge_threads%';
```



### 2.3 Page Cleaner Thread

- 作用是将脏数据刷新到磁盘，脏数据刷盘后相应的 redo log 也就可以覆盖，即可以同步数据，又能达到 redo log 循环使用的目的
- 会调用 write thread 线程处理

```mysql
show variables like '%innodb_page_cleaners%';
```



### 2.4 Master Thread

- Master thread 是 InnoDB 的主线程，负责调度其他各线程，优先级最高
- 作用是将缓冲池中的数据异步刷新到磁盘 ，保证数据的一致性
- 工作：脏页的刷新（page cleaner thread）、undo页回收（purge thread）、redo日志刷新（log thread）、合并写缓冲等
- 内部有两个主处理，分别是每隔1秒和10秒处理

```mysql
每1秒的操作
- 刷新日志缓冲区，刷到磁盘
- 合并写缓冲区数据，根据IO读写压力来决定是否操作
- 刷新脏页数据到磁盘，根据脏页比例达到75%才操作
# 脏页比例达到多少
show variables like '%innodb_max_dirty_pages_pct%';
# 每次执行刷多少页
show variables like '%innodb_io_capacity%';

每10秒的操作
- 刷新脏页数据到磁盘（Page Cleaner Thread）
- 合并写缓冲区数据   
- 刷新日志缓冲区（log thread）
- 删除无用的undo页（Purge Thread）
# 每次删除多少无用的 undo 页
show variables like '%innodb_purge_batch_size%';
```



## 3、InnoDB 数据文件（.ibd）

- InnoDB数据文件存储结构：一个ibd数据文件 ------> Segment（段）------> Extent（区）------> Page（页）------> Row（行）

![image-20211123160942406](image/image-20211123160942406.png)



### 3.1 ibd 文件存储结构

#### （1）Tablesapce（表空间）

- 一个文件包含多个段

- 用于存储多个ibd数据文件，用于存储表的记录和索引

#### （2）Segment（段）

- 用于管理多个Extent
- 分为数据段（Leaf node segment）、索引段（Non-leaf nodesegment）、回滚段（Rollback segment）
- 一个表至少会有两个segment，一个管理数据，一个管理索引。每多创建一个索引，会多两个segment。

#### （3）Extent（区）

- 一个区固定包含64个连续的页，大小为1M
- 当表空间不足，需要分配新的页资源，不会一页一页分，直接分配一个区

#### （4）Page（页）

- 用于存储多个Row行记录，大小为16K
- 包含很多种页类型，比如：数据页、undo页、系统页、事务数据页、大的BLOB对象页。
- Page是文件最基本的单位，无论何种类型的page，都是由page header、page trailer、pagebody组成

![image-20211123162302025](image/image-20211123162302025.png)

#### （5）Row（行）

- 包含了记录的字段值、事务ID（Trx id）、滚动指针（Roll pointer）、字段指针（Fieldpointers）等信息



### 3.2 ibd 文件存储格式

```mysql
# 关注 Row_format 列
# 如果 row_format 为 REDUNDANT、COMPACT，文件格式为 Antelope
# 如果 row_format 为 DYNAMIC、COMPRESSED，文件格式为 Barracuda
show table status;

# 关注 Row_format 列
# 关注 File_Format 列
select * from information_schema.innodb_sys_tables;

# 查看文件格式（File_Format）
show variables like '%innodb_file_format%';

# 在创建表和索引时，文件格式都被用于每个InnoDB表数据文件（其名称与*.ibd匹配）
# 修改文件格式的方法是重新创建表及其索引，最简单方法是对要修改的每个表使用
ALTER TABLE 表名 ROW_FORMAT=格式类型;
```



#### 3.2.1 行格式（Row_format）

- 表的行格式决定了它的行是如何物理存储的，这反过来又会影响查询和DML操作的性能
- 如果在单个page页中容纳更多行，查询和索引查找可以更快地工作，缓冲池中所需的内存更少，写入更新时所需的I/O更少
- 每个表的数据分成若干页来存储，每个页中采用B树结构存储；
- 如果某些字段信息过长，无法存储在B树节点中，这时候会被单独分配空间，此时被称为溢出页，该字段被称为页外列

- InnoDB 存储引擎支持四种行格式：REDUNDANT、COMPACT、DYNAMIC、COMPRESSED

![image-20211123165053932](image/image-20211123165053932.png)



##### （1）REDUNDANT 行格式

- 使用 REDUNDANT 行格式，表会将变长列值的前768字节存储在B树节点的索引记录中，其余的存储在溢出页上
- 对于大于等于786字节的固定长度字段 InnoDB 会转换为变长字段，以便能够在页外存储。

##### （2）COMPACT 行格式

- 与 REDUNDANT 行格式相比，COMPACT 行格式减少了约20%的行存储空间，但代价是增加了某些操作的CPU使用量
- 如果系统负载是受缓存命中率和磁盘速度限制，那么COMPACT格式可能更快
- 如果系统负载受到CPU速度的限制，那么COMPACT格式可能会慢一些

##### （3）DYNAMIC 行格式

- 使用DYNAMIC行格式，InnoDB会将表中长可变长度的列值完全存储在页外，而索引记录只包含指向溢出页的20字节指针
- 大于或等于768字节的固定长度字段编码为可变长度字段。
- DYNAMIC行格式支持大索引前缀，最多可以为3072字节

```mysql
# 通过 innodb_large_prefix 参数控制
show variables like '%innodb_large_prefix%';
```

##### （4）COMPRESSED 行格式

- COMPRESSED 行格式提供与 DYNAMIC 行格式相同的存储特性和功能，但增加了对表和索引数据压缩的支持。



#### 3.2.2 文件格式（File_Format）

- 在早期的InnoDB版本中，文件格式只有一种，随着InnoDB引擎的发展，出现了新文件格式，用于支持新的功能
- 目前InnoDB只支持两种文件格式：Antelope 和 Barracuda

##### （1）Antelope

- 先前未命名的，最原始的InnoDB文件格式
- 支持两种行格式：COMPACT、REDUNDANT
- MySQL 5.6版本- 默认格式为 Antelope

##### （2）Barracuda

- 新的文件格式
- 支持 InnoDB 所有行格式：COMPACT、REDUNDANT、新的行格式：COMPRESSED、DYNAMIC

- 5.7版本- 默认值为Antelope，5.7版本+ 改为 Barracuda



## 4、Undo Log 日志

### 4.1 Undo Log 概述

- Undo：意为撤销或取消，以撤销操作为目的，返回指定某个状态的操作。
- Undo Log：数据库事务开始之前，会将要修改的记录存放到 Undo 日志里，当事务回滚时或者数据库崩溃时，可以利用 Undo 日志，撤销未提交事务对数据库产生的影响。
- Undo Log 属于逻辑日志，记录一个变化过程

```
例如
- 执行一个 delete，undolog 会记录一个 insert
- 执行一个 update，undolog 会记录一个相反的 update
```



### 4.2 Undo Log 的产生

- Undo Log在事务开始前产生



### 4.3 Undo Log 的销毁

- 事务在提交时，并不会立刻删除undo log，innodb 会将该事务对应的 undo log 放入到删除列表中，后面会通过后台线程 purge thread进行回收处理



### 4.4 Undo Log 的存储

- undo log 采用段的方式管理和记录
- 在 innodb 数据文件中包含一种 rollback segment回滚段，内部包含1024个 undo log segment

```mysql
# Undo log 存储信息
show variables like '%innodb_undo%';
```



### 4.5 Undo Log 的作用

#### （1）实现事务的原子性

- Undo Log 是为了实现事务的原子性而出现的产物
- 事务处理过程中，如果出现了错误或者用户执行了 ROLLBACK 语句，MySQL 可以利用 Undo Log 中的备份将数据恢复到事务开始之前的状态



#### （2）实现多版本并发控制（MVCC）

- Undo Log 在 MySQL InnoDB 存储引擎中用来实现多版本并发控制
- 事务未提交之前，Undo Log 保存了未提交之前的版本数据，Undo Log 中的数据可作为数据旧版本快照供其他并发事务进行快照读

```
- 事务 A 手动开启事务，执行更新操作，首先会把更新命中的数据备份到 Undo Buffer 中
- 事务 B 手动开启事务，执行查询操作，会读取 Undo 日志数据返回，进行快照读
```

![image-20211123201405780](image/image-20211123201405780.png)



## 5、Redo Log 日志

### 5.1 Redo Log 概述

- Redo：顾名思义就是重做。以恢复操作为目的，在数据库发生意外时重现操作。
- Redo Log：指事务中修改的任何数据，将最新的数据备份存储的位置（Redo Log），被称为重做日志。



### 5.2 Redo Log 的生成

- 随着事务操作的执行，就会生成Redo Log
- 在事务提交时会将产生 Redo Log写入Log Buffer，并不是随着事务的提交就立刻写入磁盘文件。



### 5.3 Redo Log 的释放 

- 等事务操作的脏页写入到磁盘之后，Redo Log 的使命也就完成了，Redo Log 占用的空间就可以重用（被覆盖写入）



### 5.4 Redo Log 的工作原理

- Redo Log 是为了实现事务的持久性而出现的产物。
- 防止在发生故障的时间点，尚有脏页未写入表的 IBD 文件中，在重启 MySQL 服务的时候，根据 Redo Log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。

![image-20211123201804256](image/image-20211123201804256.png)



### 5.4 Redo Log 的写入机制

- Redo Log 文件内容是以顺序循环的方式写入文件，写满时则回溯到第一个文件，进行覆盖写

```
- write pos 是当前记录的位置，一边写一边后移，写到最后一个文件末尾后就回到 0 号文件开头
- checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件
- write pos 和 checkpoint 之间还空着的部分，可以用来记录新的操作

如果 write pos 追上checkpoint，表示写满，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下
```



![image-20211123201848253](image/image-20211123201848253.png)



### 5.5 Redo Log 相关配置参数

#### （1）Redo Log 存储信息

```mysql
# 每个InnoDB存储引擎至少有1个重做日志文件组（group），每个文件组至少有2个重做日志文件，默认为 ib_logfile0 和 ib_logfile1
show variables like '%innodb_log%';
```



#### （2）Redo Buffer 持久化到 Redo Log 的策略

```mysql
# 0：每秒提交 Redo buffer ->OS cache -> flush cache to disk，可能丢失一秒内的事务数据，由后台Master线程每隔 1秒执行一次操作
# 1：（默认值），每次事务提交执行 Redo Buffer -> OS cache -> flush cache to disk，最安全，性能最差的方式
# 2：每次事务提交执行 Redo Buffer -> OS cache，然后由后台Master线程再每隔1秒执行OS cache -> flush cache to disk 的操作
# 一般建议选择取值2，因为 MySQL 挂了数据没有损失，整个服务器挂了才会损失1秒的事务提交数据
show variables like '%Innodb_flush_log_at_trx_commit%';
```

![image-20211123202317680](image/image-20211123202317680.png)



## 6、Binlog 日志

### 6.1 Binlog 概述

- Redo Log 是属于InnoDB引擎所特有的日志，而MySQL Server也有自己的日志，即 Binarylog（二进制日志），简称Binlog
- Binlog是记录所有数据库表结构变更以及表数据修改的二进制日志，不会记录SELECT和SHOW这类操作
- Binlog日志是以事件形式记录，还包含语句所执行的消耗时间。
- Binlog 日志使用场景

```
- 主从复制：在主库中开启Binlog功能，这样主库就可以把Binlog传递给从库，从库拿到 Binlog 后实现数据恢复达到主从数据一致性。
- 数据恢复：通过mysqlbinlog工具来恢复数据
```



### 6.2 Binlog 文件结构

- MySQL的binlog文件中记录的是对数据库的各种修改操作，用来表示修改操作的数据结构是Logevent
- 不同的修改操作对应的不同的log event
- 比较常用的log event有：Query event、Row event、Xid event等
- binlog文件的内容就是各种Log event的集合
- Binlog文件中Log event结构图

![image-20211123203037494](image/image-20211123203037494.png)



### 6.3 Binlog 写入模式/记录模式分类

- Binlog文件名默认为 “主机名_binlog-序列号” 格式，例如oak_binlog-000001，也可以在配置文件中指定名称



#### （1）ROW（row-based replication, RBR）

- 志中会记录每一行数据被修改的情况，然后在 slave 端对相同的数据进行修改。
- 优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。
- 缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨。



#### （2）STATMENT（statement-based replication, SBR）

- 每一条被修改数据的SQL都会记录到 master的Binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。简称SQL语句复制。
- 优点：日志量小，减少磁盘IO，提升存储和恢复速度
- 缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。



#### （3）MIXED（mixed-based replication, MBR）

- 以上两种模式的混合使用，MySQL会根据执行的SQL语句选择写入模式
- 一般会使用 STATEMENT模式 保存binlog
- 对于 STATEMENT模式 无法复制的操作使用 ROW模式 保存binlog



### 6.3 Binlog 写入机制

- 根据记录模式和操作触发event事件生成log event（事件触发执行机制）
- 将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区Log Event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用于存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。

- 事务在提交阶段会将产生的log event写入到外部binlog文件中。不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。



### 6.3 Binlog 文件操作

#### （1）Binlog 状态查看

```mysql
show variables like '%log_bin%';
```



#### （2）开启 Binlog

```mysql
set global log_bin=mysqllogbin;
```

- 当开启时，报错ERROR 1238 (HY000): Variable 'log_bin' is a read only variable，需要修改my.cnf或my.ini配置文件

```ini
# 在[mysqld]下面增加 log_bin=mysql_bin_log，重启MySQL服务

# log-bin=ON 
# log-bin-basename=mysqlbinlog 
# 第4行等价于 第1行+第2行效果
log-bin=mysqlbinlog
binlog-format=ROW
```



#### （3）查看 Binlog

- 方式1：使用 show binlog events 命令

```mysql
# 等价于 show master logs;
show binary logs;

show master status;
show binlog events;
show binlog events in 'mysqlbinlog.000001';
```

- 方式2：使用 mysqlbinlog 命令（切换到安装目录下的data目录，然后在命令行中执行）

```bash
# 直接在命令行查看
mysqlbinlog "文件名"

# 输出到文件中查看
mysqlbinlog "文件名" > "test.sql"
```



#### （4）使用 Binlog 恢复数据

- 命令行中执行
- mysqldump：定期全部备份数据库数据
- mysqlbinlog：做增量备份和恢复操作

```bash
# 按指定时间恢复
mysqlbinlog --start-datetime="2020-04-25 18:00:00" --stop- datetime="2020-04-26 00:00:00" mysqlbinlog.000002 | mysql -uroot -p1234

# 按事件位置号恢复（用户名 root，密码 1234 ）
mysqlbinlog --start-position=154 --stop-position=957 mysqlbinlog.000002 | mysql -uroot -p1234
```



#### （5）删除 Binlog 文件

```sql
# 删除指定文件 
purge binary logs to 'mysqlbinlog.000001'; 

# 删除指定时间之前的文件 
purge binary logs before '2020-04-28 00:00:00'; 

# 清除所有文件
reset master; 

# 启动自动清理功能
# 默认值为0表示没启用
# 设置为1表示超出1天binlog文件会自动删除掉
show variables like '%expire_logs_days%';
```



## 7、【区别】Redo Log 和 Binlog

- Redo Log是属于InnoDB引擎功能
- Binlog是属于MySQL Server自带功能，并且是以二进制文件记录



- Redo Log属于物理日志，记录该数据页更新状态内容
- Binlog是逻辑日志，记录更新过程



- Redo Log日志是循环写，日志空间大小是固定
- Binlog是追加写入，写完一个写下一个，不会覆盖使用



- Redo Log作为服务器异常宕机后事务数据自动恢复使用
- Binlog可以作为主从复制和数据恢复使用，Binlog没有自动crash-safe能力。



# 第四章 MySQL 索引

## 1、索引概述

- 索引是存储引擎用于快速查找记录的一种数据结构。需要额外开辟空间和数据维护工作。
- 索引是物理数据页存储，在数据文件中（InnoDB，ibd文件），利用数据页(page)存储。
- 索引可以提升查询速度，但是同时也会降低增删改操作速度（如where查询，order by排序），索引维护需要代价。

- 添加索引首先应考虑在 where 及 order by 涉及的列上建立索引

  

- 索引的优点

```
- 大大的提高查询速度
- 可以显著的减少查询中分组和排序的时间
```

- 索引的缺点

```
- 创建索引和维护索引需要时间，而且数据量越大时间越长
- 当对表中的数据进行增加，修改，删除的时候，索引也要同时进行维护，降低了数据的维护速度
```



## 2、索引分类

### 2.1 从索引存储结构划分

- B Tree 索引
- Hash 索引
- FULLTEXT 全文索引
- R Tree 索引

### 2.2 从应用层次划分

- 普通索引
- 唯一索引
- 主键索引
- 复合索引

### 2.3 从索引键值类型划分

- 主键索引
- 辅助索引（二级索引）

### 2.4 从数据存储和索引键值逻辑关系划分

- 聚集索引（聚簇索引）
- 非聚集索引（非聚簇索引）



## 3、索引原理

### 3.1 二分查找法

#### （1）概述

- 二分查找法也叫作折半查找法，它是在有序数组中查找指定数据的搜索算法
- 优点：等值查询、范围查询性能优秀
- 缺点：更新数据、新增数据、删除数据维护成本高

#### （2）查找过程

- 首先定位left和right两个指针
- 计算(left+right)/2
- 判断除2后索引位置值与目标值的大小比对
- 索引位置值大于目标值就-1，right移动；如果小于目标值就+1，left移动

#### （3）查找示意图

- 下面的有序数组有17 个值，查找的目标值是7

![image-20211124175534206](image/image-20211124175534206.png)



![image-20211124175659680](image/image-20211124175659680.png)



![image-20211124175834821](image/image-20211124175834821.png)

![image-20211124175929711](image/image-20211124175929711.png)



### 3.2  InnoDB 自适应哈希索引

#### （1）Hash 结构

- Hash 底层实现是由Hash表来实现的，是根据键值 <key,value> 存储数据的结构
- 非常适合根据 key 查找 value 值，也就是单个 key 查询，或者说等值查询

#### （2）Hash 索引

- Hash索引可以方便的提供等值查询，但是对于范围查询就需要全表扫描了。
- Hash索引在 MySQL 中的Hash结构主要应用：Memory原生的Hash索引 、InnoDB 自适应哈希索引

#### （3）InnoDB 自适应哈希索引

- 目的：InnoDB 自适应哈希索引是为了提升查询效率
- 创建过程：InnoDB存储引擎会监控表上各个索引页的查询，当InnoDB注意到某些索引值访问非常频繁时，会在内存中基于B+Tree索引再创建一个哈希索引，使得内存中的 B+Tree 索引具备哈希索引的功能，即能够快速定值访问频繁访问的索引页。
- 特点：InnoDB自适应哈希索引，在使用Hash索引访问时，一次性查找就能定位数据，等值查询效率要优于B+Tree。
- 优点：自适应哈希索引的建立使得InnoDB存储引擎能自动根据索引页访问的频率和模式自动地为某些热点页建立哈希索引来加速访问

- InnoDB自适应哈希索引功能的开启或关闭

```mysql
# 开启
set global innodb_adaptive_hash_index=1;

# 关闭
set global innodb_adaptive_hash_index=0;

# 查看自适应哈希索引的信息（关注 innodb_adaptive_hash_index 的值）
show variables like '%innodb_adaptive%';
```



### 3.3 B+Tree 结构

- 系统从磁盘读取数据到内存时是以磁盘块（block）为基本单位的，位于同一个磁盘块中的数据会被一次性读取出来，而不是需要什么取什么。而系统一个磁盘块的存储空间往往没有这么大，因此InnoDB每次申请磁盘空间时都会是若干地址连续磁盘块来达到页的大小16KB。InnoDB在把磁盘数据读入到磁盘时会以页为基本单位，在查询数据时如果一个页中的每条数据都能有助于定位数据记录的位置，这将会减少磁盘I/O次数，提高查询效率。B-Tree结构的数据可以让系统高效的找到数据所在的磁盘块。

  

#### 3.3.1 B-Tree 结构

- 定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data为一行记录中除主键外的数据。对于不同的记录，key值互不相同
- 一棵m阶的B-Tree有如下特性

```
索引值和data数据分布在整棵树结构中
每个节点可以存放多个索引值及对应的data数据
树节点中的多个索引值从左到右升序排列

1. 每个节点最多有m个孩子。
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
3. 若根节点不是叶子节点，则至少有2个孩子
4. 所有叶子节点都在同一层，且不包含其它关键字信息
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
7. ki(i=1,…n)为关键字，且关键字升序排序。
8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

- 每个节点占用一个盘块的磁盘空间
- 一个节点上有两个升序排序的关键字和三个指向子树根节点的指针
- 指针存储的是子节点所在磁盘块的地址
- 两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域

以根节点为例
- 关键字为17和35
- P1指针指向的子树的数据范围为小于17
- P2指针指向的子树的数据范围为17~35
- P3指针指向的子树的数据范围为大于35
```

- B-Tree 的搜索：从根节点开始，对节点内的索引值序列采用二分法查找，如果命中就结束查找。没有命中会进入子节点重复查找过程，直到所对应的的节点指针为空，或已经是叶子节点了才结束。

```
模拟查找关键字29的过程

根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
比较关键字29在区间（17,35），找到磁盘块1的指针P2。
根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
比较关键字29在区间（26,30），找到磁盘块3的指针P2。
根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘I/O操作是影响整个B-Tree查找效率的决定因素。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。
```



![image-20211124181341634](image/image-20211124181341634.png)



#### 3.3.2 B+Tree 结构

##### （1）B+Tree 的引入

- B-Tree结构图中可以看到每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会导致B-Tree的深度较大，增大查询时的磁盘I/O次数，进而影响查询效率。
- 在B+Tree中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息，这样可以大大加大每个节点存储的key值数量，降低B+Tree的高度
- MySQL数据库索引采用的是B+Tree结构，在B-Tree结构上做了优化改，使其更适合实现外存储索引结构



##### （2）B+Tree 特点

```
- 非叶子节点只存储键值信息，这样便于存储更多的索引值
- 所有叶子节点之间都有一个链指针，提高区间的访问性能
- 数据记录（索引值和data数据）都存放在叶子节点中
- 树节点中的多个索引值从左到右升序排列
```



##### （3）B+Tree 查找方式

- 通常在B+Tree上有两个头指针，一个指向根节点，另一个指向关键字最小的叶子节点，而且所有叶子节点（即数据节点）之间是一种链式环结构
- 因此可以对B+Tree进行两种查找运算：一种是对于主键的范围查找和分页查找，另一种是从根节点开始，进行随机查找



##### （4）B+Tree 结构图

- 假设每个磁盘块能存储4个键值及指针信息，则 B+Tree 结构如下图所示

![image-20211124181403982](image/image-20211124181403982.png)



##### （5）B+Tree 与 B-Tree 比较

- B+树进行范围查找时，只需要查找定位两个节点的索引值，然后利用叶子节点的指针进行遍历即可
- B树需要遍历范围内所有的节点和数据
- 显然B+Tree效率高



##### （6）B+Tree 索引分类

- 聚集索引（clustered index）/聚簇索引

```mysql
# 聚簇索引
B+Tree的叶子节点存放主键索引值和行记录就属于聚簇索引
InnoDB 引擎中，主键索引采用的就是聚簇索引结构存储

# 非聚簇索引
如果索引值和行记录分开存放就属于非聚簇索引
MyISAM 引擎数据表的索引文件和数据文件是分开的，被称为非聚簇索引结构

# 聚簇索引概念
- 聚簇索引是一种数据存储方式，InnoDB的聚簇索引就是按照主键顺序构建 B+Tree结构
- B+Tree 的叶子节点就是行记录，行记录和主键值紧凑地存储在一起
- 这也意味着 InnoDB 的主键索引就是数据表本身，它按主键顺序存放了整张表的数据，占用的空间就是整个表数据量的大小
- 通常说的主键索引就是聚集索引

# InnoDB的表要求必须要有聚簇索引
- 如果表定义了主键，则主键索引就是聚簇索引
- 如果表没有定义主键，则第一个非空unique列作为聚簇索引
- 否则InnoDB会从建一个隐藏的row-id作为聚簇索引
```



- 辅助索引（secondary index）/二级索引

```
根据索引列构建 B+Tree结构
在 B+Tree 的叶子节点中只存了索引列和主键的信息
二级索引占用的空间会比聚簇索引小很多
通常创建辅助索引就是为了提升查询效率
一个表InnoDB只能创建一个聚簇索引，但可以创建多个辅助索引
```

![image-20211124184240743](image/image-20211124184240743.png)

![image-20211124184252472](image/image-20211124184252472.png)



## 4、索引分析 - EXPLAIN

### （1）select_type

- 表示查询的类型

```mysql
# simple：表示查询语句不包含子查询或union
explain select * from tb_admin_info where id < 3;

# primary：表示此查询是最外层的查询

# union：表示此查询是union的第二个或后续的查询
explain select * from tb_admin_info where id = 1 union select * from tb_admin_info where id = 2;

# dependent union：union中的第二个或后续的查询语句，使用了外面查询结果

# union result：union的结果

# subquery：select子查询语句
explain select * from tb_admin_info where id =(select max(id) from tb_admin_info);

# dependent subquery：select子查询语句依赖外层查询的结果
explain select * from tb_admin_info t1 where id =(select max(t2.id) from tb_admin_info t2 where t1.pwd = '2');
```



### （2）type

- 表示存储引擎查询数据时采用的方式
- 通过它可以判断出查询是全表扫描还是基于索引的部分扫描
- 常用属性值如下，从上至下效率依次增强

```mysql
# all：表示全表扫描，性能最差
explain select * from t_user;
explain select * from t_user where sex = 1;

# index：表示基于索引的全表扫描，先扫描索引再扫描全表数据
explain select * from t_user where sex = 1 order by id;   # id 有索引，因此 type = index
explain select * from t_user where sex = 1 order by sex;  # sex 没有索引，因此 type = all

# range：表示使用索引范围查询。使用>、>=、<、<=、in等等
explain select * from t_user where id > 1;   # id 有索引，因此 type = range
explain select * from t_user where sex > 1;  # sex 没有索引，因此 type = all

# ref：表示使用非唯一索引进行单值查询
create index age on t_user (age);  # 创建非唯一索引
explain select * from t_user where age = 22;  # 使用非唯一索引进行单值查询（查询结果唯一，type = ref）
explain select * from t_user where age = 18;  # 使用非唯一索引进行单值查询（查询结果不唯一，type = all）

create index sex on tb_admin_info (sex);  # 创建非唯一索引
explain select * from tb_admin_info where sex = 1;  # 使用非唯一索引进行单值查询（查询结果唯一，type = ref）
explain select * from tb_admin_info where sex = 2;  # 使用非唯一索引进行单值查询（查询结果不唯一，type = all）

# eq_ref：一般情况下出现在多表join查询，表示前面表的每一个记录，都只能匹配后面表的一行结果。
# t_user表 all
# t_score表 eq_ref
explain select * from t_user u,t_score s where u.id = s.user_id;

# const：表示使用主键或唯一索引做等值查询，常量查询
explain select * from t_user where id = 1;  # 使用主键或唯一索引做等值查询，常量查询

# null：表示不用访问表，速度最快
explain select now();
```



### （3）possible_keys

- 表示查询时能够使用到的索引
- 注意并不一定会真正使用，显示的是索引名称



### （4）key

- 表示查询时真正使用到的索引，显示的是索引名称



### （5）rows

- MySQL查询优化器会根据统计信息，估算SQL要查询到结果需要扫描多少行记录

- 原则上 rows 是越少效率越高，可以直观的了解到SQL效率高低

  

### （6）key_len

- 表示查询使用了索引的字节数量
- 可以判断是否全部使用了组合索引
- key_len的计算规则

```mysql
# 字符串类型
字符串长度跟字符集有关：latin1=1、gbk=2、utf8=3、utf8mb4=4
char(n)：n*字符集长度
varchar(n)：n * 字符集长度 + 2字节

# 数值类型
TINYINT：1个字节
SMALLINT：2个字节
MEDIUMINT：3个字节
INT、FLOAT：4个字节
BIGINT、DOUBLE：8个字节

# 时间类型
DATE：3个字节
TIMESTAMP：4个字节
DATETIME：8个字节

# 字段属性
NULL属性占用1个字节，如果一个字段设置了NOT NULL，则没有此项
```



### （7）Extra

- 表示很多额外的信息，各种操作会在Extra提示相关信息

```mysql
# Using where：表示查询需要通过索引回表查询数据
explain select * from t_user where age > 18;

# Using index：表示查询需要通过索引，索引就可以满足所需数据
explain select id from t_user order by id;     # Using index
explain select age from t_user where age = 18; # Using index
explain select age from t_user where age > 18; # Using where; Using index

# Using filesort：表示查询出来的结果需要额外排序，数据量小在内存，数据量大在磁盘，因此有 Using filesort 建议优化
explain select * from t_user order by age; # Using filesort
explain select id from t_user where age = 18 order by name; # Using where; Using filesort

# Using temporary：查询使用到了临时表，一般出现于去重、分组等操作
explain select distinct(name) from t_user;  # name 没有索引
explain select distinct(age) from t_user;   # age 有索引，extra = Using index for group-by
explain select * from t_user group by name; # name 没有索引，extra =Using temporary; Using filesort
explain select * from t_user group by age;  # age 有索引，extra = null

# 不可能
explain select * from t_user where 1 < 0;                # Impossible WHERE
explain select * from t_user group by age having 1 < 0;  # Impossible HAVING
```



## 5、索引覆盖

### 5.1 回表查询

- InnoDB索引有聚簇索引和辅助索引
- 聚簇索引的叶子节点存储行记录，InnoDB必须要有，且只有一个
- 辅助索引的叶子节点存储的是主键值和索引字段值，通过辅助索引无法直接定位行记录



- 通常情况下，需要扫码两遍索引树
- 先通过辅助索引定位主键值，然后再通过聚簇索引定位行记录，这就叫做**回表查询**，它的性能比扫一遍索引树低
- 总结：通过索引查询主键值，然后再去聚簇索引查询记录信息



### 5.2 索引覆盖

- 只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快，这就叫做索引覆盖

- 实现索引覆盖最常见的方法就是：将被查询的字段，建立到组合索引/复合索引



### 5.2 复合索引遵循的原则 - 最左前缀原则

- 最左前缀原则：查询中使用到最左边的列，那么查询就会使用到索引，如果从索引的第二列开始查找，索引将失效

![image-20211124185906685](image/image-20211124185906685.png)



## 6、索引与 like

- MySQL在使用Like模糊查询时，索引是可以被使用的，只有把%字符写在后面才会使用到索引

```mysql
# 不起作用
select * from user where name like '%o%';

# 起作用
select * from user where name like 'o%';

# 不起作用
select * from user where name like '%o'; 
```



## 7、索引与 null

- 如果MySQL表的某一列含有NULL值，那么包含该列的索引是否有效？

```
- NULL 列需要增加额外空间来记录其值是否为NULL。对于MyISAM表，每一个空列额外占用一位，四舍五入到最接近的字节
- 虽然MySQL可以在含有NULL的列上使用索引，但不建议列上允许为 NULL
- 最好设置NOT NULL，并给一个默认值
- 比如0和 ‘’ 空字符串等，如果是datetime类型，也可以设置系统当前时间或某个固定的特殊值，例如'1970-01-01 00:00:00'
```



## 8、索引与排序

- MySQL 查询支持 filesort 和 index 两种方式的排序



### 8.1 filesort 排序方式

- filesort 是先把结果查出，然后在缓存或磁盘进行排序操作，效率较低。

#### （1）filesort 排序算法：双路排序

- 需要两次磁盘扫描读取，最终得到用户数据
- 第一次将排序字段读取出来，然后排序
- 第二次去读取其他字段数据



#### （2）filesort 排序算法：单路排序

- 从磁盘查询所需的所有列数据，然后在内存排序将结果返回
- 如果查询数据超出缓存 sort_buffer，会导致多次磁盘读取操作，并创建临时表，最后产生了多次IO，反而会增加负担
- 解决方案

```mysql
# 方案1：少使用select *

# 方案2：增加 sort_buffer_size 容量和 max_length_for_sort_data 容量
show variables like '%sort_buffer%';
```



#### （3）使用 filesort 方式的排序

```mysql
# 对索引列同时使用了 asc和 desc
explain select id from user order by age asc,name desc;  # 对应 (age,name)索引

# where子句 和 order by 子句满足最左前缀，但 where 子句使用了范围查询（例如>、<、in等）
explain select id from user where age>10 order by name;  # 对应 (age,name)索引

# order by 或者 where + order by 索引列没有满足索引最左前列
explain select id from user order by name;  # 对应(age,name)索引

# 使用了不同的索引，mysql 每次只采用一个索引，order by 涉及了两个索引
explain select id from user order by name,age;  # 对应(name)、(age)两个索 引

# where子句 与 order by 子句，使用了不同的索引
explain select id from user where name='tom' order by age;  # 对应 (name)、(age)索引

# where子句 或者 order by 子句中索引列使用了表达式，包括函数表达式
explain select id from user order by abs(age);  # 对应(age)索
```



### 8.2 index 排序方式

- index 是指利用索引自动实现排序，不需另做排序操作，效率会比较高。

#### （1）使用 index 方式的排序

```mysql
# order by 子句索引列组合满足索引最左前列
explain select id from user order by id; # 对应(id)、(id,name)索引有效

# where子句 + order by 子句索引列组合满足索引最左前列
explain select id from user where age = 18 order by name; # 对应 (age,name) 索引有效
```



## 9、Explain 分析 SQL 结果

- 结果中 Extra 属性显示 Using filesort，表示使用了filesort排序方式，需要优化
- 如果 Extra 属性显示 Using index 时，表示覆盖索引，也表示所有操作在索引上完成，也可以使用 index 排序方式，建议尽可能采用覆盖索引



# 第五章 MySQL 事务

## 1、事务的特性 - ACID

### 1.1 原子性（Atomicity）

- 原子性：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行

- 修改 ---> Buffer Pool修改 ---> 刷盘。可能会有下面两种情况：

```
事务提交了，如果此时Buffer Pool的脏页没有刷盘，如何保证修改的数据生效？ 使用 Redo
如果事务没提交，但是Buffer Pool的脏页刷盘了，如何保证不该存在的数据撤销？使用 Undo
```

- 每一个写事务，都会修改BufferPool，从而产生相应的Redo/Undo日志，在Buffer Pool 中的页被刷到磁盘之前，这些日志信息都会先写入到日志文件中，如果 Buffer Pool 中的脏页没有刷成功，此时数据库挂了，那在数据库再次启动之后，可以通过 Redo 日志将其恢复出来，以保证脏页写的数据不会丢失。如果脏页刷新成功，此时数据库挂了，就需要通过Undo来实现了。



### 1.2 持久性（Durability）

- 持久性：指的是一个事务一旦提交，它对数据库中数据的改变就应该是永久性的，后续的操作或故障不应该对其有任何影响，不会丢失

- MySQL 的持久性也与 WAL 技术（Write-Ahead Logging，先写日志，再写磁盘）相关，redo log在系统Crash重启之类的情况时，可以修复数据，从而保

  障事务的持久性。通过原子性可以保证逻辑上的持久性，通过存储引擎的数据刷盘可以保证物理上的持久性。

- 一个“提交”动作触发的操作有：binlog落地、发送binlog、存储引擎提交、flush_logs，check_point、事务提交标记等。

![image-20211125013759162](image/image-20211125013759162.png)



### 1.3 隔离性（Isolation）

- 隔离性：指的是一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对其他的并发事务是隔离的

- InnoDB 支持的隔离性有 4 种，隔离性从低到高分别为：读未提交、读提交、可重复读、可串行化
- 锁和多版本控制（MVCC）技术就是用于保障隔离性的



### 1.4 一致性（Consistency）

- 一致性：指的是事务开始之前和事务结束之后，数据库的完整性限制未被破坏
- 一致性包括两方面的内容，分别是约束一致性和数据一致性

```
约束一致性：创建表结构时所指定的外键、Check、唯一索引等约束（MySQL 中不支持 Check）
数据一致性：是一个综合性的规定，因为它是由原子性、持久性、隔离性共同保证的结果，而不是单单依赖于某一种技术
```

- 一致性也可以理解为数据的完整性

```
- 数据的完整性是通过原子性、隔离性、持久性来保证的，而这3个特性又是通过 Redo/Undo 来保证的
- 逻辑上的一致性，包括唯一索引、外键约束、check 约束，这属于业务逻辑范畴。
```

![image-20211125014113620](image/image-20211125014113620.png)



### 1.5 ACID 关系图

- 持久性（Durability）、隔离性（Isolation）、原子性（Atomicity） 与 WAL 技术（Write-Ahead Logging，先写日志，再写磁盘）有关

![image-20211125014254921](image/image-20211125014254921.png)

## 2、事务的隔离级别

### 2.1 事务的隔离级别 - 简介

- 事务隔离级别，只针对 Innodb 引擎（因为 Innodb  支持事务的功能，MyISAM 引擎不支持）
- 数据库的事务隔离级别越高，并发问题就越小，但是并发处理能力越差
- 一般使用时，建议采用默认隔离级别，如果存在并发问题，可以通过悲观锁、乐观锁等实现处理

- MySQL默认隔离级别：可重复读 Repeatable Read 
- Oracle、SQLServer默认隔离级别：已提交读 Read Committed 



### 2.2 事务的隔离级别 - 分类

#### （1）读未提交 Read Uncommitted（隔离级别最低）

- 解决了回滚覆盖类型的更新丢失，但可能发生脏读现象，也就是可能读取到其他会话中未提交事务修改的数据。



#### （2）已提交读 Read Committed 

- 只能读取到其他会话中已经提交的数据，解决了脏读
- 但可能发生不可重复读现象，也就是可能在一个事务中两次查询结果不一致



#### （3）可重复读 Repeatable Read 

- 解决了不可重复读，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。
- 不过理论上会出现幻读，简单的说幻读指的的当用户读取某一范围的数据行时，另一个事务又在该范围插入了新行，当用户在读取该范围的数据时会发现有新的幻影行。



#### （4）可串行化 Serializable（隔离级别最高）

- 所有的增删改查串行执行。
- 它通过强制事务排序，解决相互冲突，从而解决幻度的问题。这个级别可能导致大量的超时现象的和锁竞争，效率低下



### 2.3 事务的隔离级别 - 并发处理能力

#### （1）事务的并发会产生的问题：更新丢失、脏读、不可重复读、幻读

```mysql
#（1）更新丢失
当两个或多个事务更新同一行记录，会产生更新丢失现象，更新丢失现象可以分为回滚覆盖和提交覆盖
- 回滚覆盖：一个事务回滚操作，把其他事务已提交的数据给覆盖了
- 提交覆盖：一个事务提交操作，把其他事务已提交的数据给覆盖了

#（2）脏读
一个事务读取到了另一个事务修改但未提交的数据

#（3）不可重复读
一个事务中多次读取同一行记录不一致，后面读取的跟前面读取的不一致

#（4）幻读
一个事务中多次按相同条件查询，结果不一致。后续查询的结果和面前查询结果不同，多了或少了几行记录
```



#### （2）事务的隔离级别 - 并发处理能力

| 事务隔离级别              | 回滚覆盖 |   脏读   | 不可重复读 | 提交覆盖 |   幻读   |
| :------------------------ | :------: | :------: | :--------: | :------: | :------: |
| 读未提交 Read Uncommitted |    ×     | 可能发生 |  可能发生  | 可能发生 | 可能发生 |
| 已提交读 Read Committed   |    ×     |    ×     |  可能发生  | 可能发生 | 可能发生 |
| 可重复读 Repeatable Read  |    ×     |    ×     |     ×      |    ×     | 可能发生 |
| 可串行化 Serializable     |    ×     |    ×     |     ×      |    ×     |    ×     |



### 2.4 事务的隔离级别 - 设置

#### （1）查看MySQL当前数据库的事务隔离级别

```mysql
# 查看MySQL当前数据库的事务隔离级别（默认是 Repeatable Read）
show variables like 'tx_isolation';
select @@tx_isolation;
```



#### （2）设置事务隔离级别

```mysql
# 设置事务隔离级别
set tx_isolation = 'READ-UNCOMMITTED';
set tx_isolation = 'READ-COMMITTED';
set tx_isolation = 'REPEATABLE-READ';
set tx_isolation = 'SERIALIZABLE';

# 设置当前 mysql连接会话的事务隔离级别，并不是永久改变的
set session transaction isolation level read uncommitted;
set session transaction isolation level read committed;
set session transaction isolation level repeatable read;
set session transaction isolation level serializable;
```



## 4、事务的控制方案

### 方案1：排队

- 完全顺序执行所有事务的数据库操作，不需要加锁，简单的说就是全局排队
- 序列化执行所有的事务单元，数据库某个时刻只处理一个事务操作
- 特点是强一致性，处理性能低

![image-20211125014646164](image/image-20211125014646164.png)



### 方案2：排他锁/互斥锁

- 引入锁之后就可以支持并发处理事务，如果事务之间涉及到相同的数据项时，会使用排他锁，或叫互斥锁
- 先进入的事务独占数据项以后，其他事务被阻塞，等待前面的事务释放锁
- 在整个事务1结束之前，锁是不会被释放的，所以，事务2必须等到事务1结束之后开始

![image-20211125014736536](image/image-20211125014736536.png)



### 方案3：读写锁（解决读读并发处理）

- 读写锁，可以让读和读并行，而读和写、写和读、写和写这几种之间还是要加排他锁

- 读写锁就是进一步细化锁的颗粒度，区分读操作和写操作，让读和读之间不加锁，这样下面的两个事务就可以同时被执行了

![image-20211125014842084](image/image-20211125014842084.png)



### 方案4：MVCC（解决读读、读写、写读并发处理）

#### （1）MVCC 概述

- MVCC：Multi Version Concurrency Control，多版本控制
- MVCC 是指在数据库中为了实现高并发的数据访问，对数据进行多版本处理，并通过事务的可见性来保证事务能看到自己应该看到的数据版本
- 优点：多版本控制很巧妙地将稀缺资源的独占互斥转换为并发，大大提高了数据库的吞吐量及读写性能
- 如何生成的多版本？每次事务修改操作之前，都会在Undo日志中记录修改之前的数据状态和事务号，该备份记录可以用于其他事务的读取，也可以进行必要时的数据回滚
- MVCC除了支持读和读并行，还支持读和写、写和读的并行，但为了保证一致性，写和写是无法并行的
- MVCC最大的好处是读不加锁，读写不冲突。在读多写少的系统应用中，读写不冲突是非常重要的，极大的提升系统的并发性能
- MVCC只在 Read Commited 和 Repeatable Read 两种隔离级别下工作
- 在事务1开始写操作的时候会copy一个记录的副本，其他事务读操作会读取这个记录副本，因此不会影响其他事务对此记录的读取，实现写和读并行

![image-20211125014937262](image/image-20211125014937262.png)

#### （2）MVCC 实现原理

- 在 MVCC 并发控制中，读操作可以分为两类: 快照读（Snapshot Read）与当前读 （Current Read）

```
快照读：读取的是记录的快照版本（有可能是历史版本），不用加锁。（select）
当前读：读取的是记录的最新版本，并且当前读返回的记录，都会加锁，保证其他事务不会再并发修改这条记录。（select... for update 或lock in share mode，insert/delete/update）
```



#### （3）MVCC 多版本实现案例

- 假设 F1～F6 是表中字段的名字，1～6 是其对应的数据。后面三个隐含字段分别对应该行的隐含ID、事务号和回滚指针，如下图所示

![image-20211125015324526](image/image-20211125015324526.png)

- 假如一条数据是刚 INSERT 的，DB_ROW_ID 为 1，其他两个字段为空。当事务 1 更改该行的数据值时，会进行如下操作，如下图所示

```
用排他锁锁定该行；记录 Redo log；
把该行修改前的值复制到 Undo log，即图中下面的行；
修改当前行的值，填写事务编号，使回滚指针指向 Undo log 中修改前的行
```

![image-20211125015346146](image/image-20211125015346146.png)



- 接下来事务2操作，过程与事务 1 相同，此时 Undo log 中会有两行记录，并且通过回滚指针连在一起，通过当前记录的回滚指针回溯到该行创建时的初始内容，如下图所示

![image-20211125015428334](image/image-20211125015428334.png)



# 第六章 MySQL 锁

## 0、锁分类

- 从操作的粒度分：行级锁、表级锁、页级锁

- 从操作的类型分：读锁/S锁/共享锁、写锁/X锁/排他锁

- 从操作的性能分：乐观锁、悲观锁



## 1、行级锁 - 属于悲观锁

### 1.1 行级锁概述

- 每次操作锁住一行数据
- 锁定粒度最小，发生锁冲突的概率最低，并发度最高
- 应用在InnoDB 存储引擎中



### 1.2 行级锁实现算法

- InnoDB 行锁是通过对索引数据页上的记录加锁实现的

#### （1）RecordLock 记录锁

- 锁定单个行记录的锁
- RC、RR隔离级别都支持

#### （2）GapLock 间隙锁/范围锁

- 锁定索引记录间隙，确保索引记录的间隙不变
- RR隔离级别支持

#### （3）Next-key Lock

- 记录锁和间隙锁组合，同时锁住数据，并且锁住数据前后范围
- RR隔离级别支持



### 1.3 SQL 语句与锁

- 在RR隔离级别，InnoDB对于记录加锁行为都是先采用Next-Key Lock，如果SQL操作含有唯一索引时，Innodb会对Next-Key Lock进行优化，降级为RecordLock，仅锁住索引本身而非范围

#### （1）select ... from 语句

- InnoDB引擎采用MVCC机制实现非阻塞读，所以对于普通的select语句，InnoDB不加锁

#### （2）select ... from … lock in share mode 语句

- 追加了共享锁，InnoDB会使用Next-Key Lock锁进行处理，如果扫描发现唯一索引，可以降级为 RecordLock锁

#### （3）select ... from … for update 语句

- 追加了排他锁，InnoDB 会使用Next-Key Lock锁进行处理，如果扫描发现唯一索引，可以降级为 RecordLock锁

#### （4）update ... where 语句

- InnoDB会使用Next-Key Lock锁进行处理，如果扫描发现唯一索引，可以降级为 RecordLock锁

#### （5）delete ... where 语句

- InnoDB会使用Next-Key Lock锁进行处理，如果扫描发现唯一索引，可以降级为 RecordLock锁

#### （6）insert 语句

- InnoDB会在将要插入的那一行设置一个排他锁RecordLock



### 1.4 举例 - 主键加锁

- InnoDB 引擎，RR隔离级别，update t1 set name=‘XX’ where id=10;
- 加锁行为：仅在id=10的主键索引记录上加X锁

![image-20211125182648057](image/image-20211125182648057.png)





### 1.5 举例 - 唯一键加锁

- InnoDB 引擎，RR隔离级别，update t1 set name=‘XX’ where id=10;
- 加锁行为：现在唯一索引id上加X锁，然后在id=10的主键索引记录上加X锁

![image-20211125182718760](image/image-20211125182718760.png)



### 1.6 举例 - 非唯一键加锁

- InnoDB 引擎，RR隔离级别，update t1 set name=‘XX’ where id=10;

- 加锁行为：对满足id=10条件的记录和主键分别加X锁，然后在(6,c)-(10,b)、(10,b)-(10,d)、(10,d)-(11,f)范围分别加Gap Lock

![image-20211125182805586](image/image-20211125182805586.png)



### 1.7 举例 - 无索引加锁

- InnoDB 引擎，RR隔离级别，update t1 set name=‘XX’ where id=10;
- 加锁行为：表里所有行和间隙都会加X锁。（当没有索引时，会导致全表锁定，因为InnoDB引擎锁机制是基于索引实现的记录锁定）

![image-20211125182858464](image/image-20211125182858464.png)



## 2、表级锁 - 属于悲观锁

### 2.1 表级锁概述

- 每次操作锁住整张表
- 锁定粒度大，发生锁冲突的概率最高，并发度最低
- 应用在 MyISAM、InnoDB、BDB 等存储引擎中



### 2.2 表级锁操作命令

```mysql
# 手动增加表锁
# lock table 表名称 read|write,表名称2 read|write;
lock table t_score read, t_user write;

# 查看表上加过的锁
show open tables;

# 删除表锁
unlock tables;
```



## 3、页级锁

- 每次锁定相邻的一组记录
- 锁定粒度界于表锁和行锁之间，开销和加锁时间界于表锁和行锁之间，并发度一般
- 应用在BDB 存储引擎中



## 行锁、表锁、页锁 与 存储引擎

| 存储引擎 | 行锁 | 表锁 | 页锁 |
| -------- | ---- | ---- | ---- |
| MyISAM   |      | √    |      |
| InnoDB   |      | √    | √    |
| BDB      | √    | √    |      |



## 4、读锁/S锁/共享锁 - 属于悲观锁

- 读锁/S锁/共享锁：属于行级锁，针对同一份数据，多个读操作可以同时进行而不会互相影响
- IS锁/意向读锁：属于表级锁，在对表记录添加 S锁 之前，会先对表添加 IS 锁

- 举例：事务A对记录添加了S锁，可以对记录进行读操作，不能做修改，其他事务可以对该记录追加S锁，但是不能追加X锁，需要追加X锁，需要等记录的S锁全部释放



## 5、写锁/X锁/排他锁 - 属于悲观锁

- 写锁/X锁/排他锁：属于行级锁，当前写操作没有完成前，它会阻断其他写锁和读锁
- IX锁/意向写锁：属于表级锁，在对表记录添加 X锁 之前，会先对表添加 IX 锁
- 举例：事务A对记录添加了X锁，可以对记录进行读和修改操作，其他事务不能对记录做读和修改操作



## 6、乐观锁（解决写写冲突）

- 一般的实现方式是对记录数据版本进行比对，在数据更新提交的时候才会进行冲突检测，如果发现冲突了，则提示错误信息

- 乐观锁是相对于悲观锁而言的，它不是数据库提供的功能，需要开发者自己去实现
- 在数据库操作时，想法很乐观，认为这次的操作不会导致冲突，因此在数据库操作时并不做任何的特殊处理，即不加锁，而是在进行事务提交时再去判断是否有冲突了
- 乐观锁实现的关键点：冲突的检测。
- 对并发率要求高的选择乐观锁



### 6.1 乐观锁实现方式 - 使用版本字段（version）

- 先给数据表增加一个版本(version) 字段，每操作一次，将那条记录的版本号加 1
- version是用来查看被读的记录有无变化，作用是防止记录在业务处理期间被其他事务修改
- 案例

```mysql
# 查询商品信息
select (quantity,version) from products where id=1;

# 根据商品信息生成订单
insert into orders ... 
insert into items ...

# 修改商品库存
update products set quantity=quantity-1,version=version+1 where id=1 and version=#{version};
```



### 6.2 乐观锁实现方式 - 使用时间戳（Timestamp）

- 需要给在数据表增加一个字段，字段类型使用timestamp时间戳
- 在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则提交更新，否则就是版本冲突，取消操作。



## 7、悲观锁 Pessimistic Locking（解决写写冲突）

- 在对一条数据修改的时候，为了避免同时被其他人修改，在修改数据之前先锁定，再修改的控制方式
- 从广义上来讲，前面提到的行锁、表锁、读锁、写锁、共享锁、排他锁等，这些都属于悲观锁
- 对于并发率要求低的可以选择悲观锁



### 7.1 表级读锁

- 当前表追加read锁，当前连接和其他的连接都可以读操作
- 但是当前连接增删改操作会报错，其他连接增删改会被阻塞
- 表级读锁会阻塞写操作，但是不会阻塞读操作



### 7.2 表级写锁

- 当前表追加write锁，当前连接可以对表做增删改查操作，其他连接对该表所有操作都被阻塞（包括查询）
- 表级写锁则会把读和写操作都阻塞



### 7.3 行级读锁/共享锁/S锁

- 多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改
- 使用方法：select ... lock in share mode，只适用查询语句
- 总结：事务使用了共享锁（读锁），只能读取，不能修改，修改操作被阻塞



### 7.4 行级写锁/排他锁/X锁

- 排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能对该行记录做其他操作，也不能获取该行的锁
- 使用方法：SQL末尾加上 for update（innodb引擎默认会在update，delete语句加上for update）
- 行级锁的实现其实是依靠其对应的索引，所以如果操作没用到索引的查询，那么会锁住全表记录。
- 总结：事务使用了排他锁（写锁），当前事务可以读取和修改，其他事务不能修改，也不能获取记录锁（select... for update）。如果查询没有使用到索引，将会锁住整个表记录



## 9、死锁

### 9.0 死锁排查

```mysql
# 查看近期死锁日志信息，使用 explain 查看下SQL执行计划
show engine innodb status;

# 检查锁的状态变量（如果等待次数高，而且每次等待时间长，需要分析系统中为什么会有如此多的等待，然后着手定制优化）
# Innodb_row_lock_current_waits：当前正在等待锁的数量
# Innodb_row_lock_time：从系统启动到现在锁定总时间长度
# Innodb_row_lock_time_avg： 每次等待锁的平均时间
# Innodb_row_lock_time_max：从系统启动到现在等待最长的一次锁的时间
# Innodb_row_lock_waits：系统启动后到现在总共等待的次数
show status like 'innodb_row_lock%';
```



### 9.1 表级死锁

#### （1）产生原因

- 用户A访问表A（锁住了表A），然后又访问表B
- 另一个用户B访问表B（锁住了表B），然后企图访问表A
- 这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了
- 用户A --> A表（表锁）--> B表（表锁）
- 用户B --> B表（表锁）--> A表（表锁）

#### （2）解决方案

- 这种是由于程序的BUG产生的，除了调整的程序的逻辑没有其它的办法。仔细分析程序的逻辑，对于数据库的多表操作时，尽量按照相同的顺序进行处理，尽量避免同时锁定两个资源
- 如操作A和B两张表时，总是按先A后B的顺序处理， 必须同时锁定两个资源时，要保证在任何时刻都应该按照相同的顺序来锁定资源。



### 9.2 行级死锁

#### （1）产生原因1

- 如果在事务中执行了一条没有索引条件的查询，引发全表扫描，把行级锁上升为全表记录锁定（等价于表级锁），多个这样的事务执行后，就很容易产生死锁和阻塞，最终应用系统会越来越慢，发生阻塞或死锁

#### （2）解决方案1

- SQL语句中不要使用太复杂的关联多表的查询
- 使用explain“执行计划"对SQL语句进行分析，对于有全表扫描和全表锁定的SQL语句，建立相应的索引进行优化



#### （3）产生原因2

- 两个事务分别想拿到对方持有的锁，互相等待，于是产生死锁

#### （4）解决方案3

- 在同一个事务中，尽可能做到一次锁定所需要的所有资源
- 按照id对资源排序，然后按顺序进行处理



### 9.3 共享锁转换为排他锁

#### （1）产生原因

- 事务A 查询一条纪录，然后更新该条纪录
- 此时事务B 也更新该条纪录，这时事务B 的排他锁由于事务A 有共享锁，必须等A 释放共享锁后才可以获取，只能排队等待
- 事务A 再执行更新操作时，此处发生死锁，因为事务A 需要排他锁来做更新操作。但是，无法授予该锁请求，因为事务B 已经有一个排他锁请求，并且正在等待事务A 释放其共享锁

```mysql
# 第一步，事务A操作（开启了共享锁）
select * from dept where deptno=1 lock in share mode;

# 第二步，事务B操作（由于1有共享锁，没法获取排他锁，需等待）
update dept set dname='Java' where deptno=1;

# 第三步，事务A操作（发生死锁，因为需要排他锁，事务B的排他锁导致A无法使用排他锁，必须等事务B释放排他锁，而事务B在等待事务A释放共享锁）
update dept set dname='java' where deptno=1;
```

#### （2）解决方案

- 思路1：一般发生在按钮等控件的重复点击，可以点击一次后立刻失效，不让用户重复点击，避免引发同时对同一条记录多次操作
- 思路2：使用乐观锁进行控制

```
- 乐观锁机制避免了长事务中的数据库加锁开销，大大提升了大并发量下的系统性能
- 需要注意的是，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中
```



# 第六章 MySQL 集群架构

## 1、集群架构设计理念

### （1）可用性设计

- 站点高可用，冗余站点
- 服务高可用，冗余服务
- 数据高可用，冗余数据

```mysql
# 保证高可用的方法
- 冗余（数据冗余会带来数据一致性问题）

# 实现高可用的方案
- 主从架构模式：简单灵活，能满足多种需求，比较主流的用法（写操作高可用需要自行处理）
- 双主架构模式：互为主从（有双主双写、双主单写两种方式，建议使用双主单写）
```



### （2）扩展性设计

- 读操作扩展，提高读性能

```mysql
# 方案1：加从库
- 从库过多会引发主库性能损耗
- 建议不要作为长期的扩充方案，应该设法用良好的设计避免持续加从库来缓解读性能问题

# 方案2：分库分表（分为垂直拆分和水平拆分）
- 垂直拆分可以缓解部分压力
- 水平拆分理论上可以无限扩展
```

- 写操作扩展，提高写性能

```mysql
# 方案：分库分表（分为垂直拆分和水平拆分）
- 垂直拆分可以缓解部分压力
- 水平拆分理论上可以无限扩展
```



### （3）一致性设计

- 一致性主要考虑集群中各数据库数据同步以及同步延迟问题

```mysql
# 方案1：不使用从库
- 扩展读性能问题需要单独考虑，否则容易出现系统瓶颈

# 方案2：增加访问路由层
- 可以先得到主从同步最长时间t，在数据发生修改后的t时间内，先访问主库
```



## 2、主从架构模式

### 2.0 架构图

- MySQL 主从架构模式是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点
- MySQL 主从架构用途

```
实时灾备，用于故障切换（高可用）
读写分离，提供查询服务（读扩展）
数据备份，避免影响业务（高可用）
```

- MySQL 主从架构条件

```
从库服务器能连通主库
主库开启binlog日志（设置log-bin参数）
主从server-id不同
```

![image-20211125192751160](image/image-20211125192751160.png)

### 2.1 主从复制/异步复制

- MySQL 默认采用异步复制方式
- 从节点不用一直访问主服务器来更新自己的数据，从节点可以复制主数据库中的所有数据库，或者特定的数据库，或者特定的表

#### （1）主从复制 - 原理图

![image-20211125224902590](image/image-20211125224902590.png)

#### （2）主从复制 - 操作步骤

- 步骤1：主库将数据库的变更操作记录到Binlog日志文件中
- 步骤2：从库读取主库中的Binlog日志文件信息写入到从库的Relay Log中继日志中
- 步骤3：从库读取中继日志信息在从库中进行Replay,更新从库数据信息



#### （3）主从复制 - 异步操作/异步复制

- Master 服务器对数据库更改操作记录在Binlog中，==BinlogDump Thread== 接到写入请求后，读取Binlog信息推送给Slave的I/O Thread
- Slave的 ==I/O Thread== 将读取到的Binlog信息写入到本地Relay Log中。
- Slave的 ==SQL Thread== 检测到Relay Log的变更请求，解析relay log中内容在从库上执行



- 异步复制时序图

![image-20211125225317535](image/image-20211125225317535.png)



#### （4）主从复制 - 存在的问题

- 主库宕机后，数据可能丢失

- 从库只有一个SQL Thread，主库写压力大，复制很可能延时
- 在从库中有两个线程IO Thread和SQL Thread，都是单线程模式工作，因此有了延迟问题（采用多线程机制来加强，减少从库复制延迟，即下面介绍并行复制）



### 2.2 半同步复制（解决数据丢失的问题）

#### （1）半同步复制 - 概述

- 为了提升数据安全，MySQL让Master在某一个时间点等待Slave节点的 ACK（*Ack*nowledgecharacter）消息，接收到ACK消息后才进行事务提交，这也是半同步复制的基础
- MySQL从5.5版本开始引入了半同步复制机制来降低数据丢失的概率



#### （2）MySQL 主库事务写入步骤

- 步骤1：InnoDB Redo File Write (Prepare Write)
- 步骤2：Binlog File Flush & Sync to Binlog File
- 步骤3：InnoDB Redo File Commit（Commit Write）
- 步骤4：Send Binlog to Slave

```
当 Master 不需要关注 Slave 是否接受到 Binlog Event 时，即为传统的主从复制
当 Master 需要在第三步等待 Slave 返回 ACK 时，即为 after-commit，半同步复制（MySQL 5.5引入）
当 Master 需要在第二步等待 Slave 返回 ACK 时，即为 after-sync，增强半同步（MySQL 5.7引入）
```



#### （3）半同步复制 - 时序图

![image-20211125225742350](image/image-20211125225742350.png)



### 2.3 并行复制（解决从库复制延迟的问题）

#### （1）并行复制 - 概述

- 并行复制，enhanced multi-threaded slave，简称MTS

- MySQL从5.6版本开始追加了并行复制功能，目的就是为了改善主从复制延迟问题
- 在 MySQL 5.6、MySQL5.7、MySQL8.0版本上，都是基于上述SQL Thread多线程思想，不断优化，减少复制延迟
- 要使用 MTS 功能，最少升级到 5.7.19 版本



#### （2）并行复制原理 - MySQL 5.6

- MySQL 5.6版本的并行复制，其并行只是基于库的
- 如果用户的MySQL数据库中是多个库，对于从库复制的速度的确可以有比较大的帮助
- 优点：基于库的并行复制，实现相对简单，使用也相对简单些
- 缺点：基于库的并行复制遇到单库多表使用场景就发挥不出优势了，另外对事务并行处理的执行顺序也是个大问题

![image-20211125230331528](image/image-20211125230331528.png)



![image-20211125230342168](image/image-20211125230342168.png)

#### （3）并行复制原理 - MySQL 5.7

- MySQL 5.7是基于组提交的并行复制
- MySQL 5.7才可称为真正的并行复制，这其中最为主要的原因就是slave服务器的回放与master服务器是一致的，即master服务器上是怎么并行执行的slave上就怎样进行并行回放。不再有库的并行复制限制。
- 为了兼容MySQL 5.6基于库的并行复制，5.7引入了新的变量 slave-parallel-type，其可以配置的值有：DATABASE（默认值，基于库的并行复制方式）、LOGICAL_CLOCK（基于组提交的并行复制方式）

- MySQL 5.7中组提交的并行复制究竟是如何实现的？

```
MySQL 5.7是通过对事务进行分组，当事务提交时，它们将在单个操作中写入到二进制日志中。如果多个事务能同时提交成功，那么它们意味着没有冲突，因此可以在Slave上并行执行，所以通过在主库上的二进制日志中添加组提交信息。

MySQL 5.7的并行复制基于一个前提，即所有已经处于prepare阶段的事务，都是可以并行提交的。这些当然也可以在从库中并行提交，因为处理这个阶段的事务都是没有冲突的。在一个组里提交的事务，一定不会修改同一行。这是一种新的并行复制思路，完全摆脱了原来一直致力于为了防止冲突而做的分发算法，等待策略等复杂的而又效率底下的工作。

InnoDB事务提交采用的是两阶段提交模式。一个阶段是prepare，另一个是commit。
```

- 那么如何知道事务是否在同一组中，生成的Binlog内容如何告诉Slave哪些事务是可以并行复制的？

```
在MySQL 5.7版本中，其设计方式是将组提交的信息存放在GTID中。为了避免用户没有开启GTID功能（gtid_mode=OFF），MySQL 5.7又引入了称之为Anonymous_Gtid的二进制日志event类型 ANONYMOUS_GTID_LOG_EVENT
```

- 通过 mysqlbinlog 工具分析 binlog 日志，可以发现组提交的内部信息

```
MySQL 5.7二进制日志较之原来的二进制日志内容多了last_committed和 sequence_number

last_committed表示事务提交的时候，上次事务提交的编号
如果事务具有相同的last_committed，表示这些事务都在一组内，可以进行并行的回放
```

![image-20211125230716256](image/image-20211125230716256.png)



#### （4）并行复制原理 - MySQL 8.0

- MySQL8.0 是基于write-set的并行复制

- MySQL会有一个集合变量来存储事务修改的记录信息（主键哈希值），所有已经提交的事务所修改的主键值经过hash后都会与那个变量的集合进行对比，来判断改行是否与其冲突，并以此来确定依赖关系，没有冲突即可并行。这样的粒度，就到了 row级别了，此时并行的粒度更加精细，并行的速度会更快。

  

#### （5）并行复制配置与调优

```mysql
# 用于控制集合变量的大小
binlog_transaction_dependency_history_size

# 用于控制binlog文件中事务之间的依赖关系，即 last_committed 值
# COMMIT_ORDERE: 基于组提交机制
# WRITESET: 基于写集合机制
# WRITESET_SESSION: 基于写集合，比writeset多了一个约束，同一个session中的事务last_committed按先后顺序递增
binlog_transaction_depandency_tracking

# 用于控制事务的检测算法，参数值为：OFF、 XXHASH64、MURMUR32
transaction_write_set_extraction

# 开启MTS功能后，务必将参数master_info_repostitory设置为TABLE，这样性能可以有50%~80%的提升
# 这是因为并行复制开启后对于元master.info这个文件的更新将会大幅提升，资源的竞争也会变大
master_info_repository

# 将slave_parallel_workers设置为0，则MySQL 5.7退化为原单线程复制
# 将slave_parallel_workers设置为1，则SQL线程功能转化为coordinator线程，但是只有1个worker线程进行回放，也是单线程复制
# 这两种性能却又有一些的区别，因为多了一次coordinator线程的转发，因此slave_parallel_workers=1的性能反而比0还要差
slave_parallel_workers

# MySQL 5.7后的MTS可以实现更小粒度的并行复制，但需要将slave_parallel_type设置为LOGICAL_CLOCK，但仅仅设置为LOGICAL_CLOCK也会存在问题，因为此时在slave上应用事务的顺序是无序的，和relay log中记录的事务顺序不一样，这样数据一致性是无法保证的，为了保证事务是按照relay log中记录的顺序来回放，就需要开启参数slave_preserve_commit_order。
slave_preserve_commit_order
```

- 开启enhanced multi-threaded slave

```properties
slave-parallel-type=LOGICAL_CLOCK
slave-parallel-workers=16
slave_pending_jobs_size_max=2147483648 slave_preserve_commit_order=1
master_info_repository=TABLE
relay_log_info_repository=TABLE
relay_log_recovery=ON
```



#### （6）并行复制监控

- MySQL 5.7在 performance_schema 库中提供了很多元数据表，可以更详细的监控并行复制过程

```mysql
show tables like 'replication%';

# 查看 worker 进程的工作情况
select * from replication_applier_status_by_worker;

```





## 3、读写分离架构



## 4、双主架构模式



## 5、分库分表



# 第七章 MyCat 分库分表

## 1、MyCat 简介

## 2、MyCat 核心概念

## 3、server.xml 配置

## 4、schema.xml 配置

## 5、rule.xml 配置

## 6、MyCat 事务



# 第八章 ShardingSphere 数据分片

## 1、ShardingSphere 简介

## 2、Sharding-JDBC

## 3、数据分片

## 4、读写分离

## 5、强制路由

## 6、数据脱敏

## 7、分布式事务

## 8、SPI 加载

## 9、编排治理

## 10、Sharding-Proxy



# 第九章 MySQL 运维工具

## 1、Yearning

## 2、canal

## 3、DataX

## 4、percona-toolkit

## 5、MySQLMTOP

## 6、ELK

## 7、Prometheus



# 第十章 MySQL 性能优化

## 0、优化维度

```
优化成本：硬件升级 > 系统配置 > 表结构设计 > SQL语句及索引
优化效果：硬件升级 < 系统配置 < 表结构设计 < SQL语句及索引
```



![image-20210527105200808](image/image-20210527105200808.png)

## 1、系统配置优化

### 1.1 保证从内存中读取数据

```
MySQL会在内存中保存一定的数据，通过LRU算法将不常访问的数据保存在硬盘文件中。

尽可能的扩大内存中的数据量，将数据保存在内存中，从内存中读取数据，可以提升MySQL性能

扩大innodb_buffer_pool_size，能够全然从内存中读取数据。最大限度降低磁盘操作。
```

- 修改 innodb_buffer_pool_size 的值

```mysql
# 确定 innodb_buffer_pool_size 的容量
show global status like 'innodb_buffer_pool_pages_%';

# 修改 my.cnf，默认为128M，理论上可以扩大到内存的3/4或4/5
innodb_buffer_pool_size = 750M
```

- 如果是专用的 MySQL Server 可以禁用 SWAP

```mysql
# 查看swap
cat /proc/swaps

# 关闭所有交换设备和文件
swapoff -a
```



### 1.2 数据预热

- 原理

```
- 默认情况，仅仅有某条数据被读取一次，才会缓存在 innodb_buffer_pool。
- 所以，数据库刚刚启动，须要进行数据预热，将磁盘上的全部数据缓存到内存中。
- 数据预热能够提高读取速度
```

- 步骤1：对于 InnoDB 数据库，创建数据预热的脚本 loadtomem.sql，保存到/root/下

```mysql
# InnoDB 数据库，进行数据预热的脚本
select distinct concat('select ', ndxcollist, ' from ', db, '.', tb, ' order by ', ndxcollist,
                       ';') selectquerytoloadcache
from (select engine,
             table_schema                                    db,
             table_name                                      tb,
             index_name,
             group_concat(column_name order by seq_in_index) ndxcollist
      from (select b.engine,
                   a.table_schema,
                   a.table_name,
                   a.index_name,
                   a.column_name,
                   a.seq_in_index
            from information_schema.statistics a
                     inner join (select engine, table_schema, table_name
                                 from information_schema.tables
                                 where engine = 'innodb') b using (table_schema, table_name)
            where b.table_schema not in ('information_schema', 'mysql')
            order by table_schema, table_name, index_name, seq_in_index) a
      group by table_schema, table_name, index_name) aa
order by db, tb;
```

- 步骤2：执行命令

```mysql
mysql -uroot -proot -AN < /root/loadtomem.sql > /root/loadtomem.sql
```

- 步骤3：在需要数据预热时，比如重启数据库，执行命令

```mysql
mysql -uroot < /root/loadtomem.sql > /dev/null 2>&1
```



### 1.3 降低磁盘写入次数

```
（1）增大redolog，减少落盘次数
- innodb_log_file_size 设置为 0.25 * innodb_buffer_pool_size

（2）通用查询日志、慢查询日志可以不开 ，bin-log开
- 生产中不开通用查询日志，遇到性能问题开慢查询日志

（3）写redolog策略 innodb_flush_log_at_trx_commit设置为0或2
- 如果不涉及非常高的安全性 (金融系统)，或者基础架构足够安全，或者事务都非常小，都能够用 0 或者 2 来减少磁盘操作
```



### 1.4 提高磁盘读写性能

```mysql
使用SSD或者内存磁盘
```



## 2、表结构设计优化

### 2.1 设计中间表

```
设计中间表，一般针对于统计分析功能，或者实时性不高的需求（OLTP、OLAP）
```

### 2.2 设计冗余字段

```
为减少关联查询，创建合理的冗余字段（创建冗余字段还需要注意数据一致性问题）
```

### 2.3 拆表

```
对于字段太多的大表，考虑拆表（比如一个表有100多个字段）
对于表中经常不被使用的字段或者存储数据比较多的字段，考虑拆表
```

### 2.4 主键优化

```
每张表建议都要有一个主键（主键索引），而且主键类型最好是int类型，建议自增主键（不考虑分布式系统的情况下 雪花算法）
```

### 2.5 字段的设计

```
- 数据库中的表越小，在它上面执行的查询也就会越快
- 因此，在创建表的时候，为了获得更好的性能，可以将表中字段的宽度设得尽可能小
- 尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值
- 对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，而数值型数据被处理起来的速度要比文本类型快得多
```



## 3、SQL 语句优化

### 3.1 SQL语句中IN包含的值不应过多

```
MySQL对于IN做了相应的优化，即将IN中的常量全部存储在一个数组里面，而且这个数组是排好的。但是如果数值较多，产生的消耗也是比较大的
```

### 3.2 当只需要一条数据的时候，使用limit 1

```mysql
# 当只需要一条数据的时候，使用limit 1
# limit 可以停止全表扫描
select id,
       username,
       pwd,
       create_user,
       create_time,
       update_user,
       update_time,
       effective
from tb_admin_info
order by update_time
limit 1;
```

### 3.3 尽量用union all代替union

```
union和union all的差异主要是前者需要将结果集合并后再进行唯一性过滤操作，这就会涉及到排序，增加大量的CPU运算，加大资源消耗及延迟。当然，union all的前提条件是两个结果集没有重复数据。
```

### 3.4 区分in和exists、not in和not exists

```mysql
- 区分in和exists主要是造成了驱动顺序的改变（这是性能变化的关键），如果是exists，那么以外层表为驱动表，先被访问，如果是IN，那么先执行子查询
- 所以IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况。
- 关于not in和not exists，推荐使用not exists，不仅仅是效率问题，not in可能存在逻辑问题。

如何高效的写出一个替代not exists的SQL语句？
# 原来的sql
select colname … from A表 where a.id not in (select b.id from B表)
# 高效sql
select colname … from A表 Left join B表 on where a.id = b.id where b.id is null
```

### 3.5 使用合理的分页方式以提高分页的效率

```mysql
# 分页使用 limit m,n 尽量让m 小
# 利用主键的定位，可以减小m的值
select * from tb_admin_info where id>6 limit 2;
```

### 3.6 分段查询

```
一些用户选择页面中，可能一些用户选择的范围过大，造成查询缓慢。主要的原因是扫描行数过多。这
个时候可以通过程序，分段进行查询，循环遍历，将结果合并处理进行展示
```

### 3.7 避免隐式类型转换

```
避免隐式类型转换
where子句中出现column字段的类型和传入的参数类型不一致的时候发生的类型转换，建议先确定where中的参数类型
```

### 3.8 使用JOIN优化

```mysql
LEFT JOIN A表为驱动表，INNER JOIN MySQL会自动找出那个数据少的表作用驱动表，RIGHT JOIN B 表为驱动表

（1）MySQL中没有full join，可以用以下方式来解决
select * from A left join B on B.name = A.namewhere B.name is null union all select * from B;

（2）尽量使用inner join，避免left join
参与联合查询的表至少为2张表，一般都存在大小之分。如果连接方式是inner join，在没有其他过滤条件的情况下MySQL会自动选择小表作为驱动表，但是left join在驱动表的选择上遵循的是左边驱动右边的原则，即left join左边的表名为驱动表。

（3）合理利用索引
被驱动表的索引字段作为on的限制字段

（4）利用小表去驱动大表
```

- 从原理图能够直观的看出如果能够减少驱动表的话，减少嵌套循环中的循环次数，以减少 IO总量及CPU运算的次数

![image-20210527155802515](image/image-20210527155802515.png)



## 4、索引优化

### 4.1 EXPLAIN查看索引使用情况

```mysql
# 使用【慢查询日志】功能，获取所有查询时间比较长的SQL语句 3秒-5秒
# 使用explain查看有问题的SQL的执行计划，重点查看索引使用情况
explain select * from tb_admin_info where username='td' and pwd='123';
```

- 查询结果列表的列字段解释

```
- type列，连接类型。一个好的SQL语句至少要达到range级别。杜绝出现all级别。
- key列，使用到的索引名。如果没有选择索引，值是NULL。可以采取强制索引方式。
- key_len列，索引长度。
- rows列，扫描行数。该值是个预估值。
- extra列，详细说明。注意，常见的不太友好的值，如下：Using filesort，Using temporary 。

常见的索引：
where 字段 、组合索引（最左前缀）、索引下推（非选择行不加锁）、覆盖索引（不回表）on 两边、排序、分组统计
```

### 4.2 SELECT 语句务必指明字段名称

```
- SELECT * 增加很多不必要的消耗（CPU、IO、内存、网络带宽）
- 减少了使用覆盖索引的可能性
- 当表结构发生改变时，前端也需要更新

所以要求直接在select后面接上字段名
```

### 4.3 排序字段加索引

```mysql
# 排序字段加索引
explain select * from tb_admin_info where username='td' order by username ;
```

### 4.4 如果限制条件中其他字段没有索引，尽量少用or

```mysql
# 如果限制条件中其他字段没有索引，尽量少用or
# or两边的字段中，如果有一个不是索引字段，会造成该查询不走索引的情况
explain select * from tb_admin_info where username='td' or pwd='123';
```

### 4.5 不使用 ORDER BY RAND()

```mysql
# ORDER BY RAND() 不走索引
select * from tb_admin_info order by rand() limit 5;
```

### 4.6 不建议使用%前缀模糊查询

```
例如LIKE“%name”或者LIKE“%name%”，这种查询会导致索引失效而进行全表扫描。但是可以使用LIKE“name%”。
那么如何解决这个问题呢，答案：使用全文索引或ES全文检索
```

### 4.7 避免在where子句中对字段进行表达式操作

```mysql
# 避免在where子句中对字段进行表达式操作
# 对字段就行了算术运算，这会造成引擎放弃使用索引
select * from tb_admin_info where pwd * 2 = 246;
# 建议修改为
select * from tb_admin_info where pwd = 246/2;
```

### 4.8 对于联合索引来说，要遵守最左前缀法则

```
对于联合索引来说，要遵守最左前缀法则

举列来说索引含有字段id、name、school，可以直接用id字段，也可以id、name这样的顺序，但是name;school都无法使用这个索引。所以在创建联合索引的时候一定要注意索引字段顺序，常用的查询字段放在最前面。
```

### 4.9 必要时可以使用force index来强制查询走某个索引

```
必要时可以使用force index来强制查询走某个索引
有的时候MySQL优化器采取它认为合适的索引来检索SQL语句，但是可能它所采用的索引并不是我们想要的。这时就可以采用forceindex来强制优化器使用我们制定的索引
```

### 4.10 注意范围查询语句

```
注意范围查询语句
对于联合索引来说，如果存在范围查询，比如between、>、<等条件时，会造成后面的索引字段失效
```



## 5、查询优化

### 5.1 慢查询优化

#### （1）查看是否开启慢查询日志

```mysql
# 查看 MySQL 数据库是否开启了慢查询日志
# 查看慢查询日志文件的存储位置
show variables like 'slow_query_log%';
```



#### （2）开启慢查询日志

```mysql
# 开启慢查询日志
set global slow_query_log = on;
set global slow_query_log_file = 'oak-slow.log';
set global log_queries_not_using_indexes = on;  # 表示会记录没有使用索引的查询SQL。前提是slow_query_log的值为ON，否则不会奏效
set long_query_time = 10;  # 指定慢查询的阀值，单位秒。如果SQL执行时间超过阀值，就属于慢查询，会记录到日志文件中

# ============================  慢查询日志 ============================
select * from slow;
```



#### （3）查看慢查询日志

##### 方法1：直接使用文本编辑器打开 slow.log 日志即可

##### 方法2：使用 mysqldumpslow 查看

```bash
perl mysqldumpslow.pl -t 5 -s at E:\06_study\MySQL_5.7.19\data\OAK-slow.log
```



#### （4）慢查询日志项

- time：日志记录的时间 
- User@Host：执行的用户及主机
- Query_time：执行的时间
- Lock_time：锁表时间
- Rows_sent：发送给请求方的记录数，结果数量
- Rows_examined：语句扫描的记录条数
- SET timestamp：语句执行的时间点
- select....：执行的具体的SQL语句



#### （5）慢查询优化方案

- 提高索引过滤性：索引过滤性与索引字段、表的数据量、表设计结构都有关系

```mysql
select * from student;

# 默认
explain select * from student where age = 18 and name like 'a%';  # rows - 5120

# 优化1：追加 name 索引
create index age_1 on student(age);
explain select * from student where age = 18 and name like 'a%';  # rows - 3072

# 优化2：追加 age,name 索引
create index age_name on student(age, name);
explain select * from student where age = 18 and name like 'a%';  # rows - 1706

# 优化3：为表添加 first_name 虚拟列，以及联合索引(first_name,age)
alter table student add first_name varchar(2) generated always as (left(name, 1)), add index(first_name, age);
explain select * from student where age = 18 and first_name = 'a%';  # rows - 1
```



#### （6）慢查询判断

- 如何判断是否为慢查询？

```
- MySQL判断一条语句是否为慢查询语句，主要依据SQL语句的执行时间
- 它把当前语句的执行时间跟 long_query_time 参数做比较
- 如果语句的执行时间 > long_query_time，就会把这条执行语句记录到慢查询日志里面

long_query_time 参数的默认值是 10s，该参数值可以根据自己的业务需要进行调整。
```

- 如何判断是否应用了索引？

```
- SQL语句是否使用了索引，可根据SQL语句执行过程中有没有用到表的索引
- 可通过 explain命令分析查看，检查结果中的 key 值，是否为NULL
```



#### （7）慢查询原因总结

- 全表扫描引起的慢查询（通过 explain 分析后，type = all 的 SQL 语句）
- 全索引扫描引起的慢查询（通过 explain 分析后，type = index 的 SQL 语句）
- 索引过滤性不好引起的慢查询（可以通过优化索引字段选型、数据量和状态、表设计解决）

```
- 在使用索引时，不要只关注是否起作用，应该关心索引是否减少了查询扫描的数据行数
- 如果扫描行数减少了，效率才会得到提升
- 对于一个大表，不止要创建索引，还要考虑索引过滤性，过滤性好，执行速度才会快。
```

- 频繁的回表查询开销引起的慢查询（尽量少用select *，使用覆盖索引）



### 5.2 分页查询优化

#### （1）SQL查询诊断分析工具

```mysql
# 查看是否开启，SQL查询诊断分析工具
show variables like 'profiling';

# 打开，SQL查询诊断分析工具
set profiling = 1;

# 查看 sql 执行时间
show profiles;
```



#### （2）一般性分页

- 一般的分页查询使用简单的 limit 子句就可以实现

```mysql
# 第一个参数指定第一个返回记录行的偏移量，注意从0开始；
# 第二个参数指定返回记录行的最大数目；
# 如果只给定一个参数，它表示返回最大的记录行数目
# select * from 表名 limit [offset,] rows;

```

- 在查询记录时，返回记录量低于100条，查询时间基本没有变化，差距不大。随着查询记录量越大，所花费的时间也会越来越多。

```mysql
# 偏移量固定，返回记录数变化
select * from slow limit 10000,1;
select * from slow limit 10000,10;
select * from slow limit 10000,100;
select * from slow limit 10000,1000;
select * from slow limit 10000,10000;
```

- 在查询记录时，如果查询记录量相同，偏移量超过100后就开始随着偏移量增大，查询时间急剧的增加。（这种分页查询机制，每次都会从数据库第一条记录开始扫描，越往后查询越慢，而且查询的数据越多，也会拖慢总查询速度。）

```mysql
# 偏移量变化，返回记录数固定
select * from slow limit 1,100;
select * from slow limit 10,100;
select * from slow limit 100,100;
select * from slow limit 1000,100;
select * from slow limit 10000,1000;
```



#### （3）分页查询优化方案

```mysql
# 方式1：利用覆盖索引优化
select id from slow limit 10000,100;

# 方式2：利用子查询优化
# 使用了id做主键比较(id>=)，并且子查询使用了覆盖索引进行优化
select * from slow where id>= (select id from slow limit 10000,1) limit 100;
```



## 6、复杂SQL优化实战











> 参考资料

https://www.runoob.com/mysql/mysql-tutorial.html

http://c.biancheng.net/view/7200.html

https://blog.csdn.net/u013235478/article/details/50625677



