> 当前位置：【Java】09_Architecture_Distributed（分布式架构） -> 9.2_Netty（分布式通信）



# 第一章 Netty 简介

## 1、原生 NIO 的问题

```
（1）NIO 的类库和 API 繁杂，使用麻烦：需要熟练掌握 Selector、ServerSocketChannel、SocketChannel、ByteBuffer等
（2）需要具备其他的额外技能：要熟悉 Java 多线程编程，因为 NIO 编程涉及到 Reactor 模式，必须对多线程和网络编程非常熟悉，才能编写出高质量的 NIO 程序
（3）开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等
（4）JDK NIO 的 Bug：臭名昭著的 Epoll Bug，它会导致 Selector 空轮询，最终导致 CPU 100%，直到JDK 1.7版本该问题仍旧存在，没有被根本解决

在NIO中通过Selector的轮询当前是否有IO事件，根据JDK NIO api描述，Selector的select方法会一直阻塞，直到IO事件达到或超时，但是在Linux平台上这里有时会出现问题，在某些场景下select方法会直接返回，即使没有超时并且也没有IO事件到达，这就是著名的epollbug，这是一个比较严重的bug，它会导致线程陷入死循环，会让CPU飙到100%，极大地影响系统的可靠性，到目前为止，JDK都没有完全解决这个问题
```



## 2、Netty 概述

```
- Netty 是由 JBOSS 提供的一个 Java 开源框架
- Netty 提供异步的、基于事件驱动的网络应用程序框架，用以快速开发高性能、高可靠性的网络 IO 程序
- Netty 是一个基于 NIO 的网络编程框架，使用 Netty 可以快速、简单的开发出一个网络应用，相当于简化和流程化了 NIO 的开发过程
- 作为当前最流行的 NIO 框架，Netty 在互联网领域、大数据分布式计算领域、游戏行业、 通信行业等获得了广泛的应用，知名的 Elasticsearch 、Dubbo 框架内部都采用了 Netty
```

![image-20210518110357679](image/image-20210518110357679.png)

- 优点

```
- 设计优雅，提供阻塞和非阻塞的 Socket
- 零拷贝、提供灵活可拓展的事件模型
- 提供高度可定制的线程模型
- 具备更高的性能和更大的吞吐量，使用零拷贝技术最小化不必要的内存复制，减少资源的消耗
- 提供安全传输、压缩、大文件传输、编解码支持等等
- 支持多种主流协议（TCP、UDP、HTTP、WebSocket等）
- 预置多种编解码功能，支持用户开发私有协议
```



## 3、线程模型

### 3.1 线程模型类型

```
不同的线程模式，对程序的性能有很大影响，目前存在的线程模型有：
- 类型1：传统阻塞 I/O 服务模型
- 类型2：Reactor 模型

根据 Reactor 的数量和处理资源池线程的数量不同，有 3 种典型的实现
- 实现1：单 Reactor 单线程
- 实现2：单 Reactor 多线程
- 实现3：主从 Reactor 多线程
- 实现4：Netty 线程模型：基于主从 Reactor 多线程模式，并做了一定的改进
```



### 3.2 类型1：传统阻塞 I/O 服务模型

```
采用阻塞 IO 模式获取输入的数据, 每个连接都需要独立的线程完成数据的输入、业务处理和数据返回工作

存在问题:
1. 当并发数很大，就会创建大量的线程，占用很大系统资源
2. 连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在 read 操作，造成线程资源浪费
```

![image-20210518112232496](image/image-20210518112232496.png)

### 3.3 类型2：Reactor 模型

```
Reactor 模式：通过一个或多个输入同时传递给服务处理器的模式，服务器端程序处理传入的多个请求，并将它们同步分派到相应的处理线程， 因此 Reactor 模式也叫 Dispatcher模式
Reactor 模式使用 IO 复用监听事件，收到事件后，分发给某个线程(进程)，这点就是网络服务器高并发处理关键
```

#### 实现1：单 Reactor 单线程

- 流程

```
- Selector 可以实现应用程序通过一个阻塞对象监听多路连接请求
- Reactor 对象通过 Selector 监控客户端请求事件，收到事件后通过 Dispatch 进行分发是建立连接请求事件，由 Acceptor 通过 Accept 处理连接请求，然后创建一个 Handler 对象处理连接完成后的后续业务处理
- Handler 会完成 Read→业务处理→Send 的完整业务流程
```

![image-20210518132112774](image/image-20210518132112774.png)

- 优点

```
- 模型简单
- 没有多线程、进程通信、竞争的问题，全部都在一个线程中完成
```

- 缺点

```
- 性能问题: 只有一个线程，无法完全发挥多核 CPU 的性能，Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈

- 可靠性问题: 线程意外终止或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障
```



#### 实现2：单 Reactor 多线程

- 流程

```
Reactor 对象通过 selector 监控客户端请求事件, 收到事件后，通过 dispatch 进行分发
- 如果建立连接请求, 则由 Acceptor 通过 accept 处理连接请求
- 如果不是连接请求，则由 reactor 分发调用连接对应的 handler 来处理
- handler 只负责响应事件，不做具体的业务处理, 通过 read 读取数据后，会分发给后面的

worker 线程池的某个线程处理业务
- worker 线程池会分配独立线程完成真正的业务，并将结果返回给 handler
- handler 收到响应后，通过 send 将结果返回给 client
```

![image-20210518132642647](image/image-20210518132642647.png)

- 优点

```
- 可以充分的利用多核 cpu 的处理能力
```

- 缺点

```
- 多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行，在高并发场景容易出现性能瓶颈
```



#### 实现3：主从 Reactor 多线程

- 流程

```
- Reactor 主线程 MainReactor 对象通过 select 监听客户端连接事件，收到事件后，通过 Acceptor 处理客户端连接事件

- 当 Acceptor 处理完客户端连接事件之后（与客户端建立好 Socket 连接），MainReactor 将连接分配给 SubReactor（即：MainReactor 只负责监听客户端连接请求，和客户端建立连接之后将连接交由 SubReactor 监听后面的 IO 事件)

- SubReactor 将连接加入到自己的连接队列进行监听，并创建 Handler 对各种事件进行处理
- 当连接上有新事件发生的时候，SubReactor 就会调用对应的 Handler 处理
- Handler 通过 read 从连接上读取请求数据，将请求数据分发给 Worker 线程池进行业务处理
- Worker 线程池会分配独立线程来完成真正的业务处理，并将处理结果返回给 Handler
- Handler 通过 send 向客户端发送响应数据
- 一个 MainReactor 可以对应多个 SubReactor，即一个 MainReactor 线程可以对应多个 SubReactor 线程
```

![image-20210518133753119](image/image-20210518133753119.png)

- 优点

```
- MainReactor 线程与 SubReactor 线程的数据交互简单职责明确，MainReactor 线程只需要接收新连接，SubReactor 线程完成后续的业务处理

- MainReactor 线程与 SubReactor 线程的数据交互简单， MainReactor 线程只需要把新连接传给 SubReactor 线程，SubReactor 线程无需返回数据

- 多个 SubReactor 线程能够应对更高的并发请求
```

- 缺点

```
- 编程复杂度较高

但是由于其优点明显，在许多项目中被广泛使用，包括Nginx、Memcached、Netty 等。这种模式也被叫做服务器的 1+M+N 线程模式，即使用该模式开发的服务器包含一个（或多个，1 只是表示相对较少）连接建立线程 +M个IO线程 +N个业务处理线程。这是业界成熟的服务器程序设计模式。
```



#### 实现4：Netty 线程模型

##### （1）简单版 Netty 模型

![image-20210518140750970](image/image-20210518140750970.png)



```
- BossGroup 线程维护 Selector，ServerSocketChannel 注册到这个 Selector 上，只关注连接建立请求事件（主 Reactor）

- 当接收到来自客户端的连接建立请求事件的时候，通过 ServerSocketChannel.accept 方法获得对应的 SocketChannel，并封装成 NioSocketChannel 注册到 WorkerGroup 线程中的 Selector，每个 Selector 运行在一个线程中（从 Reactor） 

- 当 WorkerGroup 线程中的 Selector 监听到自己感兴趣的 IO 事件后，就调用 Handler 进行处理
```



##### （2）进阶版 Netty 模型

![image-20210518141918802](image/image-20210518141918802.png)



```
有两组线程池：BossGroup 和 WorkerGroup
- BossGroup 中的线程专门负责和客户端建立连接
- WorkerGroup 中的线程专门负责处理连接上的读写

BossGroup 和 WorkerGroup 含有多个不断循环的执行事件处理的线程，每个线程都包含一个 Selector，用于监听注册在其上的 Channel

每个 BossGroup 中的线程循环执行以下三个步骤
- 轮询注册在其上的 ServerSocketChannel 的 accept 事件（OP_ACCEPT 事件）
- 处理 accept 事件，与客户端建立连接，生成一个 NioSocketChannel，并将其注册到 WorkerGroup 中某个线程上的 Selector 
- 再去以此循环处理任务队列中的下一个事件

每个 WorkerGroup 中的线程循环执行以下三个步骤
- 轮询注册在其上的 NioSocketChannel 的 read/write 事件（OP_READ/OP_WRITE 事件）
- 在对应的 NioSocketChannel 上处理 read/write 事件
- 再去以此循环处理任务队列中的下一个事件
```



##### （3）详细版 Netty 模型

![image-20210518143732253](image/image-20210518143732253.png)

```
Netty 抽象出两组线程池：BossGroup 和 WorkerGroup，也可以叫做 BossNioEventLoopGroup 和 WorkerNioEventLoopGroup

每个线程池中都有 NioEventLoop 线程

BossGroup 中的线程专门负责和客户端建立连接，WorkerGroup 中的线程专门负责处理连接上的读写

BossGroup 和 WorkerGroup 的类型都是 NioEventLoopGroup

NioEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每个事件循环就是一个 NioEventLoop

NioEventLoop 表示一个不断循环的执行事件处理的线程，每个 NioEventLoop 都包含一个 Selector，用于监听注册在其上的 Socket 网络连接（Channel）

NioEventLoopGroup 可以含有多个线程，即可以含有多个 NioEventLoop

每个 BossNioEventLoop 中循环执行以下三个步骤
- select：轮训注册在其上的 ServerSocketChannel 的 accept 事件（OP_ACCEPT 事件）
- processSelectedKeys：处理 accept 事件，与客户端建立连接，生成一个NioSocketChannel，并将其注册到某个WorkerNioEventLoop 上的 Selector 上
- runAllTasks：再去以此循环处理任务队列中的其他任务

每个 WorkerNioEventLoop 中循环执行以下三个步骤
- select：轮训注册在其上的 NioSocketChannel 的 read/write 事件（OP_READ/OP_WRITE 事件）
- processSelectedKeys：在对应的 NioSocketChannel 上处理 read/write 事件
- runAllTasks：再去以此循环处理任务队列中的其他任务

在以上两个 processSelectedKeys 步骤中，会使用 Pipeline（管道），Pipeline 中引用了 Channel，即通过 Pipeline 可以获取到对应的 Channel，Pipeline 中维护了很多的处理器（拦截处理器、过滤处理器、自定义处理器等）
```



## 4、Netty API

### 4.1 ChannelHandler 接口

![image-20210518145414626](image/image-20210518145414626.png)

- Netty 开发中需要自定义一个 Handler 类去实现 ChannelHandle 接口或其子接口或其实现类，然后重写相应方法实现业务逻辑

```java
public void channelActive(ChannelHandlerContext ctx)，通道就绪事件
public void channelRead(ChannelHandlerContext ctx, Object msg)，通道读取数据事件
public void channelReadComplete(ChannelHandlerContext ctx) ，数据读取完毕事件
public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause)，通道发生异常事件
```



### 4.2 ChannelPipeline





### 4.3 ChannelHandlerContext

### 4.4 ChannelOption

### 4.5 ChannelFuture

### 4.6 EventLoopGroup 和实现类 NioEventLoopGroup

### 4.7 ServerBootstrap 和 Bootstrap

### 4.8 Unpooled



## Netty 异步模型

## Netty  编解码器

## Netty中粘包和拆包的解决方案



# 第二章 Netty 开发案例 

## Netty 开发案例 - 入门

## Netty 开发案例 - 群聊天室

## 基于 Netty 的 Http 服务器开发

## 基于 Netty 的 WebSocket 开发网页版聊天室

## 基于 Netty 实现 RPC 框架



# 第三章 Netty 源码分析





