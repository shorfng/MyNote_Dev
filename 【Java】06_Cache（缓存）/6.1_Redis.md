> 当前位置：【Java】06_Cache（缓存）-> 6.1_Redis

# Redis 下载安装和配置

## 0、下载地址

- 官网地址：http://redis.io/
- 中文官网地址：http://www.redis.cn/
- 下载地址：http://download.redis.io/releases/



## 1、Docker - Redis 安装和配置

### 1.1 下载镜像

- https://hub.docker.com/_/redis

```bash
docker pull redis:6.2.5
```

### 1.2 单机搭建

#### Linux

```bash
# 创建文件夹
mkdir -p /docker_data/redis/{data,conf}

# 运行容器 - Linux 系统
docker run -d -p 6379:6379 -v /docker_data/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /docker_data/redis/data:/data --name redis redis:6.2.5 redis-server  /usr/local/etc/redis/redis.conf --appendonly yes
```

- 命令解释

```bash
# 在容器执行redis-server启动命令，并打开redis持久化配置
redis-server --appendonly yes
```

#### Mac

```bash
# 创建文件夹
mkdir -p /Users/td/Documents/03_DevTools/docker_data/redis/{data,conf}

# 运行容器 - Mac 系统
docker run -d -p 6379:6379 -v /Users/td/Documents/03_DevTools/docker_data/redis/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /Users/td/Documents/03_DevTools/docker_data/redis/data:/data --name redis redis:6.2.5 redis-server  /usr/local/etc/redis/redis.conf --appendonly yes
```

### 1.3 集群搭建

#### 步骤1：准备工作

```bash
# 创建网络
docker network create redis-net

# 创建集群目录
mkdir /docker_data/redis-cluster

# 创建 Redis 配置的模板文件
cd /docker_data/redis-cluster
vi redis-config.tmpl
```

- redis-config.tmpl

```properties
# 端口
port ${PORT}

# 非保护模式
protected-mode no

# 启用集群模式
cluster-enabled yes
cluster-config-file nodes.conf

# 超时时间
cluster-node-timeout 5000
cluster-announce-ip 192.168.126.200
cluster-announce-port ${PORT}
cluster-announce-bus-port 1${PORT}
# 开启aof持久化策略
appendonly yes

# 后台运行
#daemonize yes 
pidfile  /var/run/redis_${PORT}.pid
```

- 创建 shell 脚本，用于批量创建容器

```bash
vi install.sh
```

- install.sh

```sh
#!/bin/bash
# 在 /docker_data/redis-cluster 下生成conf和data目标，并生成配置信息
for port in `seq 7001 7006`; 
do 
  mkdir -p ./${port}/conf && PORT=${port} envsubst < ./redis-config.tmpl > ./${port}/conf/redis.conf && mkdir -p ./${port}/data;
done

# 创建6个redis容器
for port in `seq 7001 7006`;
do
	docker run -d -it -p ${port}:${port} -p 1${port}:1${port} -v /docker_data/redis-cluster/${port}/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /docker_data/redis-cluster/${port}/data:/data --privileged=true --restart always --name redis-${port} --net redis-net --sysctl net.core.somaxconn=1024 redis:6.2.5 redis-server /usr/local/etc/redis/redis.conf;
done

# 查找ip
for port in `seq 7001 7006`;
do
	echo  -n "$(docker inspect --format '{{ (index .NetworkSettings.Networks "redis-net").IPAddress }}' "redis-${port}")":${port}" ";
done

# 换行
echo -e "\n"

# 输入信息
read -p "输入要进入的Docker容器名字，默认redis-7001：" DOCKER_NAME

# 判断是否为空
if [ ! $DOCKER_NAME ]; 
	then DOCKER_NAME='redis-7001'; 
fi

# 进入容器
docker exec -it redis-7001 /bin/bash
```

#### 步骤2：创建容器

```bash
# 对文件执行授权
chmod +x install.sh

# 创建容器
./install.sh

# 创建完成，控制台显示如下
3650653e89b162d17f60677dec4369b5c27f0165de9058758786a0d2fdf78e2f
d770c1a477f610b0409f18b094849e20120de15b3b712b9a6a07915e15290e76
12df72dd8688d1ec6cd7353580cb8963212d6af772e43d60462824bae42d2283
ae51e5c831cfa779d787349b2acc71c7a80b43485c3b311ca9d2e56a0e07a4ee
f8438d12fd99cd38df77c7e91ac7af1e03675360cf4bf5763c01348d0a1bcf6f
08228ca6b8179fc08daab9fab7ff665a3c6ca9b65896e9ee096eaa897afb8c99
172.18.0.2:7001 172.18.0.3:7002 172.18.0.4:7003 172.18.0.5:7004 172.18.0.6:7005 172.18.0.7:7006

输入要进入的Docker容器名字，默认redis-7001：
```

#### 步骤3：创建 Redis 集群

```properties
# 进入容器
docker exec -it redis-7001 /bin/bash

# 切换目录
cd /usr/local/bin

# 创建集群
./redis-cli --cluster create 172.18.0.2:7001 172.18.0.3:7002 172.18.0.4:7003 172.18.0.5:7004 172.18.0.6:7005 172.18.0.7:7006 --cluster-replicas 1

# ----------------------------------------------------------------------
>>> Performing hash slots allocation on 6 nodes...
# 分配哈希槽
Master[0] -> Slots 0 - 5460
Master[1] -> Slots 5461 - 10922
Master[2] -> Slots 10923 - 16383
Adding replica 172.18.0.6:7005 to 172.18.0.2:7001
Adding replica 172.18.0.7:7006 to 172.18.0.3:7002
Adding replica 172.18.0.5:7004 to 172.18.0.4:7003

# 主从节点分配
M: e6f0f41a79e2da0915324a5367934d6e3b8f10aa 172.18.0.2:7001
   slots:[0-5460] (5461 slots) master
M: 33023ba3dcecc4c53cca705bd2d0b2875bcf55c9 172.18.0.3:7002
   slots:[5461-10922] (5462 slots) master
M: c980f213e5bcda96a47493448da9efb3c1da9b81 172.18.0.4:7003
   slots:[10923-16383] (5461 slots) master
S: a670ddbd4da8b9b934dd3f3d34a5c1fc5b754b40 172.18.0.5:7004
   replicates c980f213e5bcda96a47493448da9efb3c1da9b81
S: 5f930f9199ce9c97eb3feb605b55efe46a4674f1 172.18.0.6:7005
   replicates e6f0f41a79e2da0915324a5367934d6e3b8f10aa
S: 8dba862046ab4e20f5d4d78687121d3744dba00e 172.18.0.7:7006
   replicates 33023ba3dcecc4c53cca705bd2d0b2875bcf55c9
   
# ----------------------------------------------------------------------
# 输入 yes   
Can I set the above configuration? (type 'yes' to accept): yes

# ----------------------------------------------------------------------
# 开始创建集群
>>> Nodes configuration updated
>>> Assign a different config epoch to each node
>>> Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join

>>> Performing Cluster Check (using node 172.18.0.2:7001)
M: e6f0f41a79e2da0915324a5367934d6e3b8f10aa 172.18.0.2:7001
   slots:[0-5460] (5461 slots) master
   1 additional replica(s)
S: 8dba862046ab4e20f5d4d78687121d3744dba00e 192.168.126.200:7006
   slots: (0 slots) slave
   replicates 33023ba3dcecc4c53cca705bd2d0b2875bcf55c9
M: 33023ba3dcecc4c53cca705bd2d0b2875bcf55c9 192.168.126.200:7002
   slots:[5461-10922] (5462 slots) master
   1 additional replica(s)
S: a670ddbd4da8b9b934dd3f3d34a5c1fc5b754b40 192.168.126.200:7004
   slots: (0 slots) slave
   replicates c980f213e5bcda96a47493448da9efb3c1da9b81
M: c980f213e5bcda96a47493448da9efb3c1da9b81 192.168.126.200:7003
   slots:[10923-16383] (5461 slots) master
   1 additional replica(s)
S: 5f930f9199ce9c97eb3feb605b55efe46a4674f1 192.168.126.200:7005
   slots: (0 slots) slave
   replicates e6f0f41a79e2da0915324a5367934d6e3b8f10aa
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```

- 此时集群管理如下

```bash
7001（Master）    7005（Slave）
7002（Master）    7006（Slave）
7003（Master）    7004（Slave）
```

- 创建集群的相关参数

```properties
Cluster Manager Commands:
  create         host1:port1 ... hostN:portN   #创建集群
                 --cluster-replicas <arg>      #从节点个数
  check          host:port                     #检查集群
                 --cluster-search-multiple-owners #检查是否有槽同时被分配给了多个节点
  info           host:port                     #查看集群状态
  fix            host:port                     #修复集群
                 --cluster-search-multiple-owners #修复槽的重复分配问题
  reshard        host:port                     #指定集群的任意一节点进行迁移slot，重新分slots
                 --cluster-from <arg>          #需要从哪些源节点上迁移slot，可从多个源节点完成迁移，以逗号隔开，传递的是节点的node id，还可以直接传递--from all，这样源节点就是集群的所有节点，不传递该参数的话，则会在迁移过程中提示用户输入
                 --cluster-to <arg>            #slot需要迁移的目的节点的node id，目的节点只能填写一个，不传递该参数的话，则会在迁移过程中提示用户输入
                 --cluster-slots <arg>         #需要迁移的slot数量，不传递该参数的话，则会在迁移过程中提示用户输入。
                 --cluster-yes                 #指定迁移时的确认输入
                 --cluster-timeout <arg>       #设置migrate命令的超时时间
                 --cluster-pipeline <arg>      #定义cluster getkeysinslot命令一次取出的key数量，不传的话使用默认值为10
                 --cluster-replace             #是否直接replace到目标节点
  rebalance      host:port                                      #指定集群的任意一节点进行平衡集群节点slot数量 
                 --cluster-weight <node1=w1...nodeN=wN>         #指定集群节点的权重
                 --cluster-use-empty-masters                    #设置可以让没有分配slot的主节点参与，默认不允许
                 --cluster-timeout <arg>                        #设置migrate命令的超时时间
                 --cluster-simulate                             #模拟rebalance操作，不会真正执行迁移操作
                 --cluster-pipeline <arg>                       #定义cluster getkeysinslot命令一次取出的key数量，默认值为10
                 --cluster-threshold <arg>                      #迁移的slot阈值超过threshold，执行rebalance操作
                 --cluster-replace                              #是否直接replace到目标节点
  add-node       new_host:new_port existing_host:existing_port  #添加节点，把新节点加入到指定的集群，默认添加主节点
                 --cluster-slave                                #新节点作为从节点，默认随机一个主节点
                 --cluster-master-id <arg>                      #给新节点指定主节点
  del-node       host:port node_id                              #删除给定的一个节点，成功后关闭该节点服务
  call           host:port command arg arg .. arg               #在集群的所有节点执行相关命令
  set-timeout    host:port milliseconds                         #设置cluster-node-timeout
  import         host:port                                      #将外部redis数据导入集群
                 --cluster-from <arg>                           #将指定实例的数据导入到集群
                 --cluster-copy                                 #migrate时指定copy
                 --cluster-replace                              #migrate时指定replace
```

#### 步骤4：集群测试

```bash
# 登录redis集群
./redis-cli -p 7001 -c

# 添加数据
set zhangsan SDFDSFDSF.DSFSDFSDFS.FHBSDFDSFSDFF

# 自动重定向到7003节点
-> Redirected to slot [12767] located at 192.168.126.200:7003
OK

192.168.126.200:7003>
```



### 1.5 集群卸载

#### 步骤1：创建文件 uninstall.sh

```bash
cd /docker_data/redis-cluster
vi uninstall.sh
```

- uninstall.sh

```properties
#!/bin/bash
docker stop redis-7001 redis-7002 redis-7003 redis-7004 redis-7005 redis-7006
docker rm redis-7001 redis-7002 redis-7003 redis-7004 redis-7005 redis-7006
rm -rf 7001 7002 7003 7004 7005 7006
```

#### 步骤2：卸载

```bash
# 添加执行权限
chmod +x uninstall.sh

# 执行卸载
./uninstall.sh
```



### 1.6 集群扩容

#### 步骤1：创建脚本 oneinstall.sh

```bash
cd /docker_data/redis-cluster
vi oneinstall.sh
```

- oneinstall.sh

```properties
#!/bin/bash
# 在 /docker_data/redis-cluster 下生成conf和data目标，并生成配置信息
# 换行
echo -e "\n"

# 输入信息
read -p "请输入容器端口：" DOCKER_PORT

# 输入端口赋值
port=$DOCKER_PORT;

echo -e "$port"

# 创建配置文件
mkdir -p ./${port}/conf && PORT=${port} envsubst < ./redis-config.tmpl > ./${port}/conf/redis.conf && mkdir -p ./${port}/data;

# 创建redis容器
docker run -d -it -p ${port}:${port} -p 1${port}:1${port} -v /docker_data/redis-cluster/${port}/conf/redis.conf:/usr/local/etc/redis/redis.conf -v /docker_data/redis-cluster/${port}/data:/data --privileged=true --restart always --name redis-${port} --net redis-net --sysctl net.core.somaxconn=1024 redis:6.2.5 redis-server /usr/local/etc/redis/redis.conf;

# 查找ip
echo  -n "启动$(docker inspect --format '{{ (index .NetworkSettings.Networks "redis-net").IPAddress }}' "redis-${port}")":${port}" 成功！";
echo -e "\n"
```

#### 步骤2：创建新容器

```bash
# 添加可执行权限
chmod +x oneinstall.sh

# 创建新的节点
./oneinstall.sh

# 输入7007端口
7007
```

#### 步骤3：扩容

```bash
# 进入容器
docker exec -it redis-7001 /bin/bash

# 切换目录
cd /usr/local/bin

# 登录redis集群
./redis-cli -p 7001 -c

# 查看集群状态
cluster nodes

# 扩容
# 把 7007 节点添加到 7001 节点所在的集群中
./redis-cli --cluster add-node 192.168.126.200:7007 192.168.126.200:7001

# 哈希槽迁移
./redis-cli --cluster reshard 192.168.126.200:7003 --cluster-from 5d93f5ca5e7289c04b00ccc468e0ce4ef8afaea9 --cluster-to 889a13a1e1761f1e83c25e41287d1c463175d467 --cluster-slots 100

# 参数说明
5d93f5ca5e7289c04b00ccc468e0ce4ef8afaea9 指的是7003节点
889a13a1e1761f1e83c25e41287d1c463175d467 指定是7007节点
将7003节点中100个哈希槽迁移到7007上来
```



### 1.7 集群收容

```bash
# 进入容器
docker exec -it redis-7001 /bin/bash

# 切换目录
cd /usr/local/bin

# 登录redis集群
./redis-cli -p 7001 -c

# 查看集群状态
cluster nodes

# 哈希槽迁移

# 删除节点
# 把 7007 节点从 7001 节点所在的集群中删除
# ./redis-cli --cluster del-node 192.168.126.200:7001 7007的md5值
./redis-cli --cluster del-node 192.168.126.200:7001 889a13a1e1761f1e83c25e41287d1c463175d467
```



## 2、Linux系统 -  Redis 安装和配置

### 2.1 单机版

#### （1）安装

```bash
# 下载
yum install -y wget
wget http://download.redis.io/releases/redis-5.0.5.tar.gz

# 解压
tar -xzvf redis-5.0.5.tar.gz

# 安装依赖（C语言需要的 GCC 环境）
yum install gcc
yum install gcc-c++ 

# 进入目录
cd redis-5.0.5/src

# 编译
make

# 安装（/usr/local/redis目录下）
mkdir /usr/local/redis -p
make install PREFIX=/usr/local/redis
```

#### （2）启动

- 启动方式1：前端启动（客户端窗口关闭则 redis-server 程序结束，不推荐使用此方法）

```bash
# 切换到redis目录
cd /usr/local/redis/bin

# 启动
./redis-server
```

- 启动方式2：后台启动（守护进程启动，推荐）

```bash
# 复制配置文件
cp /root/redis-5.0.5/redis.conf /usr/local/redis/bin/

# 修改配置文件
vim /usr/local/redis/bin/redis.conf
/etc/redis/6379.conf

#########################################################
# 将`daemonize`由`no`改为`yes` （静默后台启动）
daemonize yes 

# 默认绑定的是回环地址，默认不能被其他机器访问，因此注释
# bind 127.0.0.1 

# 是否开启保护模式，由yes该为no 
protected-mode no

#########################################################

# 切换到redis目录
cd /usr/local/redis/bin

# 启动
./redis-server redis.conf

# 关闭
./redis-cli shutdown
```

#### （3）查看redis进程

```bash
# 查看redis进程
ps aux|grep redis
```

#### （4）登录 redis

```bash
# 切换到redis目录
cd /usr/local/redis/bin

# 访问数据库
# 方式1：访问本机数据库（默认为127.0.0.1:6379）
./redis-cli

# 方式2：访问固定ip的redis（首先在redis.conf中bind这个ip）
#./redis-cli -h ip地址 -p 端口号
./redis-cli -h 127.0.0.1 -p 6379

# 查看数据库是否通（结果为pong表示通）
ping
```



### 2.2 集群版



## 3、Win系统 -  Redis 安装和配置



## 4、Mac系统 -  Redis 安装和配置



---

# 第一章 Redis 简介

# 第二章 Redis 客户端访问

# 第三章 Redis 数据类型



# 第四章 Redis 通讯协议及事件处理机制



# 第五章 Redis 持久化



# 第六章 Redis 功能



# 第七章 Redis 集群

# 第八章 Redis 布隆过滤器

# 第九章 Redis 开发使用

## 1、Redis 缓存 - 常用注解

```java
// 开关性注解，在项目启动类或某个配置类上使用此注解后，则表示允许使用注解的方式进行缓存操作。
// 开启缓存注解，启动类上用
@EnableCaching

// 可用于类或方法上；在目标方法执行前，会根据key先去缓存中查询看是否有数据，有就直接返回缓存中的key对应的value值。不再执行目标方法；无则执行目标方法，并将方法的返回值作为value，并以键值对的形式存入缓存。
// 新增缓存时用（第一次会把数据缓存，后面会先查缓存中有没有，有的话就直接用，没有再查库）
@Cacheable

// 可用于类或方法上；在执行完目标方法后，清除缓存中对应key的数据(如果缓存中有对应key的数据缓存的话)
// @CacheEvict(key = "#typeId")  // 删除缓存时用
@CacheEvict

// 可用于类或方法上；在执行完目标方法后，并将方法的返回值作为value，并以键值对的形式存入缓存中
// @CachePut(key = "#typeId")  // 修改缓存时用（每次都把数据存到缓存，但不会使用缓存的数据）
@CachePut

// 此注解即可作为@Cacheable、@CacheEvict、@CachePut三种注解中的的任何一种或几种来使用
// 一般不用
@Caching

// 可以用于配置@Cacheable、@CacheEvict、@CachePut这三个注解的一些公共属性，例如cacheNames、keyGenerator
// @CacheConfig(cacheNames = "ad-items-skus")  // 开启缓存（cacheNames 为缓存的key ）
@CacheConfig
```

# 第十章 Redis 缓存问题

## 1、缓存击穿

### 缓存击穿 - 解决方案

#### （1）使用互斥锁（mutex key）

```java
public String get(key) {
    String value = redis.get(key);
    
    // 代表缓存值过期
    if (value == null) { 
        // 设置 3min 的超时，防止 del 操作失败的时候，下次缓存过期⼀直不能 load db
        if (redis.setnx(key_mutex, 1, 3 * 60) == 1) { 
            // 代表设置成功
            value = db.get(key);
            redis.set(key, value, expire_secs);
            redis.del(key_mutex);
        } else {
            // 代表同时候的其他线程已经 load db 并回设到缓存了，这时候重试获取缓存值即可
            sleep(50);
            get(key); //重试
        }
    } else {
        return value; 
    }
}
```



## 2、缓存穿透

### 缓存穿透 - 解决方案

#### （1）布隆过滤器



#### （2）对查询空值进行缓存，设置较短的过期时间

- 如果⼀个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进⾏缓存，但它的过期时间会很短，最⻓不超过五分钟。

```java
public object GetProductListNew() {
    int cacheTime = 30;
    String cacheKey = "product_list";
    String cacheValue = CacheHelper.Get(cacheKey); 

    // 查询的值不为空，直接返回
    if (cacheValue != null) {
        return cacheValue;
    } 

    cacheValue = CacheHelper.Get(cacheKey);
    if (cacheValue != null) {
        return cacheValue;
    } else {
        // 数据库查询不到，为空
        cacheValue = GetProductListFromDB();
        if (cacheValue == null) {
            // 如果发现为空，设置个默认值，也缓存起来
            cacheValue = string.Empty;
        }
        CacheHelper.Add(cacheKey, cacheValue, cacheTime);
        return cacheValue;
    }
}
```



## 3、缓存雪崩

### 缓存雪崩 - 解决方案

#### （1）加锁排队

```java
public object GetProductListNew() {
    int cacheTime = 30;
    String cacheKey = "product_list";
    String lockKey = cacheKey;
    String cacheValue = CacheHelper.get(cacheKey);
    
    if (cacheValue != null) {
        return cacheValue;
    } else {
        // 加锁
        synchronized(lockKey) {
            cacheValue = CacheHelper.get(cacheKey);
            if (cacheValue != null) {
                return cacheValue;
            } else {
                // 这⾥⼀般是sql查询数据
                cacheValue = GetProductListFromDB();
                CacheHelper.Add(cacheKey, cacheValue, cacheTime);
            }
        }
        return cacheValue;
    }
}
```

#### （2）将缓存失效时间分散开





## 4、Redis 缓存和 MySQL 数据⼀致性问题

### 4.1 产生原因

### 4.2 解决方案

#### （1）采用延时双删策略

- 在写库前后都进⾏ redis.del(key) 操作，并且设定合理的超时时间。

```java
public void write(String key,Object data){
    redis.delKey(key);   // 先删除缓存
    db.updateData(data); // 再写入数据库
    Thread.sleep(500);   // 休眠 500 毫秒（时间需要评估）
    redis.delKey(key);   // 再次删除缓存
}
```



#### （2）异步更新缓存（基于订阅 binlog 的同步机制）



































sentinel.conf

```
port 26699
daemonize yes
logfile "26699.log"
dir "/home/redis/redis-3.0.5/redis_cluster/sentinel/8001"
sentinel monitor master8001 10.1.103.66 8001 2
sentinel failover-timeout master8001 15000
sentinel auth-pass master8001 123
bind 10.1.103.66 127.0.0.1

```



```xml
# 1、哨兵sentinel实例运行的端口 默认26379  
port 26699
  
# 2、哨兵sentinel的工作目录  
dir "/home/redis/redis-3.0.5/redis_cluster/sentinel/8001"

# 3、哨兵sentinel监控的redis主节点的 ip port
# 格式：sentinel monitor <master-name> <ip> <redis-port> <quorum>  
# Sentinel去监视一个名为master8001的主redis节点的实例（只能由字母A-z、数字0-9 、这三个字符".-_"组成），这个主实例的IP地址为本机地址10.1.103.66 8001，端口号为8001，而将这个主实例判断为失效至少需要2个Sentinel进程的同意，只要同意的数量不达标，自动failover就不会执行
sentinel monitor master8001 10.1.103.66 8001 2
    
# 4、设置哨兵sentinel连接主从的密码（必须为主从设置一样的验证密码）
# 格式：sentinel auth-pass <master-name> <password>  
# 当在Redis实例中开启了requirepass foobared 授权密码，所有连接Redis实例的客户端都要提供密码  
sentinel auth-pass master8001 123
  
# 5、指定多少毫秒之后，当主节点没有应答哨兵sentinel时，哨兵主观上认为主节点下线，默认30秒  
# 格式：sentinel down-after-milliseconds <master-name> <milliseconds>  
sentinel down-after-milliseconds master8001 30000
  
# 指定在发生failover主备切换时最多可以有多少个slave同时对新的master进行同步，数字越小，完成failover所需的时间就越长，如果这个数字越大，就意味着越多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态
# sentinel parallel-syncs <master-name> <numslaves>  
sentinel parallel-syncs master8001 1
  
# failover-timeout：故障转移的超时时间（默认3分钟）
# 格式：sentinel failover-timeout <master-name> <milliseconds>  
# 使用情形1：同一个sentinel对同一个master两次failover之间的间隔时间
# 使用情形2：当一个slave从一个错误的master那里同步数据开始计算时间，直到slave被纠正为向正确的master那里同步数据时
# 使用情形3：当想要取消一个正在进行的failover所需要的时间
# 使用情形4：当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了
sentinel failover-timeout master8001 180000  
  
# SCRIPTS EXECUTION
# 配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员
# 对于脚本的运行结果有以下规则：  
# 若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10  
# 若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行
# 如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同
# 一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行
  
# 通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息
# 调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。  
# 如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功
# 通知脚本  
# sentinel notification-script <master-name> <script-path>  
# sentinel notification-script master8001 /var/redis/notify.sh  
  
    
# 客户端重新配置主节点参数脚本  
# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。  
# 以下参数将会在调用脚本时传给脚本:  
# <master-name> <role> <state> <from-ip> <from-port> <to-ip> <to-port>  
# 目前<state>总是“failover”,  
# <role>是“leader”或者“observer”中的一个。   
# 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的  
# 这个脚本应该是通用的，能被多次调用，不是针对性的。  
# sentinel client-reconfig-script <master-name> <script-path>  
# sentinel client-reconfig-script mymaster /var/redis/reconfig.sh  
```



https://blog.csdn.net/zanzhebo0157/article/details/88095521

https://blog.csdn.net/u012441222/article/details/80751390	

https://www.cnblogs.com/kevingrace/p/9004460.html



！！！！！！

https://www.cnblogs.com/guolianyu/p/10249687.html



查看redis服务

- ps aux|grep redis
- 

#执行启动redis和哨兵的命令
redis-server redis.conf
redis-sentinel sentinel.conf 





cd /home/redis/redis-3.0.5/redis_cluster/sentinel/8001





redis-cli -h 10.1.103.66 -p 8001 INFO|grep role



